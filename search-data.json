[{"type":"post","id":"2026-02-22-goodbye-2025","title":"再见 2025","url":"/blog/2026-02-22-goodbye-2025/","content":"迟了两个月才写这篇文章。总而言之，2025 结束了。\n\n本文禁止转载、禁止修改、禁止分发。\n随便的时间线\n按时间顺序说说吗。\n剪掉的头发\n1 月份被母上带着剪了头发。曾经的头发留得很长，已经超越了及腰，马上就要连屁股都要超过了。可惜母上的剪头发手艺似乎很烂。剪完之后，头发变得很短，妹妹头那种感觉。虽然并不能算很短吧但还是 gd 发作。\n由于很害怕理发店拖到 10 月份才去修理。\n炭火\n\n其实是翻找相册看到了回老家的照片。一年前也是在老家，烧着木柴，很多很多烟，熏得眼睛都睁不开了。虽然很不舒服，但玩火还是很有趣。虽然，传说玩火尿床\n一年的过去，也拍了炭火的照片。简直一模一样。就像时间没有流逝过。\n牛丼 ⭐️ 溫泉蛋\nFeb 27, 看到了牛丼和溫泉蛋的照片。不能確定，也許是那時候第一次喫這個吧。但是後來好像就不再去食其家了。\n小時候很討厭喫蛋。現在才發現大概是因爲家裏每次做的蛋都不好吃吧。會燒得很老，喫起來就像喫一坨乾燥的澱粉一樣。\n蝸牛\nMarch 8，照片裏是薩利亞的蝸牛。很喜歡喫這個。\n薄荷\n\nApril 1. 照片裏是薄荷，忘記什麼時候賣的了。高中畢業前在教室裏種了很多薄荷，雖然種子質量太差，發芽率很低。後來送給了老師。拿回自家的那盆換土的時候，媽媽一鏟子下去把根都弄斷了。……于是就死了。\n這次也並沒有逃過死掉的宿命。暑假沒法把它帶回去，劇烈的太陽會把它曬死，只好放在窗臺上。……然後，它的死因是被我放在窗台上，被風吹倒了。掉在了幾層樓下。倒是沒有粉身碎骨。只是沒法澆水，一點點枯萎了。\n生命如此。\n編譯原理\n被氣哭了。2025 年了還在拿 C 語言寫編譯器。明明有更好的寫法，卻被語言限制，一邊寫一邊哭。\n孤獨搖滾！\n\n和朋友去看了。紀念卡。\n還是薄荷\n\nMay 10 的照片。薄荷被我養到開了花。\n但是不知道爲什麼後面薄荷就一點點從底部枯萎到頂部。可能它沒掉下去也會死掉吧。\n飄起來的裙子\n風吹起來，把裙子吹得膨脹起來。當時覺得很有趣，拍了照片。\n……嗯，不要騎自行車的時候穿裙子。小心卡在車輪裡。\n落幕前奏\n拖延症很久以後終於不知道因爲什麼原因去了醫院。已經記不清了。總而言之，很久以前就差點拿到的證明，重新拿到了。\n珂朵莉\nJune 8. 也是和朋友出去玩，在一家穀子店看到。啊……這樣一個塑料牌賣300,二次元的錢真好賺。\n數學分析\n爲什麼我還要重修這玩意。\n鮮椒炒豬肝\n從小就不愛喫。但是，不知道爲什麼，突然很想點自己覺得難喫的東西。……然後意外的發現其實挺好喫。唉，大概又是因爲小時候家裏做出來的豬肝太老了。\n歡樂谷\n和朋友去歡樂谷玩了。發現自己再也不敢玩過山車和跳樓機…… 是否是一種焦慮症變嚴重的表現呢。\n沒有記錄的七月\n七月的照片沒有什麼特別的。\n十五\n弟弟撿到一隻小雞。……天知道爲什麼在城市裏居然還能撿到小雞啊。下着大雨的一天，突然在家裏聽到了鳥叫聲，才知道是弟弟撿了一隻被雨淋溼瑟瑟發抖的小鳥過來。\n它被起名叫做十五。本來以爲會死掉。沒想到，幾天後，還是沒死掉。然後是一個月，兩個月。之前還好奇它爲什麼不飛起來，後來才發現原來十五是一隻雞，本來就沒法飛……\n後來十五被送去了鄉下，很適合它的地方。長得很肥大一隻，還會下蛋了。\n就是長大後的雞遠遠沒有小雞可愛了。\n長大後的人也不如小孩可愛吧。\n鍵帽\n朋友家養的貓的名字。\n在朋友家睡了一晚，晚上貓突然跳到我身上來，嚇了我一大跳。不要咬我啊！！！\n鍵帽似乎很調皮。而且喜歡咬我。回去以後手上都有被抓的痕跡。\n不和貓計較。\n落幕前奏 II\n那天去了醫院，約上了手術。\n鯊鯊\n\n九月。 朋友賣了一隻好大的宜家鯊魚玩偶給我。好可愛啊！\n新的朋友\n課上認識的。\n小豆泥\n\n一直都很喜歡，突然發現了線下可以買到小豆泥周邊的店。……然後就連續剁手賣了 10 只各種各樣的小豆泥。\n好喜歡小豆泥。\nJK 店\n朋友想去，然後把我帶進坑了。\n學術會議\n11月，去了。\nNixOS\n12 月，開始使用 NixOS。\n做了\n先是弄了一個 vue 的練手作品，Misskey 前端，叫做 Sukerbuka。拿 vuetify 弄的。就是感覺有點醜…… 顏值是第一驅動力。于是就放棄了。\n後來，開始學 react。作爲 react 練手的作品，又去寫了一個 Misskey 前端，叫做 papilio.\n可惜開發到後面就，性能問題出來了。似乎是 react 的過。開個網站就要吃掉 1GB 的內存，還有一些 CPU 狂轉的問題。\n于是就慢慢被放棄了。雖然還是會偶爾更新一下，修一些小 bug。\n讀了\nPFPL （Practical Foundations for Programming Languages）。在開始前，對 PL 方向的理解其實非常淺薄。讀了以後才發現有很多很多很多東西沒有接觸過。雖然讀起來非常吃力，但感覺到了收獲，很開心。"},{"type":"post","id":"pfpl-note-12","title":"PFPL 笔记 - XII Symbolic Data","url":"/blog/pfpl-note-12/","content":"笔记 12 Symbolic Data\n\nSymbols\nA symbol is an atomic datum with no internal structure.\nA symbol is just a name, or index, for a family of operation\nlzx 同学给出的例子\n(define f (+ 1 a)) ; BOOM! \n(define f (mu () (+ 1 a))) ; OK \n(f) ; BOOM! \n(let ((a 1)) (f)) ; 2\nFluid Binding\n动态绑定\nput 用来给 a 绑定上\nget 用来获取 binding"},{"type":"post","id":"pfpl-note-11","title":"PFPL 笔记 - XI Types and Propositions","url":"/blog/pfpl-note-11/","content":"笔记 11 Types and Propositions\n\nConstructive Logic\n构造性逻辑将「真」定义为「存在一个证明」\n著名的 Curry-Howard 同构描述了\n\nPropositions as types\nProofs as programs\nSimplification of proofs as evaluation of programs\n\nConstructive logic 没有排中律，which means 如果我们有 \\phi false 并不能推出 \\neg \\phi true\nConstructive Semantics\nConstructive Logic 关注两个判断： \\phi \\text{ prop} 和 \\phi \\text{ true}\n命题不止被视为一个真值，还被视为一个问题陈述\n\nClassical Logic\nconstructive logic 没有排中律比较难受\n书中认为 Constructive Logic 某种意义上是“人类死角”而 classical logic 是“上帝视角”\n"},{"type":"post","id":"pfpl-note-10","title":"PFPL 笔记 - X Exceptions and Continuations","url":"/blog/pfpl-note-10/","content":"笔记 10 异常和 continuations\n\n该章节由我在 PL 读书会上讲解。 Presentation slides: pfpl-10.pdf\nControl Stack\n第一章给出了 Control Stack 的概念，记录当前 evaluation context 的栈\nk \\triangleright e 表示当前栈 k 将要计算一个表达式 e, 而 k \\triangleleft v 表示当前栈 k 将要返回一个值 v.\nExceptions\nExceptions 被定义为一种特殊的 value，当一个 exception 被抛出时，当前的 control stack 会被一路弹栈，并且寻找最近的 handler 来处理这个 exception.\nContinuation\nContinuation 是允许我们直接捕获和复制当前的 control stack，把 stack k 变成一个 first-class 的值 k \\text{cont}.\ncall/cc\ncall/cc 是一个高阶函数，接受一个函数作为参数，这个函数接受一个 continuation 作为参数，并且返回一个值.\n(call/cc (lambda (k) e))\ncall/cc 本质上就是书中介绍的 letcc k in e，它会把当前的 control stack 捕获并且传递给参数函数."},{"type":"post","id":"不要用马桶吃饭","title":"不要用马桶吃饭","url":"/blog/不要用马桶吃饭/","content":"\n用马桶吃饭的已经吃完饭回家了，饭盒原教旨主义团队还在加班洗碗，还拉着食品安全团队陪他们。\n\nHTTP 1.1 200 OK\nDate: Sat, 23 Aug 2025 21:30:37 GMT\nContent-type: application/json; charset=utf-8\nContent-length: 39\n\n\n{\"status\":403,\"message\":\"权限不足\"}\n\n\n我现在是坚定用马桶吃饭的。我刚入门的时候，也用饭盒老老实实装饭，吃完老老实实洗碗。然后有一次对接某个同事，他说“你能不能不要带饭盒过来吃饭，我这里 balabala（一些前端内容）”，我觉得我这样搞还省心，比如之前吃了还得洗碗，现在一按按钮冲一下就完事了，然后就一发不可收拾地远离饭盒。\n\n\n当你想吃饭时，一个饭盒拿过去，看着是舒服了，和同事对接的时候发现就是给自己找麻烦，为了方便，就用马桶吃饭了，只有屎到淋头才清理。\n\n\n曾经我也觉得，应该充分利用饭盒，后来我受够了。\n最经典的一个是，传错了参数，我问他饭盒里有什么，他说什么都没有，报异常了。\n我还要耐心的解释，虽然饭盒上没写 200，但是里面也是有东西的，你捕获一下异常看看返回了什么信息\n后来全都用马桶。\n\n\n用马桶吃饭可以让后端多睡一会，冲不了水只需要把运维叫醒来就行了，饭里有屎才需要call前后端。\n\n\n噗，饭盒才这么一点大，够用吗？最后还不是要分大小饭盒，我只给你一个小饭盒，你知道是装的什么？用饭盒，你倒是满足洁癖了，前端该骂娘了\n\n\n一个食物同时要在 web，app，微信小程序，微信公众号，支付宝小程序，支付宝订阅号等各种乱七八糟的平台用，这种时候选择用饭盒到底是多大的勇气\n\n\n虽然你是大佬，但是你是不是很久没吃过屎了\n\n\n我只想吃个饭，本来以为拿个马桶就能开吃，可楼主偏偏要我自己煮，还要我先买饭盒\n\n\n你这才是没看透。把饭盒研究透需要多少时间？如果饭盒小了不够吃怎么扩展？饭盒现在有那么多款式，要遵循规范使用的话就得部门成立预研部，把这些摸清楚……\n搞这么麻烦，最终就发现拿马桶吃饭最方便，这样一按按钮就能冲走\n\n\n看你说了那么多，可能连个屎都没吃过\n\n\n没做过食品行业导致的，千层饼一样的服务。根本不知道屎是哪层的。到没到你的马桶里。对了，还有缓存，还会限制所有非冲水请求。\n\n\n马桶和饭盒都是工具，最终目标是要实现业务解决问题，饭盒优势在哪里，缺点在哪里，要搞清楚。没有一个东西是万金油的，每个人的认知都是有限的，面临的问题又不一样，这个世界本来就没有完美都在缝缝补补，回答里我看到的是教条，只说了要用它没有说为什么要使用它\n\n\n业务一复杂你就慢慢琢磨饭盒吧\n\n\n【尴尬】有没有可能，你不用马桶吃饭，同事的筷子直接报错\n\n不要用马桶吃饭。"},{"type":"post","id":"unsafe-rust-is-not-same-as-c","title":"Unsafe Rust 并不和 C 语言一样：从 Aliasing 谈起","url":"/blog/unsafe-rust-is-not-same-as-c/","content":"在社区中你可能听到一种说法：在 unsafe 块里你可以像 C1 语言那样写。然而事实并不是这样，C 语言的约束太差，事实上给了程序员太多“宽松”的东西。而在 Rust 里，unsafe 真的很 unsafe —— 当你要接管编译器为你做的安全保证，危险就暗藏在其中。\n\n从 Aliasing XOR mutability 说起\n考虑这样一个函数\nfn alias_example(x: &mut i32, y: &mut i32) -> i32 {\n    *x = 114;\n    *y = 514;\n    return *x;\n}\n对于 C 语言新手程序员而言，这个函数看上去似乎等价于\nint alias_example(int *x, int *y) {\n    *x = 114;\n    *y = 514;\n    return *x;\n}\n真的是这样吗？想想看，假如 x 和 y 实际上是指向同一个内存区域的不同名指针怎么办？一个 C 程序员可以很自然的回答： x 被先赋值为 114，然后又被赋值为 514，最后函数整体返回 514。\n然而并非如此。实际上，Rust 使用了严格的 aliasing 规则，根据 Rust 的规则，同一个变量永远不能有两个可变引用。这直接导致编译器的优化产生不同的结果。不考虑内联，编译器可以安全的假设，x 和 y 永远指向不同的内存地址。因此，在第 2 行赋值之后，编译器可以知道 *x 一定是 114, 从而直接返回 114.\n但如果我们在 unsafe 块中直接违背这个规则呢？这会导致 Undefined Behavior（未定义行为）。在 Rust 中，unsafe 块只是允许你绕过编译器的安全检查，但这并不意味着你可以违背 Rust 的 Invariant（不变式）假设。例如，Rust 的 unsafe 代码仍然需要遵循 Rust 的 aliasing 规则。\n#[inline(never)]\nfn alias_example(x: &mut i32, y: &mut i32) -> i32 {\n    *x = 114;\n    *y = 514;\n    return *x;\n}\n\npub fn main() {\n    let mut a = 42;\n    let mut b = 84;\n    let ret = alias_example(&mut a, &mut b);\n    println!(\"a: {a}, b: {b}, ret: {ret}\");\n\n    unsafe {\n        let mut x = 1;\n        let still_x = &mut x as *mut i32;\n        // undefined behavior!\n        let ret = alias_example(&mut x, &mut *still_x);\n        println!(\"x: {x}, ret: {ret}\");\n    }\n}\n在这个例子中，我们在 unsafe 块中创建了一个指向 x 的裸指针 still_x，然后将其作为第二个参数传递给 alias_example 函数。显然这违背了 aliasing 规则，因此产生一个 undefined behavior。严格来说，该程序编译运行的结果是不确定的。但是在 rustc 1.88.0 开启 -O （3 级优化）后，我们可以看到输出如下：\na: 114, b: 514, ret: 114\nx: 514, ret: 114\n\nCompiler Explorer 链接： https://godbolt.org/z/Y6s15h9eP\n\n正如我们所料，编译器对 alias_example 函数进行了优化，虽然 *x 在函数中被第二次赋值为 514，但编译器接下来根本没有用到 *x 的值，而是直接返回了 114。生成的汇编代码如下：\nexample::alias_example::h26925842407e8957:\n        mov     dword ptr [rdi], 114\n        mov     dword ptr [rsi], 514\n        mov     eax, 114\n        ret\n而如果去掉 -O 优化选项，编译器就不会进行这样的优化了。将会正确的返回 514。\nexample::alias_example::h26925842407e8957:\n        mov     qword ptr [rsp - 16], rdi\n        mov     qword ptr [rsp - 8], rsi\n        mov     dword ptr [rdi], 114\n        mov     dword ptr [rsi], 514\n        mov     eax, dword ptr [rdi]\n        ret\n这说明，如果你的代码中包含 unsafe 块，不同的优化级别下，可能会导致不同的行为。事实上，之前的代码实际上等价于使用了 restrict 关键字 的 C 代码：\nint alias_example(int* restrict x, int* restrict y) {\n    *x = 114;\n    *y = 514;\n    return *x;\n}\n在 -O3 编译选项下，生成如下的汇编\nalias_example:\n        mov     DWORD PTR [rdi], 114\n        mov     eax, 114\n        mov     DWORD PTR [rsi], 514\n        ret\n与 Rust 的行为一致。如果去掉 restrict 关键字，g++ 编译器（和任何一个成熟的编译器）都将默认 x 和 y 是可能 aliasing 的，因此不敢进行激进优化，只能按原样生成汇编代码：\nalias_example:\n        mov     DWORD PTR [rdi], 114\n        mov     DWORD PTR [rsi], 514\n        mov     eax, DWORD PTR [rdi]\n        ret\n如果这个函数被大量执行，将会影响到性能。这不是一句玩笑。老练的 C 程序员都应该知道自从 C99 开始 memcpy 函数的类型签名就包含 restrict 关键字：\nvoid* memcpy( void *restrict dest, const void *restrict src, size_t count );\n\nThe behavior is undefined if access occurs beyond the end of the dest array. If the objects overlap (which is a violation of the restrict contract)(since C99), the behavior is undefined. The behavior is undefined if either dest or src is an invalid or null pointer.\n\n因为任何一个现代机器上，memcpy 都不是像 PDP-11 那样一个一个字节拷贝的，而是使用 SIMD 指令一次性拷贝多个字节。编译器需要知道 dest 和 src 不会 aliasing 才能进行这样的优化。你可以试一试用 Compiler Explorer 手动实现一个 memcpy，比较删掉 restrict 关键字后二者的影响。删掉 restrict 关键字后，编译器必须先比较两个指针是否相差在 count 直接以内（正如 restrict 保证），如果不是，才可以放心使用 SIMD，否则只能分情况讨论。对于 memcpy 这种被大量调用的函数，这一点点比较开销会导致可观察到的性能下降。\n而你没法保证写 C 语言的都是顶尖高手程序员，懂得时时刻刻加入 restrict 关键字，承担一旦用错就会出现未定义行为的后果。更多新手甚至连 const 也懒得或者不会使用。还有一些项目，代码质量明显堪忧，undefined behaviour 满天飞（虽然这也与 C/C++ 有一些不应该有的 undefined behaviour 有关），人们甚至总结出“不要开启优化选项，编译器会搞烂你的代码”的建议。——也可以理解，一些项目开出的工资没有办法雇佣能 C 语言期盼的不会犯错程序员。\n这也是为什么 Rust 明明比 C 语言抽象程度更高，却可能生成更高效的代码的原因。更多的约束允许编译器获得更多信息，进行更多优化。C 语言不只是不安全。它还慢。 事实上，在当今世界，C 语言反而正在拖慢代码的速度。2\n\nC also requires padding at the end of a structure because it guarantees no padding in arrays. Padding is a particularly complex part of the C specification and interacts poorly with other parts of the language. For example, you must be able to compare two structs using a type-oblivious comparison (e.g., memcmp), so a copy of a struct must retain its padding. In some experimentation, a noticeable amount of total runtime on some workloads was found to be spent in copying padding (which is often awkwardly sized and aligned).\n\n类型系统并不只是一个繁琐的工具，只是用来保证人们想当然“一眼就能看出的”程序的安全性。它还给编译器更多信息，从而自动生成更高效的代码——而对于大多数程序员而言，并不会花费那么多时间在极致的性能优化上。 这很反一些程序员的直觉：它们认为越贴近底层、越像汇编、抽象程度越低的语言速度越快。它们会想当然地觉得，写汇编是最最快的，而 C 语言比汇编慢 10%，C++ 比 C 又慢 10%，Rust 又比 C++ 慢 10% ——这来自于错误的“前人经验”，在编译优化还没有那么成熟的时代，作为“稍微抽象了一点的汇编”的 C 语言确实通常能写出很高效的代码，而 C++ 等语言编译器不够聪明，无法进行足够的优化。而当今世界随着编译技术的发展，编译器已经可以进行非常复杂的优化，甚至可以在大多数情况下超越手写的优化代码。例如一些人津津乐道的“位运算加速技巧”在如今已经不是魔法，而是编译器的常规优化。\n\n\n扩展阅读：一个 C 语言位运算加速被编译器自动实施的例子\n\n在算法题中，一个完全二叉树指的是叶子结点只能出现在最下层和次下层，且最下层的叶子结点集中在树的左部的二叉树。我们可以用一个数组直接存储完全二叉树，且节点用层次遍历编号，总是有编号为 i 的节点，左子节点编号为 2i，右子节点编号为 2i + 1。因此我们可以用 x * 2 和 x * 2 + 1 来计算左子节点和右子节点的编号。\n#include <stdio.h>\n\nint left_child(int x) {\n    return x * 2;\n}\n\nint right_child(int x) {\n    return x * 2 + 1;\n}\n\nint left_child_faster(int x) {\n    return x << 1;\n}\n\nint right_child_faster(int x) {\n    return x << 1 | 1;\n}\n\nint get_most_rchild(int x, int maxn) {\n    while (x < maxn) x = right_child(x);\n    return x;\n}\n\nint main() {\n    int x = 1;\n    int lc1 = left_child(x),\n        lc2 = left_child_faster(x),\n        rc1 = right_child(x),\n        rc2 = right_child_faster(x);\n\n    printf(\"%d %d %d %d\", lc1, lc2, rc1, rc2);\n}\n在信息学竞赛中，许多人会写 x << 1 | 1 来加速完全二叉树叶子节点 index 的计算。然而现在这种技巧已经不再是魔法了。编译器会自动将 x * 2 + 1 优化为 x << 1 | 1，你的技巧只不过是让自己读代码变得更困难，实际上对于两个函数，编译器完全会生成一模一样的代码：\nleft_child:\n        lea     eax, [rdi+rdi]\n        ret\nright_child:\n        lea     eax, [rdi+1+rdi]\n        ret\nleft_child_faster:\n        lea     eax, [rdi+rdi]\n        ret\nright_child_faster:\n        lea     eax, [rdi+1+rdi]\n        ret\nget_most_rchild:\n        mov     eax, edi\n        cmp     edi, esi\n        jge     .L6\n.L7:\n        lea     eax, [rax+1+rax]\n        cmp     esi, eax\n        jg      .L7\n.L6:\n        ret\n.LC0:\n        .string \"%d %d %d %d\"\nmain:\n        sub     rsp, 8\n        mov     r8d, 3\n        mov     ecx, 3\n        mov     edx, 2\n        mov     esi, 2\n        mov     edi, OFFSET FLAT:.LC0\n        mov     eax, 0\n        call    printf\n        mov     eax, 0\n        add     rsp, 8\n        ret\n\n使用 g++ 15.1, -O1 （相对很保守的优化）下的结果。\n可以看到，xxx_child 和 xxx_child_faster 生成的代码完全一样。而 main 和 get_most_rchild 函数内直接把函数自动内联，根本没有生成 call 指令，甚至 main 内结果也在编译期给出，没有任何运行时计算。\n\n\n但编译器优化也同时为 Rust 的 unsafe 块带来了更高风险。因为在 unsafe 块中，编译器不只是不再为你提供安全的保证，它还需要你将 Rust 的所有不变式熟记于心。这是人们随意说出“unsafe 块里像 C 语言一样写就好了”的时候所经常忽略的。\n编译器优化与 Undefined Behavior\n在 C 中一个经常被争论的点是编译器是否应该利用 undefined behavior 来进行激进的优化。C/C++ 语言的标准允许编译器在遇到 undefined behavior 时进行任意行为（比如发射核弹炸毁你的家 :P ），包括假定 undefined behaviour 永远不会发生。（如果发生了，编译器作者假定程序员将会很乐意看到意外的行为）实际上 GCC 等编译器确实会在高的优化等级下，利用这一点进行优化。一个经典的例子是 signed integer overflow。\nint foo(int x) {\n    return x + 1 > x; // either true or UB due to signed overflow\n}\n如果一字一句的翻译这段代码，在许多平台，int 上溢时会按补码规则处理，得到一个负数值。因此，写这段代码的人会期望这个函数能“证明”一个整数将在当前架构下溢出。C 语言的前几节课讲到原码、反码、补码的时候，一些老师会用类似的代码作为例子向学生生动阐述溢出的效果（虽然应该不会开优化）。然而，signed integer overflow 实际上是 undefined behavior，因此编译器在激进优化时可以假定它永远不会发生。此时编译器会发现 x + 1 的结果永远不会小于 x，因此可以直接将其优化为 return true;\nfoo:\n        mov     eax, 1\n        ret\n如果学生不小心打开了优化开关——那它可能会很惊讶的发现代码的行为和老师的例子完全不一样。\n类似的例子还有很多。例如被许多人用来证明 “C 语言的优雅” 的著名算法，如《雷神之锤 III 竞技场》源代码中平方根倒数速算法之实例。\nfloat Q_rsqrt( float number )\n{\n    long i;\n    float x2, y;\n    const float threehalfs = 1.5F;\n\n    x2 = number * 0.5F;\n    y  = number;\n    i  = * ( long * ) &y;                       // evil floating point bit level hacking（对浮点数的邪恶位元hack）\n    i  = 0x5f3759df - ( i >> 1 );               // what the fuck?（这他妈的是怎么回事？）\n    y  = * ( float * ) &i;\n    y  = y * ( threehalfs - ( x2 * y * y ) );   // 1st iteration （第一次迭代）\n//  y  = y * ( threehalfs - ( x2 * y * y ) );   // 2nd iteration, this can be removed（第二次迭代，可以删除）\n    return y;\n}\n实际上，这个代码是 undefined behaviour。C 的 strict aliasing 规则3规定：\n\nGiven an object with effective type T1, using an lvalue expression (typically, dereferencing a pointer) of a different type T2 is undefined behavior, unless:\n\nT2 and T1 are compatible types.\nT2 is cvr-qualified version of a type that is compatible with T1.\nT2 is a signed or unsigned version of a type that is compatible with T1.\nT2 is an aggregate type or union type type that includes one of the aforementioned types among its members (including, recursively, a member of a subaggregate or contained union).\nT2 is a character type (char, signed char, or unsigned char).\n\nThese rules control whether when compiling a function that receives two pointers, the compiler must emit code that re-reads one after writing through another:\n\n因此，int* 和 float* 根本不应该指向同一块内存区域。这是 undefined behaviour。对于许多程序员而言这简直是荒谬的事情，因为它极大的限制了作为底层语言的 C 语言的能力。程序员会觉得，float 和 int 都是一样的大小，为什么不能直接将一个数字的位模式转换为另一个数字的位模式？这不是 C 语言的强项吗？\n但如果你站在编译器开发和优化者的角度，这个规则就变得非常有意义：当你看到 int* 和 float* 同时出现的时候，假定两者不会指向同一块内存区域，可以让编译器进行更激进的优化。因为如果两者指向同一块内存区域，编译器就必须在每次读取 int 或 float 时都重新从内存中读取，而不能直接使用寄存器中的值。让我们再回到最开始的 aliasing 例子。如果有以下代码：\nint alias_example2(int *x, float *y) {\n    *x = 114;\n    *y = 514;\n    return *x;\n}\n编译器根本没法揣摩你的心意，尤其是像 C 这样的语言，你编译出来的代码还经常作为动态链接库，你根本不知道用户会传入什么。如果你不按 strict aliasing 就没法优化这段代码，说不定它会被大量调用，成为一个性能下降的节点呢？权衡之下，考虑到对同一块内存区域进行不同类型的解释是很罕见的情况，编译器更应该尝试将它优化成：\nalias_example2:\n        mov     DWORD PTR [rdi], 114\n        mov     eax, 114\n        mov     DWORD PTR [rsi], 0x44008000\n        ret\n由于 undefined behaviour 广泛而常见，甚至在一些地方是难以绕开的（例如操作系统，Linux 的编译包含了 -fno-strict-aliasing 规则），有人认为4 GCC 等编译器 “using undefined behaviour in the C Standard as an excuse to fuck up their own compiler is what’s beyond demented” （拿 C 标准中的未定义行为作为借口来搞砸自己的编译器，简直是疯子干得出来的事情）\n然而我实际上不那么认为。难听点说，这是非常不负责任的行为。如果你不在乎性能而喜欢非常确定的行为可以用 Python 不是吗？为什么要用 C/C++ 为难自己？如果你在乎性能，就应该知道你在这里觉得无所谓的 5~10% 差异是别人可能刚需的。编译器作者不是只为你服务。这是一个多方权衡的 trade-off。\n实际上，我认为这种想法这是倒果为因了，应该说：是写编译器的人需要有足够强的假定来给他们进行优化，因此才将一些行为定义成 undefined behaviour.\n\nDefining a semantics with that property is not a simple task. A naive semantics, such as the one used in \\lambda_{\\text{Rust}}, will give the example program5 a defined meaning and thus force the compiler to print 13. Compared to such a naive semantics, we have to “add” some undefined behavior to obtain the desired optimizations. But of course we should not add “too much” undefined behavior! We have to be careful that “desired” programs are still well-defined. This includes all safe programs, but should also include enough unsafe programs to still make unsafe Rust a useful language for implementing data structures such as Vec, and to minimize the chances of programmers accidentally running into undefined behavior. 6\n\nunsafe is really unsafe\n而你必须负起责任来。\nRust 与 C/C++ 的一个区别大概是后者有人惯着你。我敢说大部分以为自己会写 C/C++ 语言的人实际上都不懂得 C/C++ 语言的 undefined behavior —— 因此使用各种屎上糊屎的手段解决问题。例如极端地，禁止开优化。\n但是 Rust 不会让你这样。一大原因是，Rust debug 模式的产物确实太慢，与 Release 模式可以轻易到达 6 倍差距，人们不得不开优化。另一件事情来自 Rust 的设计哲学：Safe Rust 被期望是永远安全的，即使是初学者也不会写出段错误和未定义行为，如果尝试，那么编译器一定会警告。Safe Rust 的编写者从而能从底层的细节中解脱出来，专注关心业务逻辑，有时候则关心向编译器证明自己是对的。而一旦 Unsafe Rust 的编写者不够负责，信任链条就会在这里断裂，从而可能产生危险的漏洞。\n以 Unsafe Rust 随堂小测 - 知乎 中给出的代码为例子，Unsafe Rust 的编写者必须非常熟练于找出代码可能被传入的多种边缘情况，否则，一不留神，便可能写出看似正确的 unsound 代码。\n例如第 1 题，初始化上的未定义行为。\n/// !!!unsound!!!\npub fn bytes_of<T>(val: &T) -> &[u8] {\n    let len: usize = core::mem::size_of::<T>();\n    let data: *const u8 = <*const T>::cast(val);\n    unsafe { core::slice::from_raw_parts(data, len) }\n}\n编写者必须得想到多种情况：\n\nT 可能是 MaybeUninit，此时得到的 &[u8] 包含未初始化的内存，而读取未初始化内存是未定义行为\nT 可能包含对用户无感知的 padding，但是任何对 padding 的访问，包括读，都是未定义行为\nT 可能是包含内部可变性的类型（例如 Cell），此时对 &T 的访问不能保证指向的内存不变\n\n第 6 题。对齐上的未定义行为。\n/// !!!unsound!!!\npub fn ffi_static_mut<T>(val: T) -> &'static mut T {\n    unsafe {\n        let size: usize = std::mem::size_of::<T>();\n        let ptr: *mut T = libc::malloc(size).cast();\n        if ptr.is_null() {\n            std::process::abort();\n        }\n        ptr.write(val);\n        &mut *ptr\n    }\n}\n显然这就是非常经典的在 unsafe rust 中当成 C 写——例如使用 malloc 函数。但是你们有没有想过，为什么 malloc 分配的指针犹如魔法一样，可以给任何类型使用，无需担心什么问题？尤其是对于初学者而言，它们甚至可能没有质疑过，为什么 malloc 可以给所有类型指针使用这件事情。malloc 能给所有类型使用似乎是理所当然的事情。\n——然而不是。这个函数体现了 Rust 和 C 不一样的地方，C 保证了所有类型都是由对齐已知的内置类型组合而来，因此 malloc 的规范里保证了得到的指针总是与任意 object type 都能对齐7。不能对齐有很多危害，例如现代 CPU 经常在 SIMD 指令上要求地址必须对齐。\n但是 Rust 没有这个保证。Rust 的类型可能包含更复杂的 align，如果传入的 T 需要更大的对齐，那么 malloc 返回的指针可能无法满足 T 的对齐要求。此时，返回的指针不能被安全的使用，这是未定义行为。\n第 7 题，恐慌安全\n/// !!!unsound!!!\npub fn replace_with<T>(v: &mut T, f: impl FnOnce(T) -> T) {\n    unsafe {\n        let ptr: *mut T = v;\n        let val = ptr.read();\n        ptr.write(f(val));\n    }\n}\n编写者必须考虑到 f 可能会 panic 的情况。此时，ptr.write 将会被打断，因此不会对 v 写入正确的值——而 panic 后被从 v 里面 move 出来的 val 将会被析构，因此外部的 v 还保留着 val 的同一个值，这将会导致双重析构，从而导致未定义行为。这通常会导致程序直接 segfault。\n这些例子都表明，编写 Unsafe Rust 代码的责任在于开发者，这不止是说说而已。开发者必须充分理解 Rust 的内存模型、计算机底层原理、体系结构、Rust 的各种不变式和内置 trait，以确保代码在任何时候都能保证安全性和正确性——或者产生一个编译错误。\n这种心智负担比全是 unsafe，全部要开发者自己承担的 C/C++ 某种意义上还要大。C/C++ 写出 bug 大可以怪调用者没遵守调用约定，但是 unsafe rust 的编写者因为自己的 unsafe 模块考虑不周全出了 bug，所有人都只会怪 unsafe 模块的编写者。\n结语\n经常有人说：对 C++ 和 Rust 极度了解，懂得该怎么驾驭 unsafe，适当的使用 unsafe 可以极大提高数据结构设计的灵活性\n那么问题是，谁才是对 C++ 和 Rust 极度了解呢？到底有多少人能做到“极度了解”呢？如果你是一个 C/C++ 程序员，你可能会觉得自己已经很了解了，但是你真的了解吗？大部分写 C/C++ 的人应该都远远称不上了解。尚且不说需要系统学习计算机底层的各种 alignment padding 需要编译原理来理解为什么的 aliasing 还有被誉为只有语言律师才能记得的各种 undefined behavior。就单说代码习惯，大多数人都能习惯性给每一个只要现在不变的类型写成 const T & 甚至加上 __restrict 吗？能在保证没有 exception 的时候习惯性加上 noexcept 吗？\n这些都可能直接影响到性能，例如移动构造函数不加 noexcept，各种 STL 容器直接给你改成调用拷贝构造，影响性能。\n写这一篇文章大概就是为了感叹这样的问题。“在 unsafe 里就像 C 那样写就好”。然而 unsafe 并不是拿来给你在 Rust 的约束中找到一丝自由的 —— 它是允许经验丰富的人，在镣铐中跳舞，在遵守 Rust 的大量假设和不变式的同时，编写类型系统无法表达的那一部分——而你必须熟悉的是这一整套类型系统构筑起的约定、优化和安全边界。这是 Rust 的设计哲学。程序员不可信任，能在熟练掌握 unsafe 的终究是少数人。\n如果你没准备好去承担它们，那你也许根本不该碰 unsafe。\n脚注\n\n\n由于这里不需要特别区分，下文的 C 语言或者 C++ 语言可能说的是这两者 ↩\n\n\nDavid Chisnall. 2018. C Is Not a Low-level Language: Your computer is not a fast PDP-11. Queue 16, 2 (March-April 2018), 18–30. https://doi.org/10.1145/3212477.3212479 ↩\n\n\nhttps://en.cppreference.com/w/c/language/object.html#Strict_aliasing ↩\n\n\nhttps://x.com/effectfully/status/1874144090327228518 ↩\n\n\n该论文中的 example 即本文开头的代码，但是数字有不同\nfn example(x: &mut i32, y: &mut i32) -> i32 {\n    *x = 13;\n    *y = 42;\n    return *x;\n}\n↩\n\n\nUnderstanding and Evolving the Rust Programming Language ↩\n\n\nreturns a pointer that is suitably aligned for any object type with fundamental alignment. https://en.cppreference.com/w/c/memory/malloc ↩\n\n\n"},{"type":"post","id":"coroutine-intro","title":"协程概念笔记","url":"/blog/coroutine-intro/","content":"\n协程（Coroutine）是一种计算机控制流结构，它允许代码块在执行过程中显式地暂停并恢复，同时保留其执行状态（包括调用栈、变量、上下文等），从而实现协同式多任务处理。\n\n曾经一直没有太搞懂协程这个概念是什么。于是写下这样的一篇文章，尝试对自己解释协程是什么\n\n传统意义上的普通函数\n考虑一个没有副作用的函数。当我们调用它的时候，我们从 caller 跳到 callee 里面，做一些事情，然后把结果返回出来，交给调用者。\n从计算机底层来讲，这意味着 caller 保存了所有调用者该保存的寄存器，然后把自己推进栈里，跳转到 callee；而 callee 昨晚所有的事情以后，return 时，恢复所有被调用者该保存的寄存器，把返回值通常 mov 到 eax, 然后从栈里拿出调用者的地址，跳回去。\n但我们这篇文章并不想单纯讨论像 C++ 那样的底层语言是如何实现协程的，所以并不会详细介绍像上面的东西。\n考虑假如多次返回？\n考虑一个非常朴实的函数 range(a, b)。我们希望 for i in range(a, b) 迭代 [a, b) 区间内的值。\n如果它直接返回一个 List，当然也可以。但是如果 b 非常大呢？比如需要迭代一亿个数，但是中间可能有 break 直接跳出循环呢？后面的所有的生成出来的东西都浪费了。\n假如没有协程的话，那么我们需要实现一个状态机，类似于：\nconst range = (a, b) => ({\n  value: a - 1,\n  done: false,\n  [Symbol.iterator]() {\n    return this;\n  },\n  next() {\n    if (this.value >= b) {\n      this.done = true;\n      return this;\n    }\n    this.value += 1;\n    return this;\n  },\n});\n注意到我们返回了一个带有状态的对象。每次调用 next() 的时候，我们都可以返回下一个值。\n异步与回调函数\n哦，原谅我们的传统过程式语言吧。\n在早期，编写异步函数通常需要手动传入一个 callback。比如说\n"},{"type":"post","id":"win11-stuttering-solution","title":"Windows 11 Chromium 渲染卡住的解决方案","url":"/blog/win11-stuttering-solution/","content":"注册表打开：HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows\\Dwm 新增一个 OverlayTestMode 的 DWORD 项，值为 5 重启即可\n\nsource: https://www.bilibili.com/video/BV1SnNNeaEA9"},{"type":"post","id":"pointfree-thinks","title":"Point-free Style 思考","url":"/blog/pointfree-thinks/","content":"\nPoint-free style can (clearly) lead to Obfuscation when used unwisely. As higher-order functions are chained together, it can become harder to mentally infer the types of expressions. The mental cues to an expression’s type (explicit function arguments, and the number of arguments) go missing.\n\nhttps://wiki.haskell.org/Pointfree\n\n从猫头鹰运算符说起……\nThe owl ((.)$(.)) has type (a -> b -> c) -> a -> (a1 -> b) -> a1 -> c, and in pointful style can be written as \\a b c d -> a b (c d).\nExample\n> ((.)$(.)) (==) 1 (1+) 0\nTrue\n相信大家看到这个抽象东西第一反应是 “什么勾八玩意” 吧！但是其实它还是挺好理解的，只要知道\n(.) f g x = f (g x)\n($) = id\n所以这个运算符其实是 id (.) (.)\n也就是 (.) (.) 这个是不是叫奶子运算符\n(.) $ (.)\n  = (.) (.)\n  = λ a b     => (.) (a b)   -- 补充两个被省略的参数\n  = λ a b c d => (a b) (c d) -- 补充两个被省略的参数\n  = λ a b c d => a b (c d)   -- 消去冗余括号\n猫头鹰还有一个进阶版本：\n((.).(.))\n它也可以用类似的方式推导\n((.).(.))\n  = λ a       => (.) ((.) a)     -- 补充一个被省略的参数\n  = λ a b c   => (.) ((.) a) b c -- 补充两个被省略的参数\n  = λ a b c   => ((.) a) (b c)   -- 一次消去\n  = λ a b c   => (.) a (b c)     -- 冗余括号消去\n  = λ a b c d => (.) a (b c) d   -- 再补个参数\n  = λ a b c d => a ((b c) d)     -- 消去\n  = λ a b c d => a (b c d)       -- 消去冗余括号\n喂喂你 Pointless 了！\nPoint-free 当然不全是这样的奇技淫巧 —— 当然这个也称不上多奇技淫巧，简单的 β-规约 而已\nPoint-free 虽然看上去眼花缭乱，但是它其实是培养你对于函数是一等公民，以及函数是一个整体，并且是一个可以用于构建更复杂函数的基本单位的这样一种认知。这在组合子里面非常有用。\n当然大家还是一般不会用 (.).(.) 这么抽象的东西的……这样写就真的 Pointless 了\n当你写下\nsum' xs = foldr (+) 0 xs\n的时候，应该能很容易意识到\nsum = foldr (+) 0\n这件事，因为 foldr (+) 0 实际上组合出了 sum 的逻辑。而一个熟练的函数式写手，应该对后者更熟悉而不是前者。\n拿 Parser Combinator 举例子，我在学习在 Lean4 中使用 Parser Combinator 中很自然而然地写下了 pointfree 的逻辑，因为只要你把 parser 的函数看成可以组合的积木，而不需要关心它的实际参数来源的话，pointfree 写法就是最自然的：\nmutual\n  partial def parseArray : Parser Json := do\n    _ ← char '['\n    _ ← whitespaces\n    let elems ← sepBy parseJson (char ',')\n    _ ← whitespaces\n    _ ← char ']'\n    return Json.arr elems\n\n  partial def parseObject : Parser Json := do\n    _ ← char '{'\n    _ ← whitespaces\n    let pairs ← sepBy parsePair (char ',')\n    _ ← whitespaces\n    _ ← char '}'\n    return Json.obj pairs\n\n  partial def parsePair : Parser (String × Json) := do\n    _ ← whitespaces\n    let key ← quotedString\n    _ ← whitespaces\n    _ ← char ':'\n    let value ← parseJson\n    return (key.asString, value)\n\n  partial def parseJson : Parser Json := do\n    let _ ← whitespaces\n    let json ← fun str => match str with\n      | 'n' :: _ => parseNull str\n      | 't' :: _ => parseTrue str\n      | 'f' :: _ => parseFalse str\n      | '[' :: _ => parseArray str\n      | '{' :: _ => parseObject str\n      | '\"' :: _ => parseString str\n      | _ => parseNumber str\n    let _ ← whitespaces\n    return json\nend\n当然如果你再入味一点，你可能会写出这种 shit：\npartial def parseObject : Parser Json :=\n  Json.obj <$> (\n    char '{' *> whitespaces *> (\n      sepBy parsePair (char ',')\n    ) <* whitespaces <* char '}'\n  )\n相比之下，同为函数式语言，由于没有很好的 currying，Gleam 重构上述代码写出来的解析器就凌乱不堪：\nfn object_parser() -> Parser(Node) {\n  fn(input: String) {\n    use #(_, input) <- result.then(char(\"{\")(input))\n    let input = input |> string.trim\n    use #(val, input) <- result.then(seq_by(\n      pair_parser(),\n      char(\",\") |> chain(whitespace()),\n    )(input))\n    let input = input |> string.trim\n    use #(_, input) <- result.then(char(\"}\")(input))\n    Ok(#(Obj(dict.from_list(val)), input))\n  }\n}\n\n完整代码\nimport gleam/dict\nimport gleam/io\nimport gleam/list\nimport gleam/result\nimport gleam/string\n\npub type Node {\n  Nul\n  Bol(val: Bool)\n  Num(val: Int)\n  Str(val: String)\n  Arr(val: List(Node))\n  Obj(val: dict.Dict(String, Node))\n}\n\ntype Parser(t) =\n  fn(String) -> Result(#(t, String), String)\n\nfn or(p1: Parser(a), p2: Parser(a)) -> Parser(a) {\n  fn(input: String) {\n    case p1(input) {\n      Ok(x) -> Ok(x)\n      Error(_) -> p2(input)\n    }\n  }\n}\n\nfn chain(p1: Parser(a), p2: Parser(b)) -> Parser(#(a, b)) {\n  fn(input: String) {\n    use #(res1, input) <- result.then(p1(input))\n    use #(res2, input) <- result.then(p2(input))\n    Ok(#(#(res1, res2), input))\n  }\n}\n\nfn char(c: String) -> Parser(String) {\n  fn(str: String) {\n    case str |> string.pop_grapheme {\n      Error(Nil) -> Error(\"Unexpected EOF\")\n      Ok(#(first, rest)) if first == c -> Ok(#(first, rest))\n      Ok(_) -> Error(\"unexpected token \" <> str)\n    }\n  }\n}\n\nfn whitespace() -> Parser(#()) {\n  fn(input: String) { Ok(#(#(), input |> string.trim)) }\n}\n\nfn ident(id: String) -> Parser(String) {\n  fn(str: String) {\n    case str |> string.starts_with(id) {\n      True -> Ok(#(id, str |> string.drop_start(string.length(id))))\n      False -> Error(\"unexpected token \" <> str)\n    }\n  }\n}\n\nfn true_parser() -> Parser(Node) {\n  fn(input: String) {\n    use #(_, rest) <- result.then(ident(\"true\")(input))\n    Ok(#(Bol(val: True), rest))\n  }\n}\n\nfn false_parser() -> Parser(Node) {\n  fn(input: String) {\n    use #(_, rest) <- result.then(ident(\"false\")(input))\n    Ok(#(Bol(val: False), rest))\n  }\n}\n\nfn null_parser() -> Parser(Node) {\n  fn(input: String) {\n    use #(_, rest) <- result.then(ident(\"null\")(input))\n    Ok(#(Nul, rest))\n  }\n}\n\nfn string_key_parser() -> Parser(String) {\n  fn(input: String) {\n    use #(_, rest) <- result.then(char(\"\\\"\")(input))\n    case rest |> string.split_once(\"\\\"\") {\n      Ok(#(val, rest)) -> Ok(#(val, rest))\n      Error(_) -> Error(\"unexpected token \" <> input)\n    }\n  }\n}\n\nfn string_parser() -> Parser(Node) {\n  fn(input: String) {\n    use #(_, rest) <- result.then(char(\"\\\"\")(input))\n    case rest |> string.split_once(\"\\\"\") {\n      Ok(#(val, rest)) -> Ok(#(Str(val: val), rest))\n      Error(_) -> Error(\"unexpected token \" <> input)\n    }\n  }\n}\n\nfn go_for_seq_by(\n  p: Parser(a),\n  sep: Parser(b),\n  acc: List(a),\n  input: String,\n) -> #(List(a), String) {\n  case p(input) {\n    Ok(#(val, rest)) ->\n      case sep(rest) {\n        Ok(#(_, rest)) -> go_for_seq_by(p, sep, acc |> list.append([val]), rest)\n        Error(_) -> #(acc |> list.append([val]), rest)\n      }\n    Error(_) -> #(acc, input)\n  }\n}\n\nfn seq_by(p: Parser(a), sep: Parser(b)) -> Parser(List(a)) {\n  fn(input: String) { Ok(go_for_seq_by(p, sep, [], input)) }\n}\n\nfn array_parser() -> Parser(Node) {\n  fn(input: String) {\n    use #(_, input) <- result.then(char(\"[\")(input))\n    let input = input |> string.trim\n    use #(val, input) <- result.then(seq_by(\n      json_parser(),\n      char(\",\") |> chain(whitespace()),\n    )(input))\n    let input = input |> string.trim\n    use #(_, input) <- result.then(char(\"]\")(input))\n    Ok(#(Arr(val), input))\n  }\n}\n\nfn pair_parser() -> Parser(#(String, Node)) {\n  fn(input: String) {\n    let input = input |> string.trim\n    use #(key, input) <- result.then(string_key_parser()(input))\n    let input = input |> string.trim\n    use #(_, input) <- result.then(char(\":\")(input))\n    let input = input |> string.trim\n    use #(val, input) <- result.then(json_parser()(input))\n    let input = input |> string.trim\n    Ok(#(#(key, val), input))\n  }\n}\n\nfn object_parser() -> Parser(Node) {\n  fn(input: String) {\n    use #(_, input) <- result.then(char(\"{\")(input))\n    let input = input |> string.trim\n    use #(val, input) <- result.then(seq_by(\n      pair_parser(),\n      char(\",\") |> chain(whitespace()),\n    )(input))\n    let input = input |> string.trim\n    use #(_, input) <- result.then(char(\"}\")(input))\n    Ok(#(Obj(dict.from_list(val)), input))\n  }\n}\n\nfn json_parser() -> Parser(Node) {\n  fn(input: String) {\n    case input |> string.trim {\n      \"t\" <> _ -> true_parser()(input)\n      \"f\" <> _ -> false_parser()(input)\n      \"n\" <> _ -> null_parser()(input)\n      \"\\\"\" <> _ -> string_parser()(input)\n      \"[\" <> _ -> array_parser()(input)\n      \"{\" <> _ -> object_parser()(input)\n      x -> Error(\"unexpected token \" <> x)\n    }\n  }\n}\n\nfn parse_json(input: String) -> Result(Node, String) {\n  case json_parser()(input |> string.trim) {\n    Ok(#(node, rest)) -> {\n      case rest {\n        \"\" -> Ok(node)\n        _ -> Error(\"unexpected token \" <> rest)\n      }\n    }\n    Error(err) -> Error(err)\n  }\n}\n\npub fn main() {\n  let _ = io.debug(parse_json(\"null\"))\n  let _ = io.debug(parse_json(\"true\"))\n  let _ = io.debug(parse_json(\"false\"))\n  let _ = io.debug(parse_json(\"\\\"wwww\\\"\"))\n  let _ = io.debug(parse_json(\"{}\"))\n  let _ = io.debug(parse_json(\"{\\\"a\\\": true, \\\"b\\\": [true, false, null]}\"))\n  let _ = io.debug(parse_json(\"[ true, false, null, \\\"abcd\\\" ]\"))\n\n  io.debug(\"done\")\n}\n\n为什么 Gleam 这样写就凌乱不堪？因为核心观念，即函数可以自由地组合，在这里没有得到很好的体现。还是以一种描述过程的写法去写函数式，自然会如此。"},{"type":"post","id":"sml-intro","title":"Standard ML 尝旧","url":"/blog/sml-intro/","content":"Standard ML（SML），是一个函数式、指令式、模块化的通用的编程语言，具有编译时间类型检查和类型推论。它流行于编译器作者和编程语言研究者和自动定理证明研究者之中。\n虽然这玩意是 1983 年的老登了，但是还能看到许多比较现代的东西——不得不感叹 PL 与工程语言的割裂。1972 年 C 语言被发明，1973 年 ML 被发明，一边是 void* 满天飞的弱类型语言，一边已经是用了 Hindley-Milner 类型推论的 sound 的语言了。\n总而言之读了一下 Programing in Standard ML (又是你啊， Robert Harper) ，写写对 Standard ML 的主观感受\n\n美观性\nsound 的语言千篇一律， beautiful 的语言万里挑一\n不知为什么我觉得 Standard ML 比 OCaml 还好看……可能是法国人有点极端了，比如 OCaml 一个败好感的点是独树一帜的用分号 ; 分割 List，因为 [1,2,3] 会被解释成 (int * int * int) list = [(1, 2, 3)]，可能是为了让语言更没有歧义吧。\n让我们用一个经典的 时间复杂度超级烂的 fibonacci 数计算引入，它在 Standard ML 下能写成\nfun fib 0 = 1\n  | fib 1 = 1\n  | fib n = fib (n - 1) + fib (n - 2)\n\nfun main () = let\n  val n = 10\n  val result = fib n\nin\n  print (\"Fibonacci of \" ^ Int.toString n ^ \" is \" ^ Int.toString result ^ \"\\n\")\nend\n\nval _ = main ()\n我个人有点喜爱 fun 这个关键字，因为这个关键词看上去比较 fun（？\nStandard ML 的函数书写有股比较早的风味，可以看到，经常是在函数里我们会有 let in expression，把所有要用到的变量放在视觉前面，最后用一个 expression 解决问题，让人~~~不禁想起 K&R Style C~~，考虑到 Standard ML 是 1983 年的老东西了，可能真有一点相似之处\n相比于 OCaml 的完全等价的代码：\nlet rec fib = function\n  | 0 -> 1\n  | 1 -> 1\n  | n -> fib (n - 1) + fib (n - 2)\n\nlet main =\n  let n = 10 in\n  let result = fib n in\n  print_endline (\"Fibonacci of \" ^ Int.to_string n ^ \" is \" ^ Int.to_string result ^ \"\\n\")\n感觉还是比 OCaml 的略微好看一些。虽然 OCaml 不区分函数与变量，全部用 let 定义做法要更显现出函数和变量其实是一致的要更优雅一些，但是我还是会觉得用 fun 提示词更加容易让人能分析代码。\n当然都没有 Haskell 好看\n结构严谨\n其实一开始以为 ML 系语言是用缩进区分 block 的，仔细看才发现不对，ML 是缩进不敏感的…… （更喜欢了）\n所以之前的 OCaml 代码完全可以压缩到一行：\nlet rec fib = function|0->1|1->1|n->fib(n-1)+fib(n-2)let main=let n=10 in let result=fib n in print_endline(\"Fibonacci of \"^Int.to_string n^\" is \"^Int.to_string result^\"\\n\")\n惭愧的是之前一直以为要么用大括号区分块，要么用缩进，直到和 GPT 抱怨的时候才突然发现 ML 系是靠关键字自动划分 block 的，做到了虽然没有大括号，但是比缩进方便修改、比大括号好看的效果\n异常\n我不太喜欢的东西。\nStandard ML 诞生的年代还没有给异常 typing 的足够的理论支持，所以 Standard ML 也采用了无法被写进类型声明的异常机制。\n当然异常机制是可以的，毕竟一些东西其实没办法用 Result<T, E> 表达，比如用户按下 Ctrl-C 这样的时间造成的中断，用 Exception 是很自然的，但用 Result 就很坏\n但是用它来做错误处理还是有点太容易漏了，不够严格，尤其是明明 ML 系有 'a option 这样的东西，为什么要写 hd : 'a list -> 'a 这样的东西啊啊，只能说大概是时代局限性了\nML 特色的 'a\n还有说到这个 'a 我就不得不给吐槽我第一次知道原来 'a 发音是 α …… 这对吗这呃不对吧，为了不加入 unicode 支持你选择用 'a 'b 'c 这样别扭的东西表达 α β γ 吗那很坏了\n类型构造器用和函数一样的方式优点非常多，但是 ML 不知道为什么就选择了很抽象的逆序类型类，比如 'a list 是 idris 的 List a，可能当时发明的时候人们觉得这样 int list 念起来顺畅？问题是 List Int 也能念成 List of int 啊，感觉这也是个设计失误吧大概"},{"type":"post","id":"suisuinian","title":"碎碎念","url":"/blog/suisuinian/","content":"\n\n本来不想在博客写这些的，不过算了写写吧。\n\n\n此博客已被加密，请输入密码以查看：\n \n密码\n\n检查\n\n\n骗你的没有密码，打开 HTML 就能看到了。\n骗你的我也没写，所以你还是看不到。\n\n\n时至如今还是会为性别压迫感到政治性抑郁。\n无论是我变成了所谓的极端女权还好，还是其实是整个社会烂的没救了一个正常的人类就会被打成极端女权。我真希望是前者至少这只会是我一个人的悲剧。\n不支持女性主义的人不会成为我的朋友。即使是以前是，未来也未必是了。\n"},{"type":"post","id":"pfpl-note-8","title":"PFPL 笔记 - VII Subtyping","url":"/blog/pfpl-note-8/","content":"笔记 8 子类型\n\nSubtyping\n子类型是大家用的很多的东西，简单来说，里氏替换原则 如果 τ₁ <: τ 则 任何需要 τ 类型的地方都可能在任何时候被 provide 一个 τ₁ 的值\n子类型是一个 pre-order. 显然不是一个 total order. 但是为什么不是一个 partial order?\n（可能是因为存在 class T1 < T {} 这种东西，在 norminal type 的情况下二者不等但是理论上可以互相替换吧，我们这章节似乎没有对 eq 做一个很好的定义）\n比如 int <: rat <: real\nProd and Sum type\n\n这里看上去 prod type 是“逆变”的而 sum type 是“协变” 的，为什么？（虽然我不觉得在这里下标集合算逆变/协变性）\n因为 sum type 是只有其中的某一个，那么大的下标集合会包含小的那个下标集合的所有可能取值，所以小的 I 产生的是大的 J 产生的子类型\nprod type 是包含所有的，那么大的集合会包含小的那个集合的所有信息，所以大的集合是小集合的子类型\n（很难不吐槽一下子类型是十分复杂的东西）\n\n这是当类型的分量是子类型的时候的子类型关系，可以看出这显然是协变的，很符合直觉\nFunction Type\n函数类型的子类型的两条基本规则比较显然，我们以 Nat 和 Int 为例子\n假如有 f : Int -> Int ，考虑将定义域缩小， f': Nat -> Int ，注意到 f'(-1) 没有定义，所以 f' 并不 <: f\n考虑将定义域扩大， f': Real -> Int ，注意到 f' 对所有 f 可接受的输入产生合适的输出，所以 f' <: f\nInt <: Real，同时 Real -> Int <: Int -> Int\n同理，将值域扩大和缩小也能推出类似的规则，综上所述， function type 在定义域上逆变，在值域上协变。\n\nQuantified Type\n\n这两条规则都比较直白，很好看懂\n\n这两条关系要抽象很多，而且 23.11 作者还写错了呃呃，第二个 \\tau' 应该是 \\tau\n总而言之，首先让我们看看 universal type 的 contravariant 性质，让我们写一坨 ts 代码方便理解：\ntype A = { a: number };\ntype B = { b: string };\n\n// 注意 typescript 是 structural type，可以认为这里自带一个 forall\n// ∀ t : A, t -> A | undefined\nfunction id_a(a: A): A | undefined {\n  return a;\n}\n\n// ∀ t : A | B, t -> A | undefined\nfunction id_a_or_b(a: A | B): A | undefined {\n  return undefined;\n}\n\n// ∀ t : A & B, t -> A | undefined\nfunction id_a_and_b(a: A & B): A | undefined {\n  return a;\n}\n\n// A is a subtype of A | B\n// A & B is a subtype of A\n// so id_a_or_b is a subtype of id_a\n// and id_a is a subtype of id_a_and_b\n\n// universal quantification is contravariant\nfunction test(fn: typeof id_a) {}\n\ntest(id_a); // ok\ntest(id_a_or_b); // ok\ntest(id_a_and_b); // error\n// 类型“(a: A & B) => A | undefined”的参数不能赋给类型“(a: A) => A | undefined”的参数。\n//   参数“a”和“a” 的类型不兼容。\n//     不能将类型“A”分配给类型“A & B”。\n//       类型 \"A\" 中缺少属性 \"b\"，但类型 \"B\" 中需要该属性。ts(2345)\n存在类型的协变性质可以用它的 universal type 表示法解释，\n因为 ∃ t . τ == ∀ u . (∀ t . τ → u) → u\n所以两次逆变（ ∀ t . τ → u 的 t 逆变一次，它作为 → 的定义域逆变一次 ），我们可以知道 extensial type 是协变的\nSingleton Kinds\n其实我没很明白这里的 Singleton 和 design patterns 的 singleton 有什么关系。或许它的意义是一个集合中只有一个元素吧。\nSingleton Kind： 我们可以把所有和 \\tau 相等的东西记做 S(\\tau)\nSubkinding: \\kappa_1 :<: \\kappa_2\n我们现在在这里就给 type 配备了一个相等性 \\equiv\n\\dfrac{\\Delta \\vdash c :: S(d)}\n{\\Delta \\vdash c \\equiv d :: \\text{Type}}\n详细规则见\n\nDependent Kinds\nhigher kinds 可以表达一个 T \\to S(int) 这样的东西，接受一个类型返回一个类型的构造子\n但没法非常 exactly 地表达 id: T \\to T 或者 HP: T \\to T \\times T\n（应该说）\nid : a -> a\n这样的东西的准确的性质，因为没法表达出这些 T 相同。你确实能构造出一个 id 来但没法表达出它是 id 的那个相等的性质。\n（也就是说，直接用 universal type 的表达力不够）\n引入 dependent kinds，\n\n为什么要用 \\sum 表示 prod，用 \\prod 表示 arrow 呢？这确实有点呃抽象。但写都这么写了也就这样吧。\n或许我们能从信息论的角度去理解，(a, b) 的信息实际上是两个东西信息的和 a + b 而 a \\to b 的信息量实际上是 a \\times b （列表就知道）\n（同学观点：实际上是 dependent sum 和 dependent prod：）\n考虑一个 \\sum 它实际上给定了第一个参数 第二个就被确定了 这实际上是 sum 的性质，虽然有很多种可能性但是给定了第一个只能唯一的是第二个\n\n有了这个 dependent kinds 我们就能表达出像上面这样的函数的类型，它接受一个 pair 返回它们的交换（和下面这个差不多）\nswap_pair : a × b → b × a\nHigher Singletons\n我们 require c :: T 来构造 S(c) 所以现在我们引入 higher kinds 来让 S(c::\\kappa) 也能 equivalent to c\n\n24.13b 和 24.13c 是两条分配律\ndependent kind 的一个实际应用可以用 TypeScript 举例子：\ntype Shape = \"circle\" | \"square\";\ntype CircleConfig = { radius: number };\ntype SquareConfig = { sideLength: number };\ntype Config<S extends Shape> = S extends \"circle\"\n  ? CircleConfig\n  : S extends \"square\"\n  ? SquareConfig\n  : never;\n\nfunction createShape<S extends Shape>(shapeType: S, config: Config<S>): void {\n  // ....\n}\n\ncreateShape(\"circle\", { radius: 10 });\ncreateShape(\"square\", { sideLength: 5 });\ncreateShape(\"circle\", { sideLength: 5 }); // fail~~~~"},{"type":"post","id":"algebraic-effect","title":"简单接触 Algebraic Effects","url":"/blog/algebraic-effect/","content":"TL;DR：简而言之，代数效应是一种机制，允许在不破坏函数式编程纯度的前提下，更加结构化和组合化地处理副作用。\n\n引入\n本学期的 Rust 课程项目大作业是写一个 git。总而言之，Git 有一个对象存储系统，允许将 Tree 和 Blob 和 Commit 作为三种不同的 Object 存储在 .git/objects/[object hash] 这个文件中。\n作为一个浸淫于实践需求中的人，你很容易看出来，git 项目的几乎所有东西都依赖实现计算好的 .git 文件夹的位置，所以我们可以抽象一个数据类型\npub struct Repository {\n    /// .git dir for the repository\n    pub root: PathBuf,\n}\n这很好。然后你发现，我们需要带着这个 Repository 的引用（指针）到处跑，所有需要从磁盘中读取和保存的场景我们全都需要 Repository 提供的 root 路径。一个不太熟练（ 不太被腌入味了 ）的人可能会写出\nimpl Object {\n    fn save(self, repo: Repository) -> io::Result<()> { ... }\n    fn load(repo: Repository) -> io::Result<Self> { ... }\n}\n这当然好！……但是有没有可能，到处都要显式传递 repo 这件事显得很繁琐很增加键盘输入量呢？\n所以你脑袋一拍，我们构造一个数据结构吧，\npub struct WithRepo<'r, T> {\n    pub repo: &'r Repository,\n    inner: T,\n}\n\nimpl<'r, T> WithRepo<'r, T> {\n    pub fn new(repo: &'r Repository, inner: T) -> Self {\n        WithRepo { repo, inner }\n    }\n\n    /// Wrap the storeable object with the repository path\n    pub fn wrap<To>(&self, inner: To) -> WithRepo<'r, To> {\n        WithRepo {\n            repo: self.repo,\n            inner,\n        }\n    }\n\n    /// unpack self, and get the inner object\n    pub fn unwrap(self) -> T {\n        self.inner\n    }\n\n    /// A `WithRepo<T>` is actually a functor, you can apply a T -> U function to `WithRepo<T>` to get` WithRepo<U>` by mapping it.\n    pub fn map<F, U>(self, f: F) -> WithRepo<'r, U>\n    where\n        F: FnOnce(T) -> U,\n    {\n        WithRepo {\n            repo: self.repo,\n            inner: f(self.inner),\n        }\n    }\n}\nWithRepo 是一个 Functor，它有一个 map 方法，在 Haskell 里是 fmap ，用来把一个 a -> b 的函数 apply 到 WithRepo<a> 上得到一个 WithRepo<b>\n现在好多了，我们可以直接在 WithRepo<Object> 之类的东西上做文章，Repository 的指针在被创建的时候被包了进去作为依赖。我们可以写出这样优雅的代码：\nlet repo = Repository::load()?;\n\n// stage: WithRepo<'_, MutableTree>\nlet mut stage = repo.stage()?.into_muter();\n\nfor path in &self.paths {\n    let path = env::current_dir()?.join(path);\n    stage.add_path(&path)?;\n}\n\n/// impl<'a> WithRepo<'a, MutableTree> pub fn freeze(self) -> WithRepo<'a, Tree>\nstage.freeze().map(Stage).save()?;\nrepo 这个参数只在最开始被使用，之后的 stage 以及 WithRepo<'a, MutableTree> 这个东西的所有内部用到的东西都很自然地被提供了 repo 这个上下文，因此 save 不需要额外的参数指明 .git 所在文件夹的路径，直观而优雅。\n问题出在 add_path 里面。add_path 在文件系统中找到路径，测试它是文件还是文件夹，如果是文件把它读取并存储为 Blob，如果是文件夹把它 dump 成一个 Tree 并存储。\n这是我们的代码。\npub fn add_file(&mut self, path: &Path) -> io::Result<&mut Self> {\n    let filename = path\n        .file_name()\n        .ok_or(io::Error::new(\n            io::ErrorKind::InvalidInput,\n            format!(\"file name is invalid: {}\", path.display()),\n        ))?\n        .to_string_lossy();\n\n    self.debug_util(path, \"Adding file\")?;\n    let ctnt = fs::read(path)?;\n    let blob = Object::Blob(\n        String::from_utf8(ctnt)\n            .map(|str| str.into())\n            .unwrap_or_else(|e| e.into_bytes().into()),\n    );\n\n    let blob = self.wrap(blob);\n\n    if self.save_object {\n        blob.save()?;\n    }\n\n    let line = TreeLine {\n        kind: TreeLineKind::File,\n        name: filename.to_string(),\n        sha1: blob.sha1().into(),\n    };\n\n    self.data.insert(filename.to_string(), line);\n\n    Ok(self)\n}\n问题所在是什么呢？它很难测试。当然你可以直接 fs::tmp_dir() 直接在系统里创一个临时文件夹，然后灌一些临时文件进去，但是这当然不够优雅。更何况，副作用 不止有 文件 IO 一种。还有控制台 IO。如果你要测试 git commit 这个命令，希望它产生一个正确的屏幕输出，怎么做到？只能将 println! 又换成自己的宏，也做参数传进去，为了保持完美的可测试性和可组合性，久而久之你的函数可能会变成这样：\nimpl GitAdd for WithRepo<WithFs<WithConsole<WithService1<WithService2<.....>>>>>\n这完全就是地狱……于是人们发明了 DI ： 依赖注入\n但我们这里不是讲依赖注入，所以请看代数效应\nEffect，Side Effect\n要讲 Algebraic Effect 让我们先讲讲 Haskell 的 IO Monad。写过 Haskell 的人都知道，Haskell 里面的 putStrLn 是\nputStrLn :: String -> IO ()\n你会注意到一个看上去很像 Rust 的 io::Result 的 Monad，也就是 IO。但 Haskell 与 Rust 不一样的一个地方是，IO Monad 并不是“保存”了执行结果，而是“说明”了执行顺序。在 Rust 中，如果你写一个 fs::write(...) 得到了一个 io::Result<T>，这个副作用真的已经被执行了，返回的只是成功与否；而 Haskell 中返回的是这个副作用本身。它可能在未来的某一个被某个 IO a -> a 的东西执行，这时候才真正执行了副作用；但在此之前它只是一个顺序。\n对于一个完全没有什么函数式经验的人来说这句话可能很难理解。让我们引用一下 https://zhuanlan.zhihu.com/p/1892390136857228808 Haskell：优秀的过程式语言\n\n副作用作为一等公民 (first class values)\n在 Haskell 中，有副作用的计算被当作一等值。这意味着我们可以将它们存储在变量或数据结构中以备后用。有一个 Haskell 函数：\nrandomRIO :: (Int, Int) -> IO Int\n当传入两个整数作为参数时，它会在这两个数之间随机选出一个整数。我们可以将对这个函数的调用放入一个列表中，像这样：\nsome_dice = [ randomRIO(1, 6), randomRIO(1, 6) ]\n这是一个包含两次对 randomRIO 调用的列表。令非 Haskell 程序员感到惊讶的是，当这个列表被创建时，并不会生成任何随机数。来自其他编程语言的我们习惯于副作用（如随机生成）在调用带有副作用的函数时立即执行。[6]\n我们可以在列表中加入更多的随机生成操作：\nmore_dice = some_dice <> [ randomRIO(1, 6) ]\n依然不会生成随机数。我们可以任意操作这个列表，依旧不会生成随机数。\n需要明确的是，randomRIO 函数确实可能会被调用[7]。而当它被调用时，它返回的值类型是 IO Int。只不过这个值并不是一个整数。如果要说的话，我们可以把它看作是一组最终能获得整数的指令。它并非实际的整数，而是一个封装了副作用的对象。当这个副作用对象执行时，会产生一个随机整数，但这个对象本身仅仅描述了计算过程，并不是一个整数。\n换句话说，在 Haskell 中，仅仅调用一个带有副作用的函数是不足以执行其副作用的。当我们调用一个带副作用的函数时，它产生了一个封装了副作用的对象，这个对象可以在未来某个时刻被执行，从而产生副作用的结果[8]。\n\n如果它难以理解，不妨想象一下你在写一个前端项目。—— 是的，Promise 也（几乎）是一个 Monad。关于 Monad 是什么，可以看看我的 这篇文章\nPromise 和 IO 的共同点是，它们都封装了一个执行顺序。有经验的前端开发者一眼就看得出来\nfetch(\"https://example.com/example-api\")\n  .then((res) => res.json())\n  .then((res) => {\n    balabala(res);\n    dosomething(res);\n    return fetch(foo(res));\n  })\n  .then((res) => {\n    bar(res);\n  });\nPromise 提供了一套很好的接口，允许我们顺序地写出一些先后发生的事情，而无需关心回调的细节。在这里，所有的 .then 函数都不是马上执行的：它们只有在前一个 Promise fulfilled 的时候才会被自动地回调。因此，你可能会看到这样的代码：\nfunction runDecorateResult(promise) {\n  return promise.then((res) => foo(res)).then((res) => bar(res));\n}\n\nconst decorated = await runDecorateResult(\n  sendSomeApi().then((res) => baz(res))\n);\n这里，sendSomeApi().then((res) => baz(res)) 创建了一个顺序，先 sendSomeApi，再基于结果 baz。然后 runDecorateResult 又进一步的在顺序上而非结果上添加了新的顺序，先 foo 再 bar。这些与值无关，JS 引擎和 Promise 内部跑的循环将会执行这个顺序。\n或者我们这样说：then 允许我们把顺序组合起来，交给某个特定的无关的执行者。\nAlgebraic Effect\n理解了 Monad 如何组合副作用之后，我们就可以理解 Algebraic Effect 了。\n代数效应的核心思想是：我们可以把副作用进行传递和组合。让我们考察几种最常见的效应：\n\ntotal: 没有任何效应对应数学意义上的全函数，总是能给定相同输入返回一个相同输出。\nexception: （后面在 Koka 中叫 exn） 可能抛出异常\ndiv: 可能不停机，也就是发散 （divergence）\nndet: 非决定性的函数，比如 random，对于相同输入可能返回多个不同的值\nio: 这是最差的效应，这意味着程序可以引发异常、不终止、非确定性、读取和写入堆以及执行任何输入/输出作用。\n\nexn 和 div 的组合是 pure，直接对应于 Haskell 的纯度概念。一个函数可能具有多个效应。比如如下 Koka 代码：\n// combine-effects: forall<a> () -> <pure,ndet> a\nfun combine-effects()\n  val i = srandom-int() // non-deterministic\n  throw(\"oops\")         // exception raising\n  combine-effects()     // and non-terminating\n分配给 combine-effects 的效应是 ndet、div 和 exn。\nalgebraic effects 的做法是，我们把副作用抽象为 操作符（operations） 和 处理器（handlers） 两部分。以最经典的一种 effect 也就是异常为例：\neffect raise\n  ctl raise( msg : string ) : a\n这定义了一个 effect 类型 raise 和一个 (msg : string) -> raise a 类型的 operation raise。声明 effect 的签名后，我们已经可以使用这些 operations 了：\nfun safe-divide( x : int, y : int ) : raise int\n  if y==0 then raise(\"div-by-zero\") else x / y\n其中我们看到 safe-divide 函数获得了 raise 效应（因为我们在函数体内使用了 raise 操作符）。这样的效应类型意味着我们只能在处理 raise 的上下文中 evaluate 这个函数（换句话说，它是 “动态绑定”的，或者我们 “具有 raise 能力”） 的上下文。\n我们可以通过为 raise 给出具体定义来处理这种效果。例如，我们可能总是返回一个默认值：\nfun raise-const() : int\n  with handler\n    ctl raise(msg) 42 // 哦，宇宙的终极答案是 42\n  8 + safe-divide(1,0)\n\n// 返回 42 而不是 50\n调用 raise-const() 的计算结果为 42，不是 50。当调用 raise 时（在 safe-divide 中），它将 yield 于其最内层的 handler，展开堆栈，然后才 evaluate 操作符的定义 – 这个例子中，只是从定义 handler 的点直接返回 42。现在我们可以看到为什么它被称为 ctl operator （控制操作符），因为 raise 改变了常规的线性控制流，并从原始调用点直接 yield 到其最内层的处理程序。还要注意 raise-const 现在又是一个 total function 了，handler 抵消了 raise 的效果。\n看到 effect 的写法后，我觉得你应该大体就能理解代数效应解决了什么了。\n\n作者：Malcolm Yu\n链接：https://www.zhihu.com/question/300095154/answer/1744221759\n来源：知乎\n假如我们有这样一段代码，其主要目的是进行一大段精妙的运算：\nasync function biz(id) {\n  const infoId = /* do some calc */ id; // 这里可以理解为是一大段计算逻辑\n  const info = await getInfo(infoId); // 副作用，与 server 通信\n  const dataId = /* do some calc */ info.dataId; // 这里可以理解为是一大段计算逻辑\n  const data = getData(dataId); // 副作用，非幂等操作\n  return /* do some calc */ data.finalCalcData; // 这里可以理解为是一大段计算逻辑\n}\n尽管运算逻辑很优美，但美中不足的是有两段副作用，导致它不能成为一个干净的纯函数被单元测试。而且这里会导致严重的逻辑耦合：『做什么』与『怎么做』没有拆的很干净：\n\n你的一大段计算逻辑是在处理「做什么」；\n两个副作用更关心「怎么做」：比如线上是接口调用，单测里是 mock 数据直接怼；\n但是由于这两块副作用代码，导致整个糅杂的逻辑都无法复用。\n\n看到这里你可能会一拍大腿：函数在 JS 里不是一等公民嘛，我直接把两个副作用传进来不就行了？\nasync function biz(id, getInfo, getData) {\n  const infoId = /* do some calc */ id; // 这里可以理解为是一大段计算逻辑\n  const info = await getInfo(infoId); // 副作用，与 server 通信\n  const dataId = /* do some calc */ info.dataId; // 这里可以理解为是一大段计算逻辑\n  const data = getData(dataId); // 副作用，非幂等操作\n  return /* do some calc */ data.finalCalcData; // 这里可以理解为是一大段计算逻辑\n}\n是的，这样确实可以复用，但还有一个叫函数染色的问题没有解决：明明是一大段干净的同步运算逻辑，因为 getInfo 是异步的，导致整个函数都得加个 async。而且很有可能在我单元测试里，这个 getInfo 是直接同步取内存数据，还得因此弄个 Promise……\n\n没错，代数效应就能非常简单的解决这个问题。比如这个 biz，我们把它在 Koka 中写成\neffect useInfoData\n  fun getInfo(id : int) : info\n  fun getData(id : int) : data\n然后我们就可以在 biz 里面使用 getInfo 和 getData 了：\nfun biz(id : int) : useInfoData data\n  val infoId = /* do some calc */ id; // 这里可以理解为是一大段计算逻辑\n  val info = getInfo(infoId); // 副作用，与 server 通信\n  val dataId = /* do some calc */ info.dataId; // 这里可以理解为是一大段计算逻辑\n  val data = getData(dataId); // 副作用，非幂等操作\n  /* do some calc */\n  data.finalCalcData // 这里可以理解为是一大段计算逻辑\n你说 getInfo 是 async 的，那咋了？在代数效应里，这种函数染色可以直接被削去：\nfun production_run_biz(id: int) : data\n  with handler\n    fun getInfo(id)\n      some_async_task(id) fn (res) { resume (res); }\n    fun getData(id)\n      some_sync_task(id)\n  biz(id)\n\nfun test_run_biz(id: int) : data\n  with handler\n    fun getInfo(id)\n      some_sync_test_task(id)\n    fun getData(id)\n      some_sync_test_task(id)\n  biz(id)\n这样，我们复用了一大段精妙的逻辑 biz，而且没有函数染色的问题。我们可以在 production_run_biz 里面使用异步的 getInfo 和 getData，而在 test_run_biz 里面使用同步的 getInfo 和 getData。这就是代数效应的魅力所在。\n代数效应允许我们把副作用抽象成操作符和处理器，允许我们在不改变函数签名的情况下，使用不同的副作用实现。这样，我们就可以在测试中使用不同的副作用实现，而不需要修改函数本身。\n现在回到最初的场景：代数作用如何解决我们之前提到的 WithRepo, fs, console 的问题呢？\n我们可以把 fs 和 console 抽象成代数效应：（下面的代码是伪代码，不是 Koka 真的能运行的程序）\neffect fs\n  fun read(path : string) : bytes\n  fun write(path : string, data : bytes) : unit\n  fun remove(path : string) : unit\n  fun exists(path : string) : bool\n  ....\n\neffect console\n  fun log(msg : string) : unit\n  fun error(msg : string) : unit\n  fun warn(msg : string) : unit\n  fun info(msg : string) : unit\n  ....\n\neffect repo\n  val path : string\n  ...\n\nfun production-fs(action: () -> <fs|e> a) : e a\n  with handler\n    fun read(path) = std.fs.read(path)\n    fun write(path, data) = std.fs.write(path, data)\n    fun remove(path) = std.fs.remove(path)\n    fun exists(path) = std.fs.exists(path)\n    ...\n  action()\n\nfun test-fs(action: () -> <fs|e> a) : e a\n  with handler\n    fun read(path) = test.fs.read(path)\n    fun write(path, data) = test.fs.write(path, data)\n    fun remove(path) = test.fs.remove(path)\n    fun exists(path) = test.fs.exists(path)\n    ...\n  action()\n\nfun production-console(action: () -> <console|e> a) : e a\n  with handler\n    fun log(msg) = std.console.log(msg)\n    fun error(msg) = std.console.error(msg)\n    fun warn(msg) = std.console.warn(msg)\n    fun info(msg) = std.console.info(msg)\n    ...\n  action()\n\nfun test-console(action: () -> <console|e> a) : e a\n  with handler\n    fun log(msg) = test.console.log(msg)\n    fun error(msg) = test.console.error(msg)\n    fun warn(msg) = test.console.warn(msg)\n    fun info(msg) = test\n    ...\n  action()\n\n\n...\n\n最终我们可以非常自然地组合出我们真正需要的 git_add 函数：\n\nfun some_perfect_git_add_logic(files: List<string>) -> fs (console (repo unit))\n  var stage := repo.stage()\n  ....\n  stage.save()\n\nfun git_add()\n  with production-fs\n  with production-console\n  with production-repo\n  some_perfect_git_add_logic()\n\nfun test_git_add()\n  with test-fs\n  with test-console\n  with test-repo\n  some_perfect_git_add_logic()\n同时方便了 production 和 test，也让 git add 的 logic 变得可以充分的复用了起来。"},{"type":"post","id":"cpp-blackmagic-memorize","title":"C++ 黑魔法习题：memorize","url":"/blog/cpp-blackmagic-memorize/","content":"习题来自 https://bartoszmilewski.com/2014/11/24/types-and-functions/\n\n\nDefine a higher-order function (or a function object) memoize in your favorite language. This function takes a pure function f as an argument and returns a function that behaves almost exactly like f, except that it only calls the original function once for every argument, stores the result internally, and subsequently returns this stored result every time it’s called with the same argument. You can tell the memoized function from the original by watching its performance. For instance, try to memoize a function that takes a long time to evaluate. You’ll have to wait for the result the first time you call it, but on subsequent calls, with the same argument, you should get the result immediately.\n\n（当然 C++ 不是我最喜欢的语言，但是确实是很有挑战性的一个，所以这样写了）\n#include <chrono>\n#include <concepts>\n#include <functional>\n#include <iostream>\n#include <tuple>\n#include <type_traits>\n#include <unordered_map>\n#include <utility>\n\ntemplate <typename T, typename = std::void_t<>>\nstruct is_std_hashable : std::false_type {};\n\ntemplate <typename T>\nstruct is_std_hashable<\n    T, std::void_t<decltype(std::declval<std::hash<T>>()(std::declval<T>()))>>\n    : std::true_type {};\n\ntemplate <typename T>\nconstexpr bool is_std_hashable_v = is_std_hashable<T>::value;\n\ntemplate <typename... Args>\n  requires std::equality_comparable<std::tuple<Args...>>\nstruct Arguments {\n  std::tuple<Args...> data;\n  bool operator==(const Arguments &other) const = default;\n};\n\ntemplate <typename R, typename... Args> using fn_type = R(Args...);\ntemplate <typename R, typename... Args> auto memorize(fn_type<R, Args...> f) {\n  auto cache = std::unordered_map<Arguments<Args...>, R>();\n\n  return [=](Args... args) mutable -> R {\n    auto key = Arguments{std::make_tuple(args...)};\n    if (cache.find(key) == cache.end()) {\n      auto result = f(args...);\n      cache[key] = result;\n      return result;\n    }\n    return cache[key];\n  };\n}\n\ntemplate <typename R, typename... Args>\nauto memorize(std::function<R(Args...)> &&f) {\n  auto cache = std::unordered_map<Arguments<Args...>, R>();\n\n  return [=](Args... args) mutable -> R {\n    auto key = Arguments{std::make_tuple(args...)};\n    if (cache.find(key) == cache.end()) {\n      auto result = f(args...);\n      cache[key] = result;\n      return result;\n    }\n    return cache[key];\n  };\n}\n\ntemplate <typename... Args> class std::hash<Arguments<Args...>> {\n  template <size_t I>\n    requires(I == std::tuple_size_v<std::tuple<Args...>>)\n  size_t hasher_recusive(const std::tuple<Args...> &) const {\n    return 0;\n  }\n\n  template <size_t I>\n    requires(I < std::tuple_size_v<std::tuple<Args...>>)\n  size_t hasher_recusive(const std::tuple<Args...> &t) const {\n    using the_tuple = std::tuple<Args...>;\n    using the_element = std::tuple_element_t<I, the_tuple>;\n    static_assert(is_std_hashable_v<the_element>,\n                  \"the element is not std::hash-able\");\n    return std::hash<the_element>{}(std::get<I>(t)) ^ hasher_recusive<I + 1>(t);\n  }\n\npublic:\n  size_t operator()(const Arguments<Args...> &t) const {\n    return hasher_recusive<0>(t.data);\n  }\n};\n\nlong long fib(long long n) {\n  if (n <= 1)\n    return n;\n  return fib(n - 1) + fib(n - 2);\n}\n\n// struct NotHashable {\n//   constexpr bool operator==(const NotHashable &) const { return true; }\n// };\n// int foo(int x, NotHashable bar) { return 1; }\n\nint main() {\n  auto memoized_fib = memorize(fib);\n  // auto memoized_foo = memorize(foo);\n  for (int i = 0; i < 100; ++i) {\n    auto t0 = std::chrono::system_clock::now();\n    std::cout << \"calculating fib(\" << 30 << \") = \";\n    std::cout << memoized_fib(30) << \" \";\n    auto t1 = std::chrono::system_clock::now();\n    auto duration =\n        std::chrono::duration_cast<std::chrono::microseconds>(t1 - t0);\n    std::cout << \" took \" << duration.count() << \" microseconds\" << std::endl;\n  }\n\n  int n = 30;\n  auto memoized_lamfib = memorize(std::function([=]() { return fib(n); }));\n  // auto memoized_foo = memorize(foo);\n  for (int i = 0; i < 100; ++i) {\n    auto t0 = std::chrono::system_clock::now();\n    std::cout << \"calculating fib2(\" << 30 << \") = \";\n    std::cout << memoized_lamfib() << \" \";\n    auto t1 = std::chrono::system_clock::now();\n    auto duration =\n        std::chrono::duration_cast<std::chrono::microseconds>(t1 - t0);\n    std::cout << \" took \" << duration.count() << \" microseconds\" << std::endl;\n  }\n  return 0;\n}"},{"type":"post","id":"idris2-test","title":"试试 idris2","url":"/blog/idris2-test/","content":"唉早知道就不折腾这种全世界都找不出一万个人在用的东西了.txt\n\n先写简介吧\n\n大体上看, Idris 这个语言的设计, 基本上是 Haskell 的延续, 整体上语法和 Haskell 十分接近, Haskell 程序员用起来基本上只会更爽, 不太会有什么不适 (除了不是默认 Lazy 这一点需要适应之外).\n所以简而言之, Idris 就是带 Dependent Type 的 Haskell, 外加各种语法上的改良, 解决了诸多由 Haskell 所遗留的问题, 是 Haskeller 心目中的理想语言.\n怎么评价 Idris 语言？ - 罗宸的回答 - 知乎 https://www.zhihu.com/question/55342708/answer/156894932\n\n简单来说这是一门给你加了一些很有趣和实用的特性的函数式语言，其实很早就听说过它，但是之前一直被函数式吓退，这几天才折腾\n然后……好吧折腾的结果是白折腾了。\n辛苦的安装\n你们歧视 Windows 是吧？？\nwindows 需要安装 msy2，然后使用 msy2 上的 mingw 来安装，自己下的 winlib 上的 mingw gcc 缺了一些必要的头文件，装不上。这一点就折腾了我半天\n然后安装的时候 chez 默认安装路径带空格，又让我白 make 了一次，爆了一堆 C:/Programs 不是可执行文件……\n费劲终于 build 好了，试图修改一下 make install 的位置发现 idris2 还是按照写死的路径找对应的 support，否则就要配置一堆环境变量，我懒受不了了改回默认安装路径了\n终于 idris2 能启动了，然后又要指定 chez 的路径的环境变量。。。还没有提示，只是简单爆一句 “找不到指定文件” 我操找不到什么文件啊你倒是说啊 😭，花了我十几分钟才想通发生了什么……\n此刻我已经被 idris2 折腾得精疲力竭了，简单跑了个 hello world 发现没问题就放弃了\n怎么又要装 LSP\n（当然啊）\n在写 hello world 的时候发现一点语法高亮都没有，然后意思到又要装 lsp，一看 lsp 是 idris2 写的而且要装 pack，问题是 pack 又只给了 bash 的安装脚本（我操你们真的歧视 Windows 吧\n彻底被磨干了精力，放弃\n放弃\n这 Windows 就是不行啊，要和整个世界作斗争，用 WSL 去了（）"},{"type":"post","id":"traps-of-vue-layouts","title":"vite-plugin-vue-layouts 使用记","url":"/blog/traps-of-vue-layouts/","content":"前言： unplugin-vue-router 是 unplugin 的一款插件，旨在在 src/pages 等目录下使用文件驱动的 routing 来避免手写 vue-router 配置带来的麻烦与潜在的失误，是约定优于配置的一个展现。\nvite-plugin-vue-layouts 是与 unplugin-vue-router 非常般配的一款插件，旨在为 views 指定共享的 layout，在复杂前端工程上或许非常有用。\n二者是 vuetify 前端框架推荐使用的插件。\n然后就被它的【刻意的设计】坑了一把\n\n背景故事：使用上述二插件简单化页面组织\n一个经典的，SPA的前端，以我写下这篇博客时正在编写的阅读器为例，可能有这样的页面：\n\n一个 /tabs 阅读器页面下面包含\n\n/tabs/:bookname 读书页面\n/tabs/new 新标签页\n/tabs/settings 阅读器设置页\n\n\n/ 下的所有页面保持一致的风格，共享 sidebar 和 header footer 等\n\n/books/all 显示全部书库\n/books/user 显示个人书库\n/book/:bookname 显示书本详情\n/profile 显示个人信息\n/topup 充值页面\n\n\n登录系列页面保持一致的风格，但是和 / 不同，因为登录界面需要向用户展示产品亮点\n\n/login 登录\n/register 注册\n/forgot-password 忘记密码\n/confirm 验证邮件\n\n\n\n这里一致的风格不能重复编写代码，于是我们需要手动嵌套路由和编写 layout 文件，\n用传统的 vue-router 编写 router.js 需要配置大量繁复的内容：\nconst routes = [\n  {\n    path: '/tabs',\n    component: TabsLayout,\n    children: [\n      { path: '', redirect: '/tabs/new' },\n      { path: 'new', component: () => import('@/pages/tabs/New.vue') },\n      { path: 'settings', component: () => import('@/pages/tabs/Settings.vue') },\n      { path: ':bookname', component: () => import('@/pages/tabs/Read.vue') }\n    ]\n  },\n  {\n    path: '/',\n    component: MainLayout,\n    children: [\n      {\n        path: \"/books\",\n        component: BooksListLayout,\n        children: [\n          { path: 'all', component: () => import('@/pages/books/All.vue') },\n          { path: 'user', component: () => import('@/pages/books/User.vue') },\n        ],\n      },\n      {\n        path: \"/books\",\n        component: BooksInfoLayout,\n        children: [\n          { path: ':bookname', component: () => import('@/pages/book/Detail.vue') },\n        ],\n      }\n      { path: 'profile', component: () => import('@/pages/Profile.vue') },\n      { path: 'topup', component: () => import('@/pages/TopUp.vue') }\n    ]\n  },\n  {\n    path: '/',\n    component: AuthLayout,\n    children: [\n      { path: 'login', component: () => import('@/pages/auth/Login.vue') },\n      { path: 'register', component: () => import('@/pages/auth/Register.vue') },\n      { path: 'forgot-password', component: () => import('@/pages/auth/ForgotPassword.vue') },\n      { path: 'confirm', component: () => import('@/pages/auth/Confirm.vue') }\n    ]\n  }\n]\n这里我还只写了十几个页面，就已经有了这么繁琐的 vue-router 配置。实际上的大项目页面只会远远地更多，甚至可能达到上百上千个。例如，Misskey 的 router defination 在写下这篇文章的时候就有 597 行，大约 150 个页面，未来只会更多。\n并且，这样一个 router 使用 typescript 的话需要非常复杂的类型体操才能做到根据配置得到 route 的实际类型。比如，在不用任何插件的情况下，你可能不小心 push 一个 /forget-password —— 只有一个 o e 的差别，非常难以发现。这为代码造成了潜在的安全隐患。尤其是大型项目，多人协作的情况下，数百个页面不可能都记得拼写，某次失误便可能把错误的 route 引入。\n这就是 unplugin-vue-router 的方便之处与优势。有了这个插件，我们直接编写这样的文件结构：\nsrc/\n├─ pages/\n│  ├─ tabs/\n│  │  ├─ [bookname].vue\n│  │  ├─ new.vue\n│  │  └─ settings.vue\n│  ├─ tabs.vue\n│  ├─ books/\n│  │  ├─ all.vue\n│  │  └─ user.vue\n│  ├─ books.vue\n│  ├─ book/\n│  │  └─ [bookname].vue\n│  ├─ book.vue\n│  ├─ profile.vue\n│  ├─ topup.vue\n│  ├─ (auth)/\n│  ├─ ├─ login.vue\n│  ├─ ├─ register.vue\n│  ├─ ├─ forgot-password.vue\n│  └─ └─ confirm.vue\n│  └─ (auth).vue\n就能直接自动生成上述的 router defination！不仅如此，它还会全自动地为你生成一个 typed-router.d.ts 之类的文件，自动生成完善的类型检查。它内部可能是\nexport interface RouteNamedMap {\n  \"/[...path]\": RouteRecordInfo<\n    \"/[...path]\",\n    \"/:path(.*)\",\n    { path: ParamValue<true> },\n    { path: ParamValue<false> }\n  >;\n  \"/forget-password\": RouteRecordInfo<\n    \"/forget-password\",\n    \"/forget-password\",\n    Record<never, never>,\n    Record<never, never>\n  >;\n  \"/login\": RouteRecordInfo<\n    \"/login\",\n    \"/login\",\n    Record<never, never>,\n    Record<never, never>\n  >;\n  \"/register\": RouteRecordInfo<\n    \"/register\",\n    \"/register\",\n    Record<never, never>,\n    Record<never, never>\n  >;\n  \"/tabs\": RouteRecordInfo<\n    \"/tabs\",\n    \"/tabs\",\n    Record<never, never>,\n    Record<never, never>\n  >;\n  \"/tabs/new\": RouteRecordInfo<\n    \"/tabs/new\",\n    \"/tabs/new\",\n    Record<never, never>,\n    Record<never, never>\n  >;\n  // ...\n}\n你现在可以放心地\nrouter.push({ name: \"/(auth)/login\" });\n其中 name 是根据路径自动生成的。tsc 会帮你检查类型，确定你的 name 里面不包含 typo 了。\n容易看出，这种文件组织方式好是好，就是显得不太直观。共用一套 layout 的组件必须得放在同一个以括号代表的文件夹下面，给搜索带来了一定程度上的不便。\n这时候就轮到 vite-plugin-vue-layouts 出场了。利用 layout 机制（本质上就是自动创建 nesting routes），我们可以把项目结构简化成\nsrc/\n├─ layouts/\n│  ├─ default.vue         # / 下的所有页面共享\n│  ├─ tabs.vue            # /tabs 下的阅读器页面\n│  └─ auth.vue            # 登录/注册页面\n├─ pages/\n│  ├─ tabs/\n│  │  ├─ [bookname].vue\n│  │  ├─ new.vue\n│  │  └─ settings.vue\n│  ├─ tabs.vue\n│  ├─ books/\n│  │  ├─ all.vue\n│  │  └─ user.vue\n│  ├─ books.vue\n│  ├─ book/\n│  │  └─ [bookname].vue\n│  ├─ book.vue\n│  ├─ profile.vue\n│  ├─ topup.vue\n│  ├─ login.vue\n│  ├─ register.vue\n│  ├─ forgot-password.vue\n│  └─ confirm.vue\n在 layouts 中集中处理那些共性相关的部分，减少使用 nesting\n坑点来了\n细心的人不难注意到我们还是需要 tabs.vue nesting。这是为什么呢？\n因为这个库的作者的品味问题。一个没有自身组件的 route 也会默认得到一个 layout，所以如果你在 tabs/new 里面配置 layout 的话，恭喜你，你会获得这样的嵌套：\n[default [tab]]\n但我们期望的其实是\n[tab]\n糟糕的是，作为一个很 experimental 的库，vite-plugin-vue-layouts 的文档非常语焉不详……我花了几十分钟才在 github 的 issue 上找到这个问题，并看到了作者的答复，\n解决此问题的最简单的方法是创建 tabs.vue 并将布局设置为 false……\n<template>\n  <RouterView />\n</template>\n\n<route lang=\"yaml\">\nmeta:\n  layout: false\n</route>\n非常丑陋。或许这确实是个品味问题……"},{"type":"post","id":"pfpl-note-7","title":"PFPL 笔记 - VI Dynamic Types","url":"/blog/pfpl-note-7/","content":"笔记 7\n\nGirard’s System F\n之前我们讨论的语言都非常地单态，每个表达式都有独立的一个类型，不支持多态。\n这一章讲了通过 System F i.e. polymorphic typed lambda calculus 如何实现多态的。\n引入一种全称类型，∀ t . τ\nΛ t . e 是一个泛型函数，它的类型是一个 ∀ t . τ\n比如\nΛ t . λ (x : t) ↦ x\n是一个 polymorphic identity function 具有类型\n∀ t . t ↦ t\n我们自然的可以把它叫作 unit， 而上面那个函数其实就是 ⟨ ⟩ 它完全就是 null tuple 因为它是这个类型的唯一个元素\n二元组也能被很好的定义，和 Chapter 17 untyped lambda calculus 一样：\nτ₁ × τ₂  ≝ ∀ r . (τ₁ → τ₂ → r) → r\n⟨e₁, e₂⟩ ≝ Λ r . λ (x : τ₁ → τ₂ → r) ↦ x e₁ e₂\ne.l      ≝ e[τ₁] λ (x : τ₁) (y: τ₂) ↦ x\ne.l      ≝ e[τ₂] λ (x : τ₁) (y: τ₂) ↦ y\n容易看出这就是 17 章定义的 pair 加上了泛型类型。\nsum type 也是容易定义的，只需要看出来 sum type 可以看作一个函数链，其中只有一个函数是能被调的\n\n还有自然数。容易把自然数看成对于泛型 t 的\nt -> (t -> t) -> t\n比如\nzero :: t -> (t -> t) -> t\nzero z s = z\nsucc :: nat -> nat\nsucc e z s = s(e z s)\n由此可知， \\mathcal{L}{\\rightarrow \\forall} 至少具有和 \\mathcal{L}{\\text{nat }\\rightarrow} 一样的表达力。事实上，它的表达力更强。\nSystem F 可以表达 Godel’s T 的 evaluate function，但是 Godel’s T 没法表达自己的。当然二者都不是完备的，无法表达自己\n注意到，多态性仅靠类型就能一定程度上推断出行为。例如对于类型 \\forall (t. t \\to t) 因为我们没有任何关于 t 的信息，为了总是能成立，它只能是 identity function \\Lambda (t. \\lambda (x:t) x)\n（题外话：上面的东西很直观，但我没理解如何证明的，但从我之前在知乎上看的东西看，似乎在范畴论里可以证出来 ∀ t → t 只有 ident function？）\n参数化理论意味着，我们能够仅凭程序类型推导出关于程序行为的定理。这类定理有时被称为自由定理，因为它们是类型推导的“免费”结果，无需程序分析或验证即可推导。这些定理支撑了多态语言的卓越体验，即类型良好的程序在执行时往往能按预期运行。也就是说，满足类型检查器是正确性的充分条件。参数化对程序行为的限制非常严格，以至于只有相对较少的同类型程序会表现出非预期的行为，从而排除了编写代码时经常出现的一大类错误\nAbstract Types\nExistential Types\n有了 forall 类型当然就有 exist 类型对吧。\n据说 existential type 在 rust 里的对应是 dyn Trait —— 你不知道具体是什么类型 但是保证了这里存在一个类型 T 满足 Trait. 或者说，存在类型对应一个 trait 而它的一个实例对应一个 impl\n比如\nfn get_animal() -> impl Animal;\n你不知道具体返回的是哪个 animal，可能是 Cat 或者 Dog，但是它保证了会返回一个 Animal，它其实是\nget_animal : () → ∃ (t . ⟨ Animal ⟩ )\n所以\n\n其实 pack 就是构造了一个存在类型\n\\rho 是 e2 的类型其实\nMain idea of data abstracton is to introduce a interface\n抽象类型一个重大的动力是实现一个抽象的接口，客户端不需要关注具体实现，只要二者都满足相同的接口和一个（后面我们会讲得性质（？））\nExistential type 可以用 System F 表示：\n∃ t . τ == ∀ u . (∀ t. τ → u ) → u\n这意味着如果给定了 (∀ t. τ → u )，也就是存在类型最后的那个 client 我们都当然能构造出 u ，这也是 ∃ 类型用 ∀ 类型 的解释\nBisimilar\n// todo\nConstructors and Kinds\n注意到 nat → nat 和 nat list 可以被思考为\n\n(→) 构造子作用在 nat 和 nat 上\nlist 作用在 nat 上\n\n（就像函数那样）\n我们是否要支持 type 上的计算？\n比如考虑 ⟨ t₁ , t₂ ⟩ . l 似乎它等价于 t₁ 那么 ⟨ t₁ , t₂ ⟩ . l 的表达式也应该具有 t₁ 类型？\n需要引入 definational equality of constructor 的概念，并且要求我们设计一个算法看它是否等价（甚至对于太强的类型系统可能遇到图灵完备问题？）\n另一种方案：禁止这种 constructors 这样等价就只有完全长得一模一样的概念了\n这个方案的问题是会让 substitution 的定义变得困难\n这里新书选择了第一种方案，旧书选择了第二种\n目前已经有了许多检查 type equality 的方式"},{"type":"post","id":"lean4-parser-combinator","title":"学习在 Lean4 中使用 Parser Combinator","url":"/blog/lean4-parser-combinator/","content":"此时对于我那幽默的《编译原理》课程还在用 C 语言写编译器的不满达到了顶峰。\n\n你说得对，但是《编译原理》是由 Alfred V. Aho, Monica S. Lam, Ravi Sethi 和 Jeffrey D. Ullman 等人自主研发的一款全旧计算机世界编程游戏。游戏发生在一个被称作「C—」的简化语言，在这里，选择这门课的人将被迫享受「GCC 7.5.0」，没有一点 5202 年该有的体验。玩家将扮演一位名为「C 程序员」的神秘角色，在自由的编码中邂逅各种各样、时机诡异的 Segment Fault 们，和他们一起泄露内存，感受 C 语言的恶心之处——同时，逐步发掘「都 5202 年了这帮人还在拿 39 年前的书教文法分析」的真相。\n\n但跑远了。总而言之这里介绍一种叫 parser combinator —— 解析器组合子的函数式手段，为您带来哪怕是手写递归下降也很舒适的体验（并非）\n\n0. 介绍\nParser combinator（解析器组合子）是一种函数式编程中的技术，用于构建复杂语法分析器的工具。它的核心思想是：用小的、可组合的解析器函数构建更复杂的解析器。\n一个 parser combinator 就是一个函数，它接受一些解析器作为输入，返回一个新的、更复杂的解析器。它是一种“组合模式”，非常适合处理递归文法。\n一个经典的 Parser 可以是：\nabbrev Parser (α : Type) := List Char → Option (α × List Char)\n也就是说，一个 parser 就是是一个函数，接受 List Char 作为参数，如果解析成功，返回 .some (α × List Char) 为解析结果和剩余内容。如果失败，返回 .none.\n在这里，为了一步到位地解决报错，我们把返回类型改成 Except\nabbrev Parser (α : Type) := List Char → Except String (α × List Char)\n这样，如果报错就能看到一个字符串作为错误信息。\n对于不熟悉函数式写法的人，这是它的类似的 Rust 代码（懒得配平生命周期了）：\n#![feature(type_alias_impl_trait)]\n\nstruct Parser<T>(Box<dyn FnOnce(&'static str) -> Result<(T, &'static str), String>>)\nwhere\n    T: 'static;\n\nimpl<T> Parser<T> {\n    fn parse(self, input: &'static str) -> Result<(T, &'static str), String> {\n        self.0(input)\n    }\n    fn chain<U>(self, other: Parser<U>) -> Parser<(T, U)>\n    {\n        let f = self.0;\n        let g = other.0;\n        (move |input: &'static str| {\n            let (t, input) = f(input)?;\n            let (u, input) = g(input)?;\n            Ok(((t, u), input))\n        })\n        .into()\n    }\n}\n\nimpl<T, F> From<F> for Parser<T>\nwhere\n    F: FnOnce(&'static str) -> Result<(T, &'static str), String> + 'static\n{\n    fn from(value: F) -> Self {\n        Parser(Box::new(value))\n    }\n}\n\nfn char(c: char) -> Parser<char> {\n    (move |input: &'static str| {\n        if input.is_empty() {\n            return Err(\"Input is empty\".to_string());\n        }\n        if input.chars().next().unwrap() == c {\n            Ok((c, &input[c.len_utf8()..]))\n        } else {\n            Err(format!(\"Expected '{}', found '{}'\", c, input.chars().next().unwrap()))\n        }\n    })\n    .into()\n}\n\nfn main() {\n    let res = char('a').parse(\"anc\");\n    println!(\"Result: {:?}\", res);\n    let res = char('a').chain(char('b')).parse(\"anc\");\n    println!(\"Result: {:?}\", res);\n    let res = char('a').chain(char('b')).parse(\"abc\");\n    println!(\"Result: {:?}\", res);\n\n    // Result: Ok(('a', \"nc\"))\n    // Result: Err(\"Expected 'b', found 'n'\")\n    // Result: Ok((('a', 'b'), \"c\"))\n}\n其中，chain 就是一个 combinator，它用两个小的 parser 合成了一个大的 parser。\n1. 抽象\n让我们再次请出万能的 Monad 来。关于 Monad 是什么，不妨看看所以这个 Monads 到底是什么啊之让我学学\n一个 parser 的合成过程经常需要前面的 parse 都 ok，一旦其中某一个不是 ok 的了，就短路返回 error。这是典型的 monad 行为\ninstance : Monad Parser where\n  pure := fun a =>\n    fun input => .ok (a, input)\n  bind := fun parser f =>\n    fun input => do\n      let (a, rest) ← parser input\n      f a rest\n实现了 monad 的特征以后，我们就能方便的使用 do-记号，如\ndef symbol : Parser $ Int :=\n  fun input =>\n    match input with\n    | '+' :: xs => .ok (1, xs)\n    | '-' :: xs => .ok (-1, xs)\n    | xs => .ok (1, xs)\n\ndef digits : Parser $ List Char :=\n  fun input =>\n    .ok $ input.span (·.isDigit)\n\ndef parseInt : Parser Json := do\n  let symbol ← symbol\n  let numStr ← digits\n  match numStr.asString.toInt? with\n  | some n => return Json.int $ symbol * n\n  | none   => fail \"expected an integer, but got non-digit characters\"\n\n#eval parseInt \"12345abced12345\".data\n-- Except.ok (Json.int 12345, ['a', 'b', 'c', 'e', 'd', '1', '2', '3', '4', '5'])\n其次，一个 parser 还能实现 Alternative（选择子）。字面意义上地，\n\nAn Alternative functor is an Applicative functor that can “fail” or be “empty” and a binary operation <|> that “collects values” or finds the “left-most success”.\nImportant instances include\n\nOption, where failure := none and <|> returns the left-most some.\nParser combinators typically provide an Applicative instance for error-handling and backtracking.\n\nError recovery and state can interact subtly. For example, the implementation of Alternative for OptionT (StateT σ Id) keeps modifications made to the state while recovering from failure, while StateT σ (OptionT Id) discards them.\n\n关于函子 functor 的概念我推荐阅读图解 Functor、Applicative、Monad。这样，我们用\nparser1 <|> parser2\n就能描述“第一个解析成功的 parser”。\n或许 parser 还适用一些别的抽象，但我也是刚学，想到写什么就放些什么了（）总而言之，让我们又双叒叕开启愉快的 JSON 解析之旅。\n2. 实践：JSON 解析器\n还是熟悉的 JSON\ninductive Json where\n  | null\n  | bool (x: Bool)\n  | int  (x: Int)\n  | float(x: Float)\n  | str  (x: String)\n  | arr  (x: List Json)\n  | obj  (x: List (String × Json))\nderiving Repr\n这次我们要正确地解析数字，所以引入了 int 和 float 类型。然后是准备工作：\nabbrev Parser (α : Type) := List Char → Except String (α × List Char)\n\ndef fail (reason : String) : Parser α :=\n  fun _ => .error reason\n-- 无论如何总是返回失败原因的函数\n\ninstance : Monad Parser where\n  pure := fun a =>\n    fun input => .ok (a, input)\n  bind := fun p f =>\n    fun input => do\n      let (a, rest) ← p input\n      f a rest\n\ninstance : Alternative Parser where\n  failure := fail \"unknown error\"\n  orElse p₁ p₂ := fun input =>\n      match p₁ input with\n      | .ok    r => .ok r\n      | .error _ => p₂ () input\n接下来可以实践写几个辅助函数\n-- 返回一个拿一个 char 的 parser\ndef char (c : Char) : Parser Char :=\n   fun input =>\n    match input with\n    | x :: xs =>\n      if x == c then\n        .ok (c, xs)\n      else .error s!\"Expected '{c}', got '{x}'\"\n    | [] => .error s!\"Unexpected EOF, expected character '{c}'\"\n\n-- 返回一个拿走前面的 whitespace 的 parser\ndef whitespaces : Parser Unit :=\n  fun input =>\n    .ok ((), input.dropWhile (·.isWhitespace))\n\n-- 返回一个拿一个 + 或者 - 符号的 parser\ndef symbol : Parser $ Int :=\n  fun input =>\n    match input with\n    | '+' :: xs => .ok (1, xs)\n    | '-' :: xs => .ok (-1, xs)\n    | xs => .ok (1, xs)\n\n-- 返回一个拿数字的 parser\ndef digits : Parser $ List Char :=\n  fun input =>\n    .ok $ input.span (·.isDigit)\n\n这样， number 的 parse 工作就变得很简单，只需要分两种情况：\ndef parseInt : Parser Json := do\n  let symbol ← symbol\n  let numStr ← digits\n  match numStr.asString.toInt? with\n  | some n => return Json.int $ symbol * n\n  | none   => fail \"expected an integer, but got non-digit characters\"\n\ndef toFloat (num : List Char) (fraction : List Char) : Option Float := do\n  let num ← num.asString.toNat?\n  let fra ← fraction.asString.toNat?\n  let exp := 0.1 ^ fraction.length.toFloat\n  return num.toFloat + (fra.toFloat * exp)\n\ndef parseFloat : Parser Json := do\n  let symbol ← symbol\n  let num ← digits\n  let _ ← char '.'\n  let fraction ← digits\n  match toFloat num fraction with\n  | .some num => return Json.float $ if symbol == -1 then -num else num\n  | .none => fail \"expected a float\"\n\ndef parseNumber : Parser Json := do\n  parseFloat <|> parseInt\n现在我们的 paserNumber 就是一个既可以解析整数又可以解析浮点数的 parser 了！\n随后我们一鼓作气，把几个简单的 parser 写掉。先写字符串：\ndef quotedString : Parser $ List Char := do\n  _ ← char '\"'\n  fun input =>\n    let (str, last) := input.span (· != '\"')\n    .ok (str, last.drop 1)\n\ndef parseString : Parser Json := do\n  let str ← quotedString\n   return (Json.str str.asString)\n为什么要分 quoted string 和 string 呢？因为后者直接得到了一个 Json，但我们还要在 object 那里复用获得字符串的 parser。\n随后是几个关键字，异常简单：\ndef keyword (kw : String) (val : Json) : Parser Json :=\n  fun input =>\n    if input.asString.startsWith kw then\n      .ok (val, input.drop kw.length)\n    else .error s!\"Expected keyword '{kw}', but got '{input.asString}'\"\n\ndef parseTrue := keyword \"true\" $ Json.bool true\ndef parseFalse := keyword \"false\" $ Json.bool false\ndef parseNull := keyword \"null\" Json.null\n现在是三个递归结构：\n-- 这是一个辅助函数，用来把以 sep 分割的 a 生成一个 list parser\npartial def sepBy (α : Parser a) (sep : Parser b) : Parser (List a) :=\n  fun input =>\n    let rec go (acc : List a) (input : List Char) : (List a × List Char) :=\n      match α input with\n      | .ok (a, rest) =>\n        match sep rest with\n        | .ok (_, rest') => go (acc.concat a) rest'\n        | .error _ => (acc.concat a, rest)\n      | .error _ => (acc, input)\n    .ok $ go [] input\n\nmutual\n  partial def parseArray : Parser Json := do\n    _ ← char '['\n    _ ← whitespaces\n    let elems ← sepBy parseJson (char ',')\n    _ ← whitespaces\n    _ ← char ']'\n    return Json.arr elems\n\n  partial def parseObject : Parser Json := do\n    _ ← char '{'\n    _ ← whitespaces\n    let pairs ← sepBy parsePair (char ',')\n    _ ← whitespaces\n    _ ← char '}'\n    return Json.obj pairs\n\n  partial def parsePair : Parser (String × Json) := do\n    _ ← whitespaces\n    let key ← quotedString\n    _ ← whitespaces\n    _ ← char ':'\n    let value ← parseJson\n    return (key.asString, value)\n\n  partial def parseJson : Parser Json := do\n    let _ ← whitespaces\n    let json ← fun str => match str with\n      | 'n' :: _ => parseNull str\n      | 't' :: _ => parseTrue str\n      | 'f' :: _ => parseFalse str\n      | '[' :: _ => parseArray str\n      | '{' :: _ => parseObject str\n      | '\"' :: _ => parseString str\n      | _ => parseNumber str\n    let _ ← whitespaces\n    return json\nend\n整个逻辑极其清晰和简单！这就是 parser combinator 的魅力。回顾我们之前写的 lean4 的 json 大概长这样\ndef parseJsonObject (fuel: Nat) (str: List Char) : Except String (List (String × Json) × List Char) := do\n  match fuel with\n  | 0 => .error \"out of fuel\"\n  | .succ fuel =>\n  let mut xs := trimList str\n  let mut ret : List (String × Json) := []\n  while true do\n    match xs with\n    | '\"' :: next =>\n      let (key, next) ← parseJsonString next\n      xs := trimList next\n      if xs.head? != some ':' then\n        .error \"expect `:` but got unexpected token\"\n      else\n        xs := xs.tail\n      let (val, next) ← parseJsonValue fuel xs\n      ret := ret.append [(key, val)]\n      match trimList next with\n      | ',' :: next => xs := trimList next\n      | '}' :: next =>\n        return (ret, next)\n      | x => .error $ \"expect `,` or `}` but got unexpected token:\" ++ String.mk x\n    | '}' :: next =>\n      return (ret, next)\n    | x => .error $ \"unexpected token:\" ++ String.mk x\n  return ([], xs.tail)\ntermination_by fuel\n虽然比起抽象更少的 gleam 还是很不错，但对比 parser combinator 的做法：\npartial def parseObject : Parser Json := do\n  _ ← char '{'\n  _ ← whitespaces\n  let pairs ← sepBy parsePair (char ',')\n  _ ← whitespaces\n  _ ← char '}'\n  return Json.obj pairs\n\npartial def parsePair : Parser (String × Json) := do\n  _ ← whitespaces\n  let key ← quotedString\n  _ ← whitespaces\n  _ ← char ':'\n  let value ← parseJson\n  return (key.asString, value)\n显然，所有人都看得出来， parser combinator 的做法非常简洁明了，可读性极强。\n如果你正在编写一个传统的递归下降解析器来解析 JSON 数组，你可能会尝试在循环中解析语句，当它无法解析中间的逗号时停止。这个过程很难做到复用，除非你其实已经在写一个 parser combinator 了。比如我之前写的 C++ 的解析器：\nclass Object : public Node {\n  using ObjectVT = std::unordered_map<std::string, JSON>;\n  ObjectVT value_{};\n\npublic:\n  Object() {};\n  explicit Object(ObjectVT &&val) : value_(std::move(val)) {};\n  Object(Object &&) = default;\n  Object(const Object &) = delete; // 删掉拷贝构造函数\n  Object &operator=(Object &&) = default;\n  Object &operator=(const Object &) = delete;\n\n  inline static std::unique_ptr<Object> parse(std::string_view &sv, int dep) {\n    assert_depth(sv, dep);\n    removeWhiteSpaces(sv);\n    if (sv[0] != '{')\n      throw getJSONParseError(sv, \"object start `{`\");\n    sv.remove_prefix(1);\n    removeWhiteSpaces(sv);\n    ObjectVT val;\n    bool isTComma = false; // 是不是尾随逗号\n    while (sv[0] != '}') {\n      auto key = String::parse(sv); // 解析 key\n      if (ENABLE_DUMPLICATED_KEY_DETECT && val.contains(key->value())) {\n        throw getJSONParseError(\n            sv, (\"unique key, but got dumplicated key `\" + key->value() + \"`\")\n                    .c_str());\n      } else {\n        removeWhiteSpaces(sv);\n        if (sv[0] != ':') // 解析 key :\n          throw getJSONParseError(sv, \"object spliter `:`\");\n        sv.remove_prefix(1);\n        val.insert({key->take(), JSON(Node::parse(sv, dep + 1))});\n        removeWhiteSpaces(sv); // 解析 key : value\n        switch (sv[0]) {\n        case '}': // 看看结束了没\n          sv.remove_prefix(1);\n          return std::make_unique<Object>(std::move(val));\n        case ',':\n          sv.remove_prefix(1);\n          isTComma = true;\n          continue;\n        default:\n          throw getJSONParseError(sv, \"object spliter `,` or object end `}`\");\n        }\n      }\n    }\n    if (isTComma && !ENABLE_TRAILING_COMMA)\n      throw getJSONParseError(sv, \"next json value\");\n    sv.remove_prefix(1);\n    return std::make_unique<Object>(std::move(val));\n  }\n\n  // ...\n}\n但如你所见，使用函数式语言 parser combinator 的话，定义一个复用的解析器极其简单\ndef arrayElems := sepBy parseJson (char ',')\ndef urlParams := sepBy (agg3 $ parseVar (char '=') parseVal) (char '&')\n3. 扩展：用在不那么方便的语言上？\n显然这一套是很容易用在不那么方便的语言上的。对比刚接触函数式的时候写出来的幽默代码，这套使用了解析器组合子的代码要好看很多，好理解很多\nimport gleam/dict\nimport gleam/io\nimport gleam/list\nimport gleam/result\nimport gleam/string\n\npub type Node {\n  Nul\n  Bol(val: Bool)\n  Num(val: Int)\n  Str(val: String)\n  Arr(val: List(Node))\n  Obj(val: dict.Dict(String, Node))\n}\n\ntype Parser(t) =\n  fn(String) -> Result(#(t, String), String)\n\n// Parser 工具\n\nfn skip(builder: Parser(a), f: Parser(b)) -> Parser(a) {\n  fn(input: String) {\n    use #(res, input) <- result.then(builder(input))\n    use #(_, input) <- result.then(f(input))\n    Ok(#(res, input))\n  }\n}\n\nfn result_is(builder: Parser(a), f: Parser(b)) -> Parser(b) {\n  fn(input: String) {\n    use #(_, input) <- result.then(builder(input))\n    use #(res, input) <- result.then(f(input))\n    Ok(#(res, input))\n  }\n}\n\nfn or(p1: Parser(a), p2: Parser(a)) -> Parser(a) {\n  fn(input: String) {\n    case p1(input) {\n      Ok(x) -> Ok(x)\n      Error(_) -> p2(input)\n    }\n  }\n}\n\nfn map(p: Parser(a), f: fn(a) -> b) -> Parser(b) {\n  fn(input: String) {\n    use #(res, input) <- result.then(p(input))\n    Ok(#(f(res), input))\n  }\n}\n\nfn chain(p1: Parser(a), p2: Parser(b)) -> Parser(#(a, b)) {\n  fn(input: String) {\n    use #(res1, input) <- result.then(p1(input))\n    use #(res2, input) <- result.then(p2(input))\n    Ok(#(#(res1, res2), input))\n  }\n}\n\nfn go_for_seq_by(\n  p: Parser(a),\n  sep: Parser(b),\n  acc: List(a),\n  input: String,\n) -> #(List(a), String) {\n  case p(input) {\n    Ok(#(val, rest)) ->\n      case sep(rest) {\n        Ok(#(_, rest)) -> go_for_seq_by(p, sep, acc |> list.append([val]), rest)\n        Error(_) -> #(acc |> list.append([val]), rest)\n      }\n    Error(_) -> #(acc, input)\n  }\n}\n\nfn seq_by(p: Parser(a), sep: Parser(b)) -> Parser(List(a)) {\n  fn(input: String) { Ok(go_for_seq_by(p, sep, [], input)) }\n}\n\n// JSON 工具函数\n\nfn char(c: String) -> Parser(String) {\n  fn(str: String) {\n    case str |> string.pop_grapheme {\n      Error(Nil) -> Error(\"Unexpected EOF\")\n      Ok(#(first, rest)) if first == c -> Ok(#(first, rest))\n      Ok(_) -> Error(\"need char '\" <> c <> \"', got unexpected token \" <> str)\n    }\n  }\n}\n\nfn whitespace() -> Parser(#()) {\n  fn(input: String) { Ok(#(#(), input |> string.trim_start)) }\n}\n\nfn ident(id: String) -> Parser(String) {\n  fn(str: String) {\n    case str |> string.starts_with(id) {\n      True -> Ok(#(id, str |> string.drop_start(string.length(id))))\n      False -> Error(\"need \" <> id <> \", got unexpected token \" <> str)\n    }\n  }\n}\n\nfn true_parser() -> Parser(Node) {\n  ident(\"true\") |> map(fn(_) { Bol(val: True) })\n}\n\nfn false_parser() -> Parser(Node) {\n  ident(\"false\") |> map(fn(_) { Bol(val: False) })\n}\n\nfn null_parser() -> Parser(Node) {\n  ident(\"null\") |> map(fn(_) { Nul })\n}\n\nfn string_key_parser() -> Parser(String) {\n  fn(input: String) {\n    use #(_, rest) <- result.then(char(\"\\\"\")(input))\n    case rest |> string.split_once(\"\\\"\") {\n      Ok(#(val, rest)) -> Ok(#(val, rest))\n      Error(_) -> Error(\"except string key, got unexpected token \" <> input)\n    }\n  }\n}\n\nfn string_parser() -> Parser(Node) {\n  string_key_parser() |> map(fn(val) { Str(val: val) })\n}\n\nfn array_parser() -> Parser(Node) {\n  char(\"[\")\n  |> result_is(\n    json_parser()\n    |> seq_by(char(\",\"))\n    |> map(fn(val) { Arr(val) }),\n  )\n  |> skip(whitespace())\n  |> skip(char(\"]\"))\n}\n\nfn pair_parser() -> Parser(#(String, Node)) {\n  whitespace()\n  |> result_is(string_key_parser())\n  |> skip(whitespace())\n  |> skip(char(\":\"))\n  |> chain(json_parser())\n}\n\nfn object_parser() -> Parser(Node) {\n  char(\"{\")\n  |> skip(whitespace())\n  |> result_is(\n    pair_parser()\n    |> seq_by(char(\",\"))\n    |> map(fn(val) { Obj(dict.from_list(val)) }),\n  )\n  |> skip(whitespace())\n  |> skip(char(\"}\"))\n}\n\nfn json_parser() -> Parser(Node) {\n  fn(input: String) {\n    let input = input |> string.trim_start\n    case input {\n      \"t\" <> _ -> true_parser()(input)\n      \"f\" <> _ -> false_parser()(input)\n      \"n\" <> _ -> null_parser()(input)\n      \"\\\"\" <> _ -> string_parser()(input)\n      \"[\" <> _ -> array_parser()(input)\n      \"{\" <> _ -> object_parser()(input)\n      x -> Error(\"unexpected token \" <> x)\n    }\n  }\n  // eat whitespaces\n  |> skip(whitespace())\n}\n\nfn parse_json(input: String) -> Result(Node, String) {\n  case json_parser()(input |> string.trim_start) {\n    Ok(#(node, rest)) -> {\n      case rest {\n        \"\" -> Ok(node)\n        _ -> Error(\"unexpected token \" <> rest)\n      }\n    }\n    Error(err) -> Error(err)\n  }\n}\n\npub fn main() {\n  let _ = io.debug(parse_json(\"null\"))\n  let _ = io.debug(parse_json(\"true\"))\n  let _ = io.debug(parse_json(\"false\"))\n  let _ = io.debug(parse_json(\"\\\"wwww\\\"\"))\n  let _ = io.debug(parse_json(\"{}\"))\n  let _ = io.debug(parse_json(\"{\\\"a\\\": true, \\\"b\\\": [true, false, null]}\"))\n  let _ = io.debug(parse_json(\"{\\\"a\\\"  : true, \\\"b\\\"  : [true, false, null]}\"))\n  let _ = io.debug(parse_json(\"[ true, false, null, \\\"abcd\\\" ]\"))\n  let _ = io.debug(parse_json(\"[true,false,null,\\\"abcd\\\"  ]\"))\n\n  io.debug(\"done\")\n}"},{"type":"post","id":"lean4-json","title":"很难不承认 Lean4 真香 —— 然后写了一个简单的 JSON 解析器","url":"/blog/lean4-json/","content":"在之前的文章中我尝试了一下 Lean4 定理证明器——然后我是在并非干这个方向的所以后面就抛在脑后了\n后面因为学习函数式语言于是又捡起了 Lean4 函数式编程，然后……好吧我真的不得不说真香啊\n\n于是我又拿 Lean4 写了一个 JSON parser，说起来我真的好爱写 JSON 解析器啊（？）（毕竟 JSON 是我们平时接触的最实用又最简单的可以拿 LL1 文法表达的东西\n首先我们定义一个经典的 JSON 结构。接触了一些 PL 理论以后不难看出这是一个 inductive type 即归纳类型\ninductive Json where\n  | Number (n : String)\n  | Null\n  | Bool (b : Bool)\n  | String (s : String)\n  | Array (a : List Json)\n  | Object (o : List (String × Json))\nderiving Repr\n为了懒得解析我们不妨直接用 String 存放一个数字。现在我们要开始写一个解析器了！首先这些函数是互相递归的所以我们先来一个 mutual 块。 Lean4 里面互相递归的函数得被 mutual 包起来。\nmutual\n\ndef parseJsonString (str: List Char) : Except String (String × List Char) := do\n  sorry\n\ndef parseJsonObject (fuel: Nat) (str: List Char) : Except String (List (String × Json) × List Char) := do\n  sorry\n\ndef parseJsonArray (fuel: Nat) (str: List Char) : Except String (List Json × List Char) := do\n  sorry\n\ndef parseJsonNumber (str: List Char) : Except String (String × List Char) :=\n  sorry\n\ndef parseJsonValue (fuel: Nat) (str: List Char): Except String (Json × List Char) := do\n  sorry\n\ndef parseJson (str: String) : Except String Json := do\n  sorry\n\nend\nfuel 在这里是最大递归层级，如果 fuel 用光了就强制停止 parse 的过程。为什么我们要引入 fuel 呢？答案很简单：\n因为我不会证明它停机\n虽然作为一个 JSON 解析器它停机是比较显然的，但是 Lean4 不这样觉得，所以你得向它证明停机。证明这个停机需要一些设计，反正我不会，所以在询问了 GPT 并且得不到正确的答复以后我选择从心：直接丢个最大递归深度进去肯定是停机的，Lean4 也很容易自动证明这一点\n（当然你也可以直接使用 partial def 告诉 Lean4 这个函数根本就可能不停机，但是问题不大，何况这个函数明明就是会停机的我们应该坚守原则）\n好的那么让我们上代码！\ninductive Json where\n  | Number (n : String)\n  | Null\n  | Bool (b : Bool)\n  | String (s : String)\n  | Array (a : List Json)\n  | Object (o : List (String × Json))\nderiving Repr\n\nmutual\n\ndef trimList (str: List Char) : List Char :=\n  str.dropWhile (·.isWhitespace)\n\ndef parseJsonString (str: List Char) : Except String (String × List Char) := do\n  let mut xs := str\n  let mut str : List Char := []\n  for ch in xs do\n    match ch with\n    | '\"' => return (.mk str, xs.tail) -- 可以直接写引号但是这个博客的幽默高亮有问题\n    | x =>\n      str := str ++ [x]\n      xs := xs.tail\n  return (.mk str, xs)\n\ndef parseJsonObject (fuel: Nat) (str: List Char) : Except String (List (String × Json) × List Char) := do\n  match fuel with\n  | 0 => .error \"out of fuel\"\n  | .succ fuel =>\n  let mut xs := trimList str\n  let mut ret : List (String × Json) := []\n  while true do\n    match xs with\n    | '\"' :: next =>\n      let (key, next) ← parseJsonString next\n      xs := trimList next\n      if xs.head? != some ':' then\n        .error \"expect `:` but got unexpected token\"\n      else\n        xs := xs.tail\n      let (val, next) ← parseJsonValue fuel xs\n      ret := ret.append [(key, val)]\n      match trimList next with\n      | ',' :: next => xs := trimList next\n      | '}' :: next =>\n        return (ret, next)\n      | x => .error $ \"expect `,` or `}` but got unexpected token:\" ++ String.mk x\n    | '}' :: next =>\n      return (ret, next)\n    | x => .error $ \"unexpected token:\" ++ String.mk x\n  return ([], xs.tail)\ntermination_by fuel\n\ndef parseJsonArray (fuel: Nat) (str: List Char) : Except String (List Json × List Char) := do\n  match fuel with\n  | 0 => .error \"out of fuel\"\n  | .succ fuel =>\n  let mut xs := trimList str\n  let mut ret : List Json := []\n  while xs.head? != some ']' do\n    let (car, next) ← parseJsonValue fuel xs\n    ret := ret.append [car]\n    match trimList next with\n    | ',' :: next => xs := trimList next\n    | ']' :: next =>\n      return (ret, next)\n    | _ => .error \"unexpected token\"\n  return ([], xs.tail)\ntermination_by fuel\n\ndef parseJsonNumber (str: List Char) : Except String (String × List Char) :=\n  let (num, xs) := str.span (·.isDigit)\n  match num.length with\n  | 0 => .error \"unexpected token\"\n  | _ => .ok (.mk num, xs)\n\ndef parseJsonValue (fuel: Nat) (str: List Char): Except String (Json × List Char) := do\n  match fuel with\n  | 0 => .error \"out of fuel\"\n  | .succ fuel =>\n  match trimList str with\n  | 'n'::'u'::'l'::'l'::xs => .ok (Json.Null, xs)\n  | 't'::'r'::'u'::'e'::xs => .ok $ (Json.Bool true, xs)\n  | 'f'::'a'::'l'::'s'::'e'::xs => .ok $ (Json.Bool false, xs)\n  | '[' :: xs => do\n    let (inner, next) ← parseJsonArray fuel xs\n    return (Json.Array inner, next)\n  | '{' :: xs => do\n    let (inner, next) ← parseJsonObject fuel xs\n    return (Json.Object inner, next)\n  | '\"' :: xs => do\n    let (str, next) ← parseJsonString xs\n    return (Json.String str, next)\n  | maybe_number => do\n    let (num, next) ← parseJsonNumber maybe_number\n    return (Json.Number num, next)\ntermination_by fuel\n\ndef parseJson (str: String) : Except String Json := do\n  let (json, next) ← parseJsonValue 999 str.data\n  match trimList next with\n  | [] => return json\n  | x => .error $ \"unexpected token after json: \".append x.toString\n\nend\n\n#eval parseJsonNumber \"1234abc\".data\n\n#eval \"123waf32e\".data.span (·.isDigit)\n\n\ndef read_and_parse : IO (Except String Json) := do\n  let json ← IO.FS.readFile \"some.json\"\n  IO.println json\n  return parseJson json\n\n#eval read_and_parse\n\n#eval \"true\".data\n\n#eval parseJson \"true\"\n#eval parseJson \"false\"\n#eval parseJson \"[true, false]\"\n#eval parseJson \"\\\"hello world\\\"\"\n#eval parseJson \"111\"\n#eval parseJson \"[\\\"hello world\\\", true, false, [1,2,3, {\\\"s\\\": null}], null, [\\\"hello\\\"]]\"\n#eval parseJson \"{\\\"hello\\\": \\\"world\\\", \\\"foo\\\": [1, 2, 3], \\\"bar\\\": {\\\"baz\\\": true}}\"\n#eval parseJson \"{\\\"hello\\\": \\\"world\\\", \\\"foo\\\": null}\"\n在这份代码中你可以非常直观地看到 Lean4 的优越之处。作为一个 pure 的 functional language 它为你提供了原生的 for 和 while 语法糖。语法糖的底层细节我们懒得讲解，但这是 Lean4 中一个非常甜的地方——显然没人说 for / while 循环就不是纯函数了，那么为什么不使用甜甜的语法糖呢？\n所以你可以直接写\ndef parseJsonString (str: List Char) : Except String (String × List Char) := do\n  let mut xs := str\n  let mut str : List Char := []\n  for ch in xs do\n    match ch with\n    | '\"' => return (.mk str, xs.tail)\n    | x =>\n      str := str ++ [x]\n      xs := xs.tail\n  return (.mk str, xs)\n而在另一些不够甜的纯函数式语言中就不得不\nfn read_str(str: String) -> Result(ParseStrResult, String) {\n  case str |> string.pop_grapheme {\n    Error(Nil) -> Error(\"Unexpected EOF\")\n    Ok(#(first, rest)) ->\n      case first {\n        \"\\\"\" -> Ok(ParseStrResult(\"\", rest))\n        _ ->\n          read_str(rest)\n          |> result.map(fn(res) {\n            ParseStrResult(first <> res.result, res.rest)\n          })\n      }\n  }\n}\n\nfn parse_str(str: String) -> Result(ParseStrResult, String) {\n  let str = str |> string.trim_start\n  case str {\n    \"\\\"\" <> content -> read_str(content)\n    x -> Error(\"unexpected token \" <> x)\n  }\n}\n一点也不直观，蠢蠢的\n同时，你可以在这份代码中直观地看到 monads 的魅力。Except 显然也是一个 monad，所以可以使用 do 记号完美完成“不出错则继续，出错则跳出”的逻辑。不得不说，看到\n  | '[' :: xs => do\n    let (inner, next) ← parseJsonArray fuel xs\n    return (Json.Array inner, next)\n这样的代码，又直观又好看，这才是函数式语言优美的地方\n总而言之，Lean4 真香，uwu"},{"type":"post","id":"strong-typed","title":"一千个计算机人有一千个强类型","url":"/blog/strong-typed/","content":"所以不要再说强类型了啊！！\n\nQ: 什么是强类型？\n\n强类型意味着不会发生隐式类型转换（所以 Rust 是强类型）\n—— 某 Rust 课教师\n\n你好，Rust 有 &String 到 &str 的隐式类型转换\n\n可以绕过类型系统的限制说明是强类型\n—— https://stackoverflow.com/questions/2690544/what-is-the-difference-between-a-strongly-typed-language-and-a-statically-typed\n\n坏了，带 unsafe 的东西基本都能拿指针强制 reinterpret 绕过类型系统的限制，这下 Rust 成弱类型了\n\n不同类型的对象可以相加就是弱类型！\n——不知道哪来的野鸡教程\n\n能重载加法运算符的语言多了去了，这下全变成弱类型了，Rust 也是弱类型，Haskell 也是弱类型，C++也是弱类型，Python 也是弱类型\n\n如果编译器的类型系统检查通过就不会在运行时发生类型错误，那就是强类型的\n—— 某编译原理课教师\n\n……有没有一种可能这个定义是 type safety，以及只要是能造出某种 std::any 的都可以在运行时发生类型错误，这下全变成弱类型语言了。哦还有那些做不到 null safe 的语言也全变成弱类型了\n\n强类型意味着在该语言的实现下，归类为某种类型的对象是否都能携带对应信息以决定其类型。\n—— 某知乎答主\n\n这下所有动态语言全部变成强类型了，毕竟动态语言必须要在对象上存储它的类型信息\n一千个计算机人有一千个强类型\n总结以后你会发现，一般来说公认地，C 是弱类型语言，JavaScript 是弱类型语言，Rust、Haskell 这样的是强类型语言，剩下的语言都是有争议的。有的人觉得 C++ 到处是隐式类型转换怎么就是强类型了，有的人觉得 C++ 所有东西都要写明类型很强啊，有的人觉得 Python 倾向于不进行隐式类型转换就是强类型语言。很多人完全不分辨 static/dynamic typed 与 strong/weak typed，所以有人觉得 C 也是强类型，甚至还有一些当老师的人原地混淆强类型与类型安全。坏消息是，动态语言在某种意义上比含有 void* 或者 transmute / reinterpret_cast 这种操作的语言更加“类型安全”得多了，毕竟遇到错误的类型动态语言直接抛一个 TypeError 至少不会 panic，控制了错误的范围，而允许你 reinterpret_cast 的语言要是 cast 出了问题直接就是一个 undefined behavior 上来了鬼知道会不会在 114514 层调用链后造成点缓冲区溢出之类的安全漏洞。\n浏览大家的回答，会发现那些还在区分强弱类型的人根本就没吵出一个严谨的定义来。\n\nJavaScript: 几乎都认为它是弱的\nC: 很多人认为它是弱的，一些人觉得是强的\nC++: 有人觉得强，有人觉得弱\nJava: 有人觉得强，有人觉得弱\nPython: 很多人觉得弱，不少觉得强\nRust: 几乎都认为它是强的\nHaskell: 几乎都认为它是强的\n\n强/弱类型根本就没有一个公认的、well-defined 的定义。 这比“面向对象的语言”还严重，OOP 虽然争议比较多，起码能来个自我解释，比如说“impl 封装继承多态 ←→ OOP”之类的。\n不要再说强/弱类型语言了\n如果你想说的是静态类型和动态类型，which 我们可以不规范的定义为\n\n静态类型语言：不是动态类型语言的语言\n动态类型语言：所有 value 有统一的 type dyn，一切类型检查都是通过运行时打上的类型标记的语言\n\n去说静态类型/动态类型，而不是强/弱类型。\n如果你想说的是类型安全与类型不安全，which 我们可以不规范的定义为：\n\n类型安全的：如果在静态检查中通过的代码永远不会发生未定义的类型错误，它是类型安全的\n类型不安全：不是类型安全的语言\n\n去说类型安全/不安全，而不是强/弱类型。\n（进一步的，在严谨的讨论中，我们会用 sound, complete, total 这样的词来形容类型系统）\n\nsound: 如果类型系统认为程序是合法的（类型正确的），那么运行时就不会出现类型错误\ncomplete: 所有在运行时不会出错的程序，类型系统都能通过它们。\ntotal: 类型检查算法总能在有限步骤内完成\n\n如果你想讨论的是隐式类型转换，which 我们可以不规范的定义为\n\n语言充斥着/很少出现 许多隐式的行为，这些行为允许自动地将一个值从一个类型转换到另一个类型，以匹配定义好的操作\n\n那就去说隐式类型转换，而不是强/弱类型\n\n强/弱类型被说了这么久，甚至连一个公认的定义都没有。不管你以前怎么理解强/弱类型的赶快把这个词扔进垃圾堆吧."},{"type":"post","id":"pop-front-list-compare-vec","title":"小数据的时候 `std::vector<int>` 删除首元素比 deque 和 list 还快","url":"/blog/pop-front-list-compare-vec/","content":"链表可以当成双端队列来使用——至少在渐进时空复杂度上，它们是相同的。\n但在现代化的 CPU 的支持下，std::vector 由于内存的连贯性，在小规模数据下甚至可以做到比 std::deque 更好的性能，更别提在随机访问上 std::vector 有巨大优势了。\n\n灵感来源： C++ list vs vector 性能测试 - 君实的文章 - 知乎 https://zhuanlan.zhihu.com/p/1888283969994336101\n测试代码：\n#include <algorithm>\n#include <chrono>\n#include <cstdint>\n#include <cstdlib>\n#include <deque>\n#include <iostream>\n#include <list>\n#include <string>\n#include <type_traits>\n#include <vector>\n\nconstexpr int TEST_ITERS = 100000;\n\ntemplate <typename T>\n  requires std::is_same_v<T, std::list<int>> ||\n           std::is_same_v<T, std::vector<int>> ||\n           std::is_same_v<T, std::deque<int>>\nvoid test_for(const char *name, int count) {\n  auto t_0 = std::chrono::system_clock::now();\n  T container;\n  for (int i = 0; i < count; i++) {\n    container.push_back(i);\n  }\n  auto t_initialized = std::chrono::system_clock::now();\n  for (int i = 0; i < TEST_ITERS; i++) {\n    int elem = rand() % count;\n    auto iter = std::ranges::find(container, elem);\n    container.erase(iter);\n    container.push_back(elem);\n  }\n  auto t_random_test = std::chrono::system_clock::now();\n  for (int i = 0; i < TEST_ITERS; i++) {\n    auto elem = *container.begin();\n    container.erase(container.begin());\n    container.push_back(elem);\n  }\n  auto t_pop_front_test = std::chrono::system_clock::now();\n\n  std::cout << \"====================================================\\n\"\n            << \"test final for \" << name << \" with count: \" << count << \"\\n\"\n            << \"\\ttime_init = \" << t_initialized - t_0 << \"\\n\"\n            << \"\\ttime_random_erase = \" << t_random_test - t_initialized << \"\\n\"\n            << \"\\ttime_pop_front = \" << t_pop_front_test - t_random_test << \"\\n\"\n            << std::endl;\n}\n\ntemplate <typename T> void test_for_str(const char *name, int count) {\n  auto t_0 = std::chrono::system_clock::now();\n  T container;\n  for (int i = 0; i < count; i++) {\n    container.push_back(std::to_string(i));\n  }\n  auto t_initialized = std::chrono::system_clock::now();\n  for (int i = 0; i < TEST_ITERS; i++) {\n    auto elem = *container.begin();\n    container.erase(container.begin());\n    container.push_back(elem);\n  }\n  auto t_pop_front_test = std::chrono::system_clock::now();\n\n  std::cout << \"====================================================\\n\"\n            << \"test final for \" << name << \" with count: \" << count << \"\\n\"\n            << \"\\ttime_init = \" << t_initialized - t_0 << \"\\n\"\n            << \"\\ttime_pop_front = \" << t_pop_front_test - t_initialized << \"\\n\"\n            << std::endl;\n}\n\nint main() {\n  test_for<std::vector<int>>(\"std::vector<int>\", 16);\n  test_for<std::list<int>>(\"std::list<int>\", 16);\n  test_for<std::deque<int>>(\"std::deque<int>\", 16);\n  test_for<std::vector<int>>(\"std::vector<int>\", 256);\n  test_for<std::list<int>>(\"std::list<int>\", 256);\n  test_for<std::deque<int>>(\"std::deque<int>\", 256);\n  test_for<std::vector<int>>(\"std::vector<int>\", 4096);\n  test_for<std::list<int>>(\"std::list<int>\", 4096);\n  test_for<std::deque<int>>(\"std::deque<int>\", 4096);\n  test_for<std::vector<int>>(\"std::vector<int>\", 32768);\n  test_for<std::list<int>>(\"std::list<int>\", 32768);\n  test_for<std::deque<int>>(\"std::deque<int>\", 32768);\n\n  test_for_str<std::vector<std::string>>(\"std::vector<std::string>\", 16);\n  test_for_str<std::list<std::string>>(\"std::list<std::string>\", 16);\n  test_for_str<std::deque<std::string>>(\"std::deque<std::string>\", 16);\n  test_for_str<std::vector<std::string>>(\"std::vector<std::string>\", 256);\n  test_for_str<std::list<std::string>>(\"std::list<std::string>\", 256);\n  test_for_str<std::deque<std::string>>(\"std::deque<std::string>\", 256);\n  test_for_str<std::vector<std::string>>(\"std::vector<std::string>\", 8192);\n  test_for_str<std::list<std::string>>(\"std::list<std::string>\", 8192);\n  test_for_str<std::deque<std::string>>(\"std::deque<std::string>\", 8192);\n  test_for_str<std::vector<std::string>>(\"std::vector<std::string>\", 32768);\n  test_for_str<std::list<std::string>>(\"std::list<std::string>\", 32768);\n  test_for_str<std::deque<std::string>>(\"std::deque<std::string>\", 32768);\n}\n测试输出\n====================================================\ntest final for std::vector<int> with count: 16\n        time_init = 4500ns\n        time_random_erase = 2478100ns\n        time_pop_front = 548300ns\n\n====================================================\ntest final for std::list<int> with count: 16\n        time_init = 2200ns\n        time_random_erase = 4760000ns\n        time_pop_front = 2577000ns\n\n====================================================\ntest final for std::deque<int> with count: 16\n        time_init = 1300ns\n        time_random_erase = 3194600ns\n        time_pop_front = 938800ns\n\n====================================================\ntest final for std::vector<int> with count: 256\n        time_init = 4300ns\n        time_random_erase = 5934600ns\n        time_pop_front = 1134400ns\n\n====================================================\ntest final for std::list<int> with count: 256\n        time_init = 27900ns\n        time_random_erase = 19486100ns\n        time_pop_front = 2807300ns\n\n====================================================\ntest final for std::deque<int> with count: 256\n        time_init = 13300ns\n        time_random_erase = 10613400ns\n        time_pop_front = 980900ns\n\n====================================================\ntest final for std::vector<int> with count: 4096\n        time_init = 43400ns\n        time_random_erase = 190562800ns\n        time_pop_front = 313020900ns\n\n====================================================\ntest final for std::list<int> with count: 4096\n        time_init = 134500ns\n        time_random_erase = 634532100ns\n        time_pop_front = 3362300ns\n\n====================================================\ntest final for std::deque<int> with count: 4096\n        time_init = 6900ns\n        time_random_erase = 99171000ns\n        time_pop_front = 879800ns\n\n====================================================\ntest final for std::vector<int> with count: 32768\n        time_init = 81800ns\n        time_random_erase = 1844930700ns\n        time_pop_front = 2943559900ns\n\n====================================================\ntest final for std::list<int> with count: 32768\n        time_init = 902000ns\n        time_random_erase = 6683027100ns\n        time_pop_front = 3578600ns\n\n====================================================\ntest final for std::deque<int> with count: 32768\n        time_init = 69700ns\n        time_random_erase = 790749400ns\n        time_pop_front = 886100ns\n\n====================================================\ntest final for std::vector<std::string> with count: 16\n        time_init = 3100ns\n        time_pop_front = 3449700ns\n\n====================================================\ntest final for std::list<std::string> with count: 16\n        time_init = 1800ns\n        time_pop_front = 2865500ns\n\n====================================================\ntest final for std::deque<std::string> with count: 16\n        time_init = 17200ns\n        time_pop_front = 672300ns\n\n====================================================\ntest final for std::vector<std::string> with count: 256\n        time_init = 147700ns\n        time_pop_front = 48857700ns\n\n====================================================\ntest final for std::list<std::string> with count: 256\n        time_init = 19900ns\n        time_pop_front = 2907400ns\n\n====================================================\ntest final for std::deque<std::string> with count: 256\n        time_init = 5600ns\n        time_pop_front = 758500ns\n\n====================================================\ntest final for std::vector<std::string> with count: 8192\n        time_init = 254700ns\n        time_pop_front = 1175939400ns\n\n====================================================\ntest final for std::list<std::string> with count: 8192\n        time_init = 303600ns\n        time_pop_front = 2826500ns\n\n====================================================\ntest final for std::deque<std::string> with count: 8192\n        time_init = 172300ns\n        time_pop_front = 646900ns\n\n====================================================\ntest final for std::vector<std::string> with count: 32768\n        time_init = 679900ns\n        time_pop_front = 5407818600ns\n\n====================================================\ntest final for std::list<std::string> with count: 32768\n        time_init = 1202400ns\n        time_pop_front = 3050200ns\n\n====================================================\ntest final for std::deque<std::string> with count: 32768\n        time_init = 639600ns\n        time_pop_front = 712600ns\n分析测试数据可以发现，在 16 和 256 的 int 数据这样极小的数据中，已知迭代器的擦写 vector<int> 甚至可以比 deque<int> 还快，更别提 cache miss 吃满的 list<int>。\n但是在 std::string 的容器中，由于 string 移动常数明显地比 int 大很多，即使是 16 这样的小容器也是 vector 更慢一些。\n对于常用的 先 find 再 remove （即，remove-if）的过程，更是很难说有什么不用 vector 的理由。直到 4096 这样的数字，vector 随机删除会移动后续所有元素的性质才开始与 deque 拉开距离。deque<int> 在 256 的时候随机删除仍然不如 vector<int>\n而链表，顺序迭代的速度更是费拉不堪，比 vector 和 deque 可能慢 3 倍有余。\n\n链表在工程上已经失去了绝大多数的用武之地。\n\n或许只有你需要保持迭代器的有效性的同时，还要在已知迭代器的情况下进行随机删除的时候 std::list 是一个不错的选择。\n\n版权声明： CC BY-SA 4.0"},{"type":"post","id":"learn-monads","title":"所以这个 Monads 到底是什么啊之让我学学","url":"/blog/learn-monads/","content":"简单的说单子(Monad)就是自函子范畴上的一个幺半群 👀 你说这个谁懂啊\n\n\n从很久以前就听说了 Monads 这个概念，但是一直都不懂，今天终于花了几个小时去理解（然后还是似懂非懂）\nOption, one of the most simple Monad\n\nmonad 可以理解成包了一些其他控制结构/副作用, 用来提供数据的管线\n\n让我们看看 Haskell 和 Lean 4 里分别对 Monad 的定义\nclass Monad m where\n  return :: a -> m a           -- 也可以叫 pure\n  (>>=)  :: m a -> (a -> m b) -> m b\nclass Monad (m : Type u → Type v) where\n  pure : {α : Type u} → α → m α\n  bind : {α β : Type u} → m α → (α → m β) → m β\n之后我们 focus on 最经典的 Monads 之一 也就是 Option 或者说 Maybe\ninstance Monad Maybe where\n  return x = Just x\n  Just x >>= f = f x\n  Nothing >>= _ = Nothing\n-- 真实代码不长这样\n\ninductive Option (α : Type u) where\n  /-- No value. -/\n  | none : Option α\n  /-- Some value of type `α`. -/\n  | some (val : α) : Option α\n\ninstance : Monad Option where\n  pure x := some x\n  bind opt next :=\n    match opt with\n    | none => none\n    | some x => next x\n可以大概地看出一件事：一个 Monad （在这里）是一个类型类，得到一种将它们串起来的方法\n什么事类型类呢？类型类可以理解为一个接口 / trait 之类的东西，实现了这个接口以后就有这个接口的特征\n也就是说，我们给 Option 实现了 Monad 以后，就能用 Monad 来串联 Option 了\n#eval bind (some 2) λ x => pure $ x + 3\n#eval (some 2) >>= λ x => pure $ x + 3\n-- some 5\n也就是说，我们可以这样直观地去理解一个 Monad：它是一个管子，pure 用来往管子里放东西，bind 用来定义管子里的东西怎么流动。\n为了方便非函数式背景的人比如我进一步理解 Monad，我们可以用 C++ 模拟一个半残的 Monad Option：\n#include <functional>\n#include <iostream>\n#include <optional>\ntemplate <class T, class M> class Monads {\npublic:\n  static auto pure(T) -> M;\n  static auto bind(M, std::function<M(T)>) -> M;\n  auto operator>>(std::function<M(T)> fun) -> M { return bind(*this, fun); }\n};\n\ntemplate <class T> class Option : public Monads<T, Option<T>> {\n  std::optional<T> v;\n  Option(std::optional<T> v) : v(std::move(v)) {}\n\npublic:\n  static auto pure(T val) -> Option<T> { return Option(std::optional<T>(val)); }\n  static auto bind(Option opt, std::function<Option(T)> fun) -> Option {\n    if (opt.v.has_value()) {\n      return fun(opt.v.value());\n    } else {\n      return Option(std::nullopt);\n    }\n  }\n  auto operator>>(std::function<Option(T)> fun) -> Option {\n    return bind(*this, fun);\n  }\n  auto get_v() -> std::optional<T> { return this->v; }\n};\n\nint main() {\n  auto opt = Option<int>::pure(3);\n  auto p2 = opt >> [](int v) { return Option<int>::pure(v + 2); };\n  std::cout << p2.get_v().value(); // 5\n}\n有了 Monad 定义的这根管子，任何继承了 Monad （或者说实现了 Monad 接口）的类都将会有一个 >> 符号，把自己“流”到一个函数里面，流出来一个新的 Monad。这就是 Monad 的作用。\nWhy Monads\n如果没有 monads，我们可能不得不写出这样的代码\ndef get1357 (xs : List α) : Option (α × α × α × α) :=\n  match xs[0]? with\n  | none => none\n  | some first =>\n    match xs[2]? with\n    | none => none\n    | some third =>\n      match xs[4]? with\n      | none => none\n      | some fifth =>\n        match xs[6]? with\n        | none => none\n        | some seventh =>\n          some (first, third, fifth, seventh)\n比如说许多的非函数式语言，就不得不这样写\nfunc foo() {\n  _, err = task1();\n  if err != nil {\n    return nil, err\n  }\n  _, err = task2();\n  if err != nil {\n    return nil, err\n  }\n  _, err = task3();\n  if err != nil {\n    return nil, err\n  }\n  _, err = task4();\n  if err != nil {\n    return nil, err\n  }\n  _, err = task5();\n  if err != nil {\n    return nil, err\n  }\n}\n人们已经注意到这样的链式行为非常多，以至于在 C#, Kotlin, Javascript 等语言中，有一个 ?. 运算符，专门用于链式地在可能为 null 的值上查找属性或调用方法的。如果 ?. 前的值为 null，则整个表达式为 null。否则，该非 null 值会被用于使用。像这样链接 null 检查比编写和维护深层嵌套的 if 方便得多。\nState Monad\n在接触纯函数式语言的时候，我们最先知道的也是最先深受其害大为震撼的，应该是它的不可变。我们不再能方便地使用状态。但是有时候，必须要用到一些状态。\n比如，让我们用函数式语言写一个斐波那契数列的计算。\nfib :: Int -> Int\nfib 1 = 1\nfib 2 = 1\nfib n = fib (n - 1) + fib (n - 2)\n\nmain :: IO ()\nmain = print $ fib 10\n-- 55\n它很好，但是效率致命的低下，具有指数级的时间复杂度。有很多更加函数式风格的改善，不过让我们考虑 C/C++ 的代码\nint fib(int n) {\n    int a = 1, b = 1;\n    for (int i = 1; i <= n; i++) {\n        int c = a;\n        a = b;\n        b = a + c;\n    }\n    return a;\n}\na 和 b 是状态，维护了 fib (n - 1) 和 fib (n - 2)\n如果是函数式语言的话，容易想出一种解决方案：把状态当成参数传入（和传出）。给定状态 S, 返回 (R, S') 其中 R 是本来的返回值，S' 是修改后的新状态。\nfibHelper :: Int -> (Int, Int) -> Int\nfibHelper 0 (a, b) = a\nfibHelper n (a, b) = fibHelper (n - 1) (b, a + b)\n\nfib :: Int -> Int\nfib n = fibHelper n (0, 1)\n\nmain :: IO ()\nmain = print $ fib 10\n-- 55\n这样很好地解决了这个问题。\n注意到，因为有了状态，之前理论上可能可以交换的执行顺序变得固定了。在之前，fib (n - 1) 和 fib (n - 2) 完全是独立的，理论上先算哪个都没关系。现在后面的状态总是依赖于前面的状态被计算出。这种关系形成了一个链条，于是有了我们 Monads 的用武之地。\nState Monads 通常被实现为一个\nstructure State (σ α : Type) where\n  run : σ → (α × σ)\n容易看出这就是一个对 state -> (val, state) 的包装，\ninstance : Monad (State σ) where\n  pure x := ⟨fun s => (x, s)⟩  -- 直接返回 x，不改变状态\n  bind sa f := ⟨fun s =>\n    let (a, s') := sa.run s  -- 取出当前状态，计算 a\n    (f a).run s'⟩  -- 用新状态执行 f\n然后在上面经常会实现有 get 和 put 两个很方便的函数\ndef get : State σ σ :=\n  ⟨fun s => (s, s)⟩  -- 直接返回当前状态 s\n\ndef put (s' : σ) : State σ Unit :=\n  ⟨fun _ => ((), s')⟩  -- 不关心旧状态，直接设置新状态\n比如之前那个斐波那契数列，可以这样写：\nimport Std\n\ndef fibStep : StateM (Nat × Nat) Nat := do\n  let (a, b) ← get    -- 读取 (a, b)\n  set (b, a + b)     -- 更新状态为 (b, a+b)\n  return b\n\ndef fib (n: Nat) := (do\n  for _ in [0:n] do\n    _ <- fibStep\n  return <- fibStep).run' (0, 1)\n\n#eval [1,2,3,4,5,6].map fib\n-- [1, 2, 3, 5, 8, 13]\n我们把它 desugar，基本上相当于\ndef fibStep' : StateM (Nat × Nat) Nat :=\n  get >>= fun (a, b) =>           -- 读取 (a, b)\n  set (b, a + b) >>= fun _ =>     -- 更新状态为 (b, a+b)\n  pure b                          -- 返回 b\n\ndef fibrecu (step : Nat) : StateM (Nat × Nat) Nat :=\n  fibStep >>= fun r => match step with\n  | .zero => pure r\n  | .succ step' => fibrecu step'\n\ndef fib' (n : Nat) : Nat := (fibrecu n).run' (0, 1)\n\n#eval [1,2,3,4,5,6].map fib'\n-- [1, 2, 3, 5, 8, 13]\n也就是说，在 State Monad 这个神奇的管道下，只需要传入初始状态，则 get 和 set 就能一路把状态在管道内传递，而无需我们手动维护。有了 State Monads 我们就在 “不可变” 的语言里产生了 “可变”\n当然，我们这样费力 Desugar 反而有点适得其反了，其实我们本身就是为了能写 do 记号而引入的 Monads。\nPromise Monad\n\n什么？这不是 Promise，这是一个异步 Monad 。我们这个异步 Monad 体积小方便携带，拆开一包，放 then 里就变出值，怎么 then 都有值，用来解决回调地狱，做异步都是很好用的。你看打开以后像 Monads 一样的结构，放在事件循环里，你看它遇 resolved 变大变高，可用性很强的。打开以后，是一条加大加厚的 value，你看它怎么玩都玩不坏，不掉毛不掉絮，then 个七八次都没问题，异步函数带上它非常方便，你用它跑个 XMLHTTPRequest，跑个 fs.readFile，干净又卫生。什么？在哪里用？点击键盘 F12，开 Console，敲一行，看一行，还有结果。\n\n当我们写 JavaScript 的时候，应该感谢 Monads 的伟力。显然 Promise （删掉 catch）本质上是一个 Monad：\nconst monad_promise = {\n  pure: Promise.resolve as <T>(t: T) => Promise<T>,\n  bind: Promise.prototype.then as <T, U>(\n    this: Promise<T>,\n    fn: (t: T) => Promise<U>\n  ) => Promise<U>,\n};\n有了 Promise Monad，之前的回调地狱就这样变成了\nPromise.resolve(3)\n  .then((x) => x + 4)\n  .then((x) => x * 2)\n  .then((x) => some_api(x));\n同样的，Javascript 也提供了像 do notation 那样消除显式的 then 的工具，也就是 async\nasync function () {\n  let x = await Promise.resolve(3);\n  x = await add4(x);\n  x = await somefunc(x);\n  x = await some_api(x);\n  return x\n}\n起到了将异步函数打成看上去像同步一样的效果。\n总结\n所以并非只有函数式语言，我们其实已经应用了许多的 Monads 到实践中。Monads 将链式的控制流封装起来，提供统一的表达方式，从而提高代码的可读性。"},{"type":"post","id":"pfpl-note-6","title":"PFPL 笔记 - VI Dynamic Types","url":"/blog/pfpl-note-6/","content":"笔记 6\n最详细的一集，因为我要讲解这部分（摊手\n但是读得很开心！这章真是让我受益匪浅啊！\n\nChapter 17 The Untyped Lambda Calculus\n许多实际使用的编程语言宣称自己是无类型的（untyped），然而这只是一种假象。这些语言实际上是单一类型的(uni-typed)而非无类型。\nLambda 演算，丘奇于 1930 年提出。它唯一的“特性”就是高阶函数（higher-order function），即：\n\n\n一切都是函数，\n\n\n每个表达式都可以被应用于一个参数，而该参数本身也必须是一个函数，\n\n\n最终的结果仍然是一个函数。\n\n\n\nSee also: Learn Lambda Calculus in Y Minutes\nStatics\nThe statics of \\mathcal L\\{\\lambda\\} is defined by general hypothetical judgments of the form\nx1 ok, x2 ok, ..., xn ok |- u ok\nstating that u is a well-formed expression involving the variables x1 ~ xn\n\n\n若 x 在环境 Γ 中已声明为合法，则 x 本身是合法的。\n若 u₁ 和 u₂ 都是合法表达式，则它们的应用 ap(u₁; u₂) 也是合法的。\n若在环境 Γ 下 x ok 则 u ok 则 λ(x . u) 也是合法的。\n\nDynamics\nλ-演算的 dynamics 不是通过传统的 transition system 来定义，而是通过 equaitonally（至少 PFPL 里这样定义）\nDefinitional equality for L is a judgment of the form \\Gamma \\vdash u, u', where \\Gamma \\vdash x1 ok,...,xn ok for some n 0, and u and u’ are terms having at most the variables x1 … xn free. It is inductively defined by the following rules\n\n\n自反性\n\\dfrac{}{\\Gamma, u \\text{ ok} \\vdash u \\equiv u}\n\n\n对称性\n\n\n\\dfrac{\\Gamma, u \\text{ ok} \\vdash u \\equiv u'}{\\Gamma, u \\text{ ok} \\vdash u' \\equiv u}\n\n传递性\n\n\\dfrac\n{\\Gamma, u \\text{ ok} \\vdash u \\equiv u' \\quad \\Gamma, u \\text{ ok} \\vdash u' \\equiv u''}\n{\\Gamma, u \\text{ ok} \\vdash u \\equiv u''}\n\n……\n\n\nWe often write just u \\equiv u' when the variables involved need not be emphasized or are clear from context.\nDefinablity\n无类型 λ-演算的一个重要特性是它的表达能力。它是一个图灵完备（Turing-complete） 的语言，也就是说，它和任何已知的编程语言一样，都可以表达自然数上的所有可计算函数。\nChuch’s Law: 任何可计算的函数都有其 Lambda Calculus 等价表达\n作为例子，我们证明 lambda 演算至少和 PCF 一样强：\n我们可以用 lambda 的形式定义自然数，which 叫 丘奇数\nChurch Numerals\n为了懒得打 latex 下面用 \\a -> b 表示 \\lambda(a)b\n    0 = \\b -> \\s -> b\nn + 1 = \\b -> \\s -> s(n(b)(s))\n表示原文的\n\n注意到，b 可以解释为 blank，或者说初始值， 而 s 可以解释为 successor\n也就是说这里定义了 0 是用 blank 和 successor 两个组合子构造出的一个 lambda，\n这样，运用 successor 到 n(b)(s) i.e. 用 b，s 实例化了的 n 就能得到 n + 1\n另外一个有趣的事情是，当我们得到 n 这个 丘奇数（它自己也是一个函数）的时候，显然 n f g 是 g(g(g(... n个g...(f))))，也就是说这个数字就能用来作为 n-fold\n比如展开后\n1 = \\b -> \\s -> s(b)\n2 = \\b -> \\s -> s(s(b))\n3 = \\b -> \\s -> s(s(s(b)))\n...\n那么自然数运算也就很好理解了\n\n举例\nsucc = \\x -> \\b -> \\s -> s(x(b)(s))\n故\nsucc 0  = \\b -> \\s -> s( 0(b)(s) )\n        = \\b -> \\s -> s(b)\n        = 1\nplus = \\x -> \\y -> y(x)(succ)\n可以理解为\nplus x y 就是将 x 作为初始值，调用 y (x) succ 当然就是 “x + y”\n例如，展开 plus 1 2\n= 1(2)(succ)\n= (\\b -> \\s -> s(b))(2)(succ)\n= succ(s(2))\n= 3\n对于乘法\ntimes = \\x -> \\y -> y(0)(plus(x))\n则是将原先的 successor 换成了 plus(x) 后的新 y，显然这就是 y * x\ntimes 2 2\n= 2(0)(plus 2)\n= (\\s -> s(s(0)))(plus 2)\n= plus 2 (plus 2) 0\n= 4\n\n一些简单验算\nghci> b = 0\nghci> s x = x+1\nghci> zero = \\b -> \\s -> b\nghci> succ = \\x -> \\b -> \\s -> s(x(b)(s))\nghci> ghci> succ zero b s\n1\nghci> plus = \\x -> \\y -> y(x)(succ)\nghci> one = succ zero\nghci> one b s\n1\nghci> plus one one b s\n2\nghci> two = succ one\nghci> plus one two b s\n3\n\n要定义 ifz(u; u0; x.u1) 需要一些技巧，因为我们需要找到一个前驱函数 pred\npred 0 = 0\npred (n + 1) = n\n这并不是听起来那么容易 因为相当于我们需要能把一大坨的高阶函数里的 s(n) 的 n 拿出来，而且还需要考虑 0 的存在\n可以借鉴移位的思想，如果有 (n-1, n) \\to (n, n+1) 的推导就能很容易拿到 n - 1\nChurch Pairs\n先定义丘奇风格的 pair\n(括号好多懒得打……不如把 f(a)(b) 写成 f a b 好了)\npair u1 u2 = \\f -> f u1 u2\n\nleft  u = u(\\x -> \\y -> x)\nright u = u(\\x -> \\y -> y)\n\n然后，注意到我们之前定义的 Church Numeric 的 b 和 s 都是可以替换成任意的实例的！因此，只需要把 <0, 0> 作为 b 传入，就能获得一个带有 predecessor 的 Church numberic.\n\npred' = \\x -> x ([0, 0])(\\y -> [right y, succ(right y)])\npred  = \\x -> right (pred' x)\n这样我们就获取了需要的 pred 函数。这样，ifz 也很好定义了\nifz u, u0, x, u1 = u(u0)(\\never -> [(pred u)/x] u1)\n现在我们还差 general recursion。一如既往地，lambda calculus 的函数是没有名字的，我们需要得到一个 fix 让 general recursion 存在\nY 组合子\n最出名的 fix point combinator 是 Y 组合子\n\nY = \\F -> (\\f -> F(f(f))) (\\f -> F(f(f)))\n验算\nY(F)\n= (\\f -> F(f(f)))(\\f -> F(f(f)))\n= F((f)(f)) where f = \\f -> F(f f)\n= F(\n  (\\f -> F(f(f)))(\\f -> F(f(f)))\n  )\n= F(Y(F))\n看到这里我非常的震撼，人们是如何构造出这样神奇的组合子的？原书接下来做了解释：\n让我们抛开内存和地址空间这些不谈。假如有一个函数\nfunction fib(x) {\n  return x > 1 ? fib(x - 1) + fib(x - 2) : 1;\n}\n现在我们忘记函数可以有名字。为了还能实现递归，自然而然的，我们会尝试加一个参数，self 或者 this 之类的，这样这个函数就知道了自己是什么。\nfunction tmp(self, x) {\n  return x > 1 ? self(self, x - 1) + self(self, x - 2) : 1;\n}\nfunction fib(x) {\n  reutnr tmp(tmp, x);\n}\n注意到 tmp(tmp, ...args) 的存在！为了更好看出来，我们把它写成柯里化的 lambda 函数\nconst tmp = (self) => (x) => {\n  return x > 1 ? self(self)(x - 1) + self(self)(x - 2) : 1;\n};\nconst fib_1 = (x) => {\n  return tmp(tmp)(x);\n};\n// 然后 x 可以消掉\nconst fib = tmp(tmp);\n// fib\n因此，对于任何一个我们需要递归的函数 F = \\self -> 函数体, 构造\nF' = \\f -> F(f(f))\n能帮我们把每次 F 里的 self 换成 self(self)\n此时观察到\nF'(F') == F(F'(F'))\nF'(F') 就是我们想要的 F 的不动点。现在把它展开，就得到了\n(\\f -> F(f(f)))(\\f -> F(f(f)))\n于是我们就得到了 Y 组合子，可以得到任意 F 的 fixed point\nScott’s Theorem\nScott 定理表明：\n\n在无类型 λ-演算中，定义相等性是不可判定的，即不存在算法可以确定两个 λ-项是否相等。\n\ninseparability\n\\mathcal A_0 和 \\mathcal A_1 是 insparability (不可区分的)，当且仅当没有一个决定性的属性 \\mathcal B such that\n\n\\mathcal A_0 \\ u implies \\mathcal B \\ u\n\\mathcal A_1 \\ u implies not the case that \\mathcal B \\ u\n\nbehavioral\n\\mathcal A 是 behavioral (行为属性)，当且仅当 u \\equiv u' 则 \\mathcal A iff \\mathcal u'\nScott 定理有两部分：\n\n\n任何两个非平凡的属性 A 和 B 是不可区分的\n\n（如果某个属性对所有 untyped terms 都成立，或者对任何 untyped terms 都不成立，则该属性被称为平凡的。）\n\n\n也就是说这里引入了一个构造 v 是 w(x) 的反面，同时根据 lemma 17.1 它又得能接受一个自身到自身，所以矛盾了\n这里放点我自己的思考不知道对不对\n我们应该也能用图灵机的停机问题的思想去证明 Scott 定理。（虽然维基百科说 Scott’s Theorem 比停机问题还早 XD）\n\n在 1936 年邱奇利用 λ 演算给出了对于判定性问题（Entscheidungsproblem）的否定：关于两个 lambda 表达式是否等价的命题，无法由一个“通用的算法”判断，这是不可判定性能够证明的头一个问题，甚至还在停机问题之先。 ——维基百科\n\n首先，Lambda 演算的停机问题也是不可判定的，可以直接照搬图灵机的证明\n定义 λ-演算的停机：给定一个 λ-项 M 如果经过有限步 β-归约后到达一个正常形式（normal-form），即不再能进行 β-约简，则称 M 停机。\n如果存在 lambda 演算 Halt 可以判定一个 lambda 演算 F 在参数 args 的时候是否停机，比如\n\nHalt(F)(args) = 0 当F停机\nHalt(F)(args) = 1 当F不停机\n\n则我们可以构造一个 U\nU = \\P -> ifz(Halt(P)(P); Y(Y); 0)\n\n则考虑 Halt(U)(U)，\n若 Halt(U)(U) = 0，则 U(U) 应当跑一个无限递归，矛盾\n若 Halt(U)(U) = 1，则 U(U) 应当直接返回0，不停机，矛盾\n\n所以不存在一个lambda演算 Halt 可以判定任意 lambda 演算 F 在参数 args 的时候是否停机。\n利用停机问题不可判定性，\n如果 lambda 演算 Equiv 能判定两个 lambda 演算是否相同 （相同返回0，不同返回1）\n则构造\n\nA = \\f -> \\args -> 0\nB = \\f -> \\args -> ifz(f(args); 0; 0)\n\n（我们假定 f(args) 应该在停机的时候得到一个 church numeral）\n\n那么A 和 B 相同当且仅当 f(args) 停机。Equiv 规约到停机问题，故不存在。\n还有一些有趣的补充\n\n无类型的 λ 演算系统被证明在用于逻辑系统的时候是不自洽的——在 1935 年斯蒂芬·科尔·克莱尼和 J. B. Rosser 举出了 Kleene-Rosser 悖论\n\n考虑 P = \\lambda (f) \\neg f(f) 则 P(P) = \\neg P(P) 所以我们可以找到一个等于其否定的项。\n这提醒我们，有必要清楚地区分哪些 lambda 项可以代表命题，哪些 lambda 不能，这导致了项的类型概念。\nUntyped MeansUni-Typed\n无类型的 λ 演算可以被忠实地嵌入到具有递归类型的类型语言中。这意味着每个无类型 λ 项都可以表示为一个带类型的表达式，使得表示的执行对应于项自身的执行。\n这种嵌入并不是通过在 L 中编写一个解释器（这当然是可以实现的），而是通过直接将无类型 λ 项表示为具有递归类型的带类型表达式。\n关键观察是：无类型的 λ 演算实际上是单类型的 λ 演算。赋予其强大功能的并非类型缺失，而是它只有一个类型，即递归类型\nD = μt.t → t\nD 类型的值形式为 fold(e)，其中 e 是 D→D 类型的值——一个其定义域和值域均为 D 的函数。-任何这样的函数都可以“卷起”被视为 D 类型的值，而任何 D 类型的值都可以“展开”转换为函数。递归类型通常可以被视为类型同构方程的解，此处的方程是 D = D → D。这表明 D 是一个与其自身上的函数空间同构的类型，这在传统的集合论中是不可能的，但在基于计算的 λ 演算环境中是可行的。\n\n由此可见，所谓的无类型语言 L{ lambda } 尽管在术语上与类型语言相对立，实际上仍然是一种带类型的语言。无类型语言并非消除了类型，而是将无限集合的类型合并为一个递归类型。这使得静态类型检查变得 trivial，但代价是在值与递归类型之间进行强制转换时带来了显著的动态开销。\n在第 18 章中，我们将更进一步，允许许多不同类型的值（而不仅仅是函数），每种类型都是“主”递归类型的组成部分。这表明所谓的动态类型语言实际上是静态类型语言。因此，这一传统区别几乎不能被视为对立，因为动态语言不过是静态语言的一种特殊形式，强调了一个递归类型。\nChapter 18 Dynamic Typing\n17 章介绍了 untyped lambda calculus，其中所有 term 都同构于一个函数。因此，不会因为值的误用而发生运行时错误，因为所有参数都是函数。\n但一旦语言中允许不止一类值，这个特性就会失效。例如，如果我们将自然数作为 primitive 添加到无类型演算中（而不是通过 Church 编码定义它们），那么尝试将数字应用于参数或将函数添加到数字时可能会引发运行时错误。\n语言设计中的一种思想流派是将这种缺点转化为优点，即采用一种具有单一类型 (type), 多个值类 (value class) 的计算模型。这种语言被称为动态类型语言，与静态类型语言相对立。但这种所谓的对立是虚幻的：正如所谓的 untyped 演算实际上是 uni-typed 类型的一样，动态语言最终也只是静态语言的受限形式。这句话非常重要，值得重复：每种动态语言本质上都是静态语言，我们将自己限制在（不必要的）受限类型规则中以确保安全。\nDynamically Typed PCF\nDynamically typed version of \\mathcal L \\{\\text{nat} \\rightharpoonup \\} called \\mathcal L \\{dyn\\}\n\n现在我们有两种 value： numbers 和 functions。succ 和 zero 不是值，在这里是一种算符，来产生 value.\n递归虽然可以用 fixed point combinator 定义，但是我们这里把它定义成原型类型 (primitive) 来简化 chapter 18.3 中的分析。\n对于这些动态语言来说，具体语法往往具有欺骗性，因为它掩盖了抽象语法的一个重要细节：即每个值都标有一个在运行时发挥重要作用的分类器(classifier)（我们很快就会看到）。\n因此，尽管数字 n 的具体语法只是单纯地 \\overline n ，但抽象语法表明该数字被标记为类别(class) num，以表明该值属于数字类别。这样做是为了将其与函数值区分开来，函数值具体具有形式 \\lambda (x) d，但其抽象语法 fun 表示要用标签 fun 对其进行分类，以将其与数字区分开来。\n\n注：这里你可以认为 tag 是变量类别 class（而非类型，type）的 id\n\n这种标记在任何动态语言中都是至关重要的，因此，在下文中密切关注抽象形式非常重要。\nStatics\n显然。而之前一样，只需要检验一下 expression 里面有没有自由变量就行。\nx_1 \\text{ ok}, ..., x_n \\text{ ok} \\vdash d \\text{ ok}\nDynamics\n作为动态语言的 \\mathcal L \\{dyn\\} 需要检查之前 \\mathcal L \\{\\text{nat} \\rightharpoonup \\} 永远不可能发生的一些错误。比如，函数调用的时候需要判断一下那个被调用的是不是真的是一个函数。\n\n注意后四条判断只有在 d val 的时候有意义。这些 affirmative class checking judgments 第二个参数代表的是 value 的底层结构，它本身不是 value。\n\nLemma 18.1 (Class Checking) 如果 d val 则\n\neither d is_num for some n or d isnt_num;\neither d is_fun x.d’ for some x and d’, or d isnt_fun\n\n证明显然。\nTheorem 18.2 (Progress): If d ok then either d val or d err, or there exists d’ such that d \\mapsto d'\nTheorem 18.3 (Exclusivity): 对此语言中的任意 d ，下面恰有一个成立：d val, d err, d \\mapsto d' for some d’\nVariations and Extensions\n在之前的 \\mathcal L \\{\\text{nat} \\rightharpoonup \\} 中我们使用 zero 和 succ 来定义 nat。在 \\mathcal L \\{dyn\\} 中，我们直接定义了 numberals。这样做是为了确保只有一个数字类，而不是 zero 和 succ 两个单独的 class。\n另一种方法是将 zero 和 succ(d) 视为两个单独 class 的值，并为它们分别引入 class checking 判断。这会使错误检查规则复杂化，并允许出现有问题的值，例如 succ(lambda (x)d)，但它允许我们避免使用 class of numbers。当以这种风格书写时，条件分支的 dynamics 如下所示：\n\n注意 successor class 的前驱不一定要是一个 number，虽然我们前面的公式不可能产生这种可能性。\n接下来结构化数据也是容易加入的。\n\n注意上面这个函数，显然，你可以直接把任何值用在这两个函数上，无论它们是不是列表。如果 arg1 不是列表，会产生错误并终止，但是该函数不会遍历参数 arg2，所以 arg2 是任何值都可以。\n有人会觉得，用 null 来分辨 pair 不是合适的，因为这语言包含不止这两种 classes。一种可能的手段是，完全放弃 pattern matching 想法，直接用 general 的 conditional branch 去分辨 null\n\n\n此处引入一个小插曲：为什么叫 cons 和 car 和 cdr 呢？小编也很好奇\n这是来自 lisp 的习惯，在 1950s Lisp 最早被实现的时候，car 和 cdr 分别是两个寄存器：\n\ncar (“contents of the address part of register number”) “寄存器号地址部分的内容”\ncdr (“contents of the decrement part of register number”), “寄存器号递减部分的内容”\n\n而 cons 直接是 constructor 的缩写，指的是 list 的构造子\n\n现在 append 可以用下面的公式给出：\nfix a is \\x -> \\y -> cond(x; cons(car(x); a(cdr(x))(y)); y)\n\n看不太清的话就是\nappend x y = case cond x of\n  anyhow -> cons (car x) (append (cdr x) y)\n  nil -> y\n\n这种 append 公式的行为与之前的公式没有什么不同；唯一的区别是，我们不再根据值是否为 nil 或 pair 来进行分派，而是根据值的谓词来进行区分，其中包括特殊情况的检查。\n还有另一种方式，即增强而非限制条件分支，让它包含语言中所有可能的值类别，比如在具有 num, fun, null, pair 的的语言中，条件将会有四个分支。这种方法的困难是，现实语言中会有许多数据类型，这样会非常笨重。\n此外，即使我们已经对值的类别进行了指派，与该类别的原始操作也需要进行运行时检查，例如，我们可以确定值 d 属于数字类，但没有办法将此信息传播到条件分支中。加法运算仍然必须检查 d 的类别，获取底层数字，并创建一个新的数字类值。这是动态语言的固有限制，它不允许处理除分类值之外的其他值\nCritique of Dynamic Typing - 对动态类型的批判\n像 \\mathcal L \\{dyn\\} 这样的语言的 safety theorem 经常被宣传为动态类型相比于静态类型的优势。与排除了某些类型错误的静态语言不同， \\mathcal L \\{dyn\\} 中的每一段抽象语法基本上都是格式良好的，因此，根据定理 18.2，具有定义良好的动态性。\n但这也可以看作是一个缺点，因为在 \\mathcal L \\{dyn\\} 中，本该通过类型检查在编译时排除的错误直到运行时才会显现。并且为了实现这一点， \\mathcal L \\{dyn\\} 的 dynamic 必须强制执行静态类型语言中不需要检查的条件。\n考虑加法\n\\x -> fix p is \\y -> ifz y { zero => x | succ(y') => succ(p(y'))}\n注意到，fix pointer 把 p 绑定到了该函数，这意味着在递归调用中，ap(p) 的动态检查总是会成功，但是 \\mathcal L \\{dyn\\} 没有办法取消这种冗余检查，因为它没有能力表达 that “p 始终的将绑定到一个不变的 function”。\n其次，内部的 lambda-abstraction 的 apply 要么是 x，要么是 x 的递归的 successor。也就是说除了基本情况外后面的情况都可以保证通过 class check，但我们没有能力表达这一点，successor 只能每次都老老实实地进行 class check\nClassification 不是免费的——tag 需要存储空间，每次使用时都需要花时间将类与值分离，每次创建类时又需要花时间将类附加到值上。虽然分类的开销不是渐近显著的（它只会使程序变慢一个常数），但它仍然是不可忽略的，应该尽可能消除。但这在 \\mathcal L \\{dyn\\} 中是不可能的，因为它无法表达所需不变量所需的限制。\n为此，我们需要一个静态类型系统。\nChapter 19 Hybrid Typing\n混合语言是一种将静态类型和动态类型相结合的语言，它通过为静态类型语言添加一个独特的动态值类型 dyn 来丰富它。\n第 18 章中讨论的动态类型语言可以通过将动态类型程序视为 dyn 类型的静态类型程序来嵌入到混合语言中。这表明静态类型和动态类型并不相互对立，而是可以和谐共存。\n然而，混合语言的概念本身就是虚幻的，因为 dyn 类型实际上是一种特殊的递归类型。不需要任何特殊的机制来支持动态类型。相反，它们可以从更一般的递归类型概念中派生出来。此外，这表明动态类型只是静态类型的一种使用方式。因此，动态类型和静态类型之间的所谓对立是一种谬论。动态类型只是静态类型的一种特殊情况。\nA Hybrid Language\n\n这里的 new 当然和 C++ 里的不一样，这里的 new 是添加一个 classifier 到 value，而 cast 是检查这个 classifier，然后返回对应的 value。\n\n几个定理：\n\n有 sum type 和 recursive type 的语言里 dyn 不需要是一个 primitive。\n\nDynamic as Static Typing\n\\mathcal L \\{dyn\\} 可以嵌入到 \\mathcal L \\{\\text{nat dyn } \\rightharpoonup\\} 中，只需要一个简单的翻译\n\nOptimization of Dynamic Typing\n考虑之前提到的那个加法函数。\n\n我们之前已经指出它具有大量可以在静态类型版本中消除的开销。消除这些开销需要静态类型\n\n由于动态语言只能表示一种类型的值，因此不可能在动态语言中表达优化后的形式。动态语言所声称的自由——即由于省略了类型而带来的灵活性——实际上对语言的表达能力施加了严重的限制，相比之下，具有动态值类型的静态语言则更具表现力。\n\n首先，关于前文所说 p 绑定递归的低效性。我们只需要简单地把 p 的类型改成 dyn -> dyn 就能直接表达 p 是一个作用于动态值函数的不变量。\nfun ! λ (x : dyn) fun ! fix p : dyn -> dyn is λ (y : dyn) e'(x,p,y')\n其中 e'(x,p,y') 是\nifz (y ? num) { zero ⇒ x | succ(y') ⇒ num ! (s(p(num! y') ? num)) }.\n这样，循环内部的 p 就无须 tag check 了。\n接下来，观察到类型为 dyn 的参数 y 在每次循环迭代时都会被转换为一个数字，然后才会被测试是否为零。由于此函数是递归的，参数 y 在两种情况下会绑定到值：\n\n在最初调用加法函数时。\n在每次递归调用时。\n\n但是，递归调用是在 y 的 predecessor 上进行的，而前驱一定是一个自然数。在调用点上，它被标记为 num，但在下一次迭代的条件检查中却会被移除。这表明，我们应该在循环外部就对 y 进行类型转换，避免在递归调用中对参数进行类型转换。\n这样做会改变函数的类型，从 dyn -> dyn 变为 nat -> dyn。因此，还需要进一步更改，以确保整个函数保持类型正确。\n继续观察。递归调用的结果会进行检查，以确保其类别是 num，然后对底层值进行递增，并将其标记为 num。如果递归调用的结果来自条件语句的这个分支，则显然类别检查是多余的，因为我们已经知道它必须具有 num 类别。但如果结果来自条件语句的另一个分支呢？在这种情况下，函数返回 x，但 x 不一定是 num，因为它是由函数的调用者提供的。然而，我们可以合理地认为，向加法函数传递非数值参数是一个错误。这可以通过将条件分支中的 x 替换为 x ? num 来强制执行。\n结合这些优化，我们得到内循环 e''(x) 的最终形式如下：\nfix p : nat -> nat is λ (y : nat) ifz y { zero ⇒ x ? num | succ(y') ⇒ s(p(y')) }.\n这个函数的类型是 nat -> nat，并且在应用于自然数时会以全速运行——所有的检查都已经从内部循环中移除。\n最后，回顾一下我们的整体目标：我们希望定义一个加法函数，该函数作用于 dyn 类型的值。因此，我们需要一个 dyn -> dyn 的值，而当前我们得到的是 nat -> nat。可以通过在前面预加一个 num 类型转换，并在后面加一个 num 类型的强制转换来获得所需的形式：\nfun ! λ (x : dyn) fun ! λ (y : dyn) num ! (e''(x) (y ? num)).\n最内层的 λ-抽象 通过组合类检查将 e”(x) 从 nat -> nat 转换为 dyn -> dyn，确保 y 在初始调用时是一个自然数，并将结果重新标记为 dyn。\n这些转换的结果是，计算的内部循环可以“全速”运行，不需要对函数或数字进行 tag check。而加法函数的最外层仍然保持为 dyn 类型的值，它封装了一个柯里化函数，接收两个 dyn 类型的参数。这种方式保留了所有对加法函数的调用的正确性，即传递和返回 dyn 类型的值，同时优化其执行过程。\n当然，我们还可以去除加法函数的类标签，将其类型从 dyn 更改为更具描述性的 dyn -> dyn -> dyn。但这要求调用者不能将加法视为 dyn 类型的值，而必须将其视为一个函数，该函数必须依次应用于两个 dyn 类型的值，并且它们的 class 必须是 num。如果程序员可以控制在哪里调用该函数，就可以进行这样的转换，并不会有什么问题。只有在可能存在程序员无法直接控制的外部 call 时，才有必要将加法函数封装为 dyn 类型的值。\n从这个原则出发，我们可以得出一个更广泛的结论：动态类型的作用仅限于系统的“边缘”，即那些涉及不受控制的调用的地方。在系统的内部，仅使用 dyn 类型没有任何好处，反而会带来相当大的弊端。\nStatic Versus Dynamic Typing\n动态类型的支持者曾试图通过各种方式区分动态语言和静态语言。我们可以从当前的视角来重新审视这些所谓的区别。\n\n\n“动态语言将类型与值关联，而静态语言将类型与变量关联。“\n但这种说法是错误的，源于将“类型”（types）与“类别”（classes）混淆的错误认识。动态语言实际上是通过标记（tagging）来将 class 与 value 关联，比如使用 num 和 fun 这样的标识符。这种分类方法本质上等同于在静态类型语言中使用递归和 sum types。因此，这并不是动态语言的一个独特特性。此外，静态语言不仅为变量分配类型，还为表达式分配类型。由于动态语言本质上是一种特殊的静态语言（仅包含单一类型），因此它们同样也为表达式分配类型。\n举一点现实语言的例子。比如 C 标准库的 qsort 为\nvoid qsort(\n    void* ptr, size_t count, size_t size,\n    int (*comp)(const void*, const void*)\n);\n其实这里的 void* 就充当了某种 dyn 的作用。C++ 中也有更现代的 std::any\n#include <any>\n#include <iostream>\nint main() {\n  std::any a = 1;\n  std::cout << a.type().name() << \": \" << std::any_cast<int>(a) << '\\n';\n  a = 3.14;\n  std::cout << a.type().name() << \": \" << std::any_cast<double>(a) << '\\n';\n  a = true;\n  std::cout << a.type().name() << \": \" << std::any_cast<bool>(a) << '\\n';\n\n  // Outputs:\n  // double: 3.14\n  // bool: true\n  // bad any_cast\n}\n\n\n“动态语言在运行时检查类型，而静态语言在编译时检查类型。“\n这也是一个错误的说法。动态语言和静态语言在本质上都是静态类型的，只不过动态语言采用了一种退化的类型系统，即只有一个类型。如我们所见，动态语言确实会在运行时进行类别检查（class checks），但静态语言中如果允许 sum types，同样也需要执行类别检查。真正的区别仅在于类别检查的使用范围：在动态语言中，类别检查是始终必须的；而在静态语言中，类别检查只在必要时才会进行。\n\n\n“动态语言支持异构集合，而静态语言只支持同构集合。”\n（这句话说的是，你可以在动态语言中构造 [1, true, \"foo\", { bar: null }] 这样元素类型不同的集合，而这些人认为静态语言中做不到这一点）\n这同样是一个错误的说法。静态语言中的 sum types 本来就是用于支持异构数据的，任何支持 sum type 的静态语言都可以表示异构数据结构。例如，考虑以下列表：\ncons(num(1); cons(fun(λ(x)x); nil))\n有人认为在静态语言中无法表示这样的列表，因为它的元素类型不同。然而，无论是在静态语言还是动态语言中，这种列表实际上都是类型同构（type homogeneous）的，只不过它的元素类别可能是异构（class heterogeneous）的。在上述列表中，所有元素的类型都是 dyn，但第一个元素的类别是 num，第二个元素的类别是 fun。\n在这里我们甚至也能给出一个现实生活的例子： Crystal 语言。一个编译的、native 的静态语言。它支持以类型 itself 为 tag 的 sum type（或者被叫作 union type），所以你很容易写出\narr = [] of (Int32 | String)\narr.push(1)\narr.push(\"qwq\")\nputs arr # 输出 [1, \"qwq\"]\n这很好的打破了这句话。\n\n\n所以，我们该如何看待动态语言和静态语言之间的这种所谓的区别呢？\n与其说它们是对立的，不如说动态语言实际上是静态语言的一种使用方式。每一种动态语言本质上都是一种静态语言，只不过它的类型系统极为有限（只有一个类型！）。然而，正如我们之前所看到的，类型对于程序的正确性和效率至关重要，它们不仅用于表达程序的不变性（invariants），还用于强制执行这些不变性。因此，动态语言的“自由”实际上是一种受限的自由，牺牲了类型信息所能提供的优势。\n\n版权声明： CC BY-NC-SA 4.0"},{"type":"post","id":"pfpl-note-5","title":"PFPL 笔记 - V Infinite Data Types","url":"/blog/pfpl-note-5/","content":"笔记 5\n\nInductive and Co-Inductive Types\ninductive type 一个很直观的例子是自然数类型 nat\n之前的定义是\nzero : nat\nn: nat |- succ(n) : nat\n现在我们引入新的定义\nGamma |- e : unit + nat\n------------------\nGamma |- fold(nat, e) : nat\nfold(nat, e) 是 nat 的唯一引入形式。在这样的表达式里， z 被定义为 fold(nat, l) 而 s(e) 被定义为 fold(nat, e)\n另一个不错的例子是 stream. 熟悉 Haskell 的会知道 Haskell 内存在无限列表这样的东西。\n在之前，我们的递归类型需要递归到把所有值都计算出来，stream 相反，需要什么就计算什么\n\n其中 hd(e) 为 head of the stream"},{"type":"post","id":"pfpl-note-4","title":"PFPL 笔记 - IV Finite Data Types","url":"/blog/pfpl-note-4/","content":"Practical Foundations for Programming Languages 是 Robert Harper 的一本书，而这是我写的笔记 4\n\nChapter 11 Product Types\n可以参照 C++ 的 sturct 类型\n定义 \\tau_1 \\times \\tau_2 为两个类型的 product，这个新类型包含两个类型。e = <e_1, e_2> 可以用 e.l e.r 取出 e 的 left 和 right projection\n\n定义了 pair (binary product) 以后，一个 finite product (tuple) 也就很容易了。\n\n在 product 上，我们可以简化第 9 章中定义的原始递归构造，以便只有前一个结果而不是前一个本身的结果被传递给后继分支。将其写为\n同时在 product 上我们还能定义两个相互引用的递归函数，这是之前做不到的\n\\tau_EO :: <even :: nat -> nat, odd :: nat -> nat>\n\nfix this: \\tau_EO is <even = e_E, odd = e_O>\n\nwhere e_E = \\lambda (x: nat) ifz x { z => s(z) | s(y) => this.odd(y) },\n      e_O = \\lambda (x: nat) ifz x { z => z | s(y) => this.even(y) }\nChapter 12 Sum Types\n可以类比为 Typescript 的 | 类型，或者说 Rust 的 union 类型\n(更正：typescript 的 | 类型并不是 sum type，考虑 i32 + i32 ，应该有 33 的信息熵，但 Ts 的 i32 | i32 只有 32 )\n\n从 Sum Types 中我们很容易得到一个 bool 类型：\n\n当然，从 sum types 中我们显然能得到 Option<T> 类型\n\nChapter 13 Pattern Matching\n模式匹配是乘积和和类型的消去形式的自然而方便的推广。例如，与其写\nlet x be e in x.l + x.r\n来将 pair 的两对加起来，有了 pattern matching 我们可以写出\nmatch e { <x_1, x_2> => x_1 + x_2 }\n同样的，pattern matching 可以在 sum type 上，比如\n\\text{match} \\{ <l \\cdot <>, x> \\Rightarrow x + x | <r \\cdot <>, y> \\Rightarrow y * y \\}\n\nChapter 14 Generic Programing\n\nTODO"},{"type":"post","id":"pfpl-note-3","title":"PFPL 笔记 - III Functional Types","url":"/blog/pfpl-note-3/","content":"Practical Foundations for Programming Languages 是 Robert Harper 的一本书，而这是我写的笔记 3\n\nChapter 8 Function Definations and Values\n这一章我们尝试往 \\mathcal L \\{\\text{num str}\\} 中引入函数。\n首先尝试引入 First order 函数。我们直接引入两个 expression call[f](e) 和 fun[t1;t2](x1.e2; f.e) 分别为 call 和 defination\n容易发现这样的定义并没有什么必要，为了将函数排除到 type 之外引入了不必要的额外的替换工作。所以引入 Higher Order Functions （箭头）\ntype arr(t1, t2) 记为 \\tau_1 \\to \\tau_2 为函数类型\nexp lam[\\tau](x,e)计为 \\lambda(x:\\tau)e 为 abstraction\n新的语言记做 \\mathcal L \\{\\text{num str} \\to\\}\n\nChapter 9 Godel’s T\n\\mathcal L \\{\\text{nat} \\to\\} 哥德尔的 System T 为函数引入了递归的可能性。这个递归非常类似于数学归纳法：所有递归都是有限的。\n\n表达式 rec(e;e0;x.y.e1) 称为原始递归。\nGodel’s T 和之前介绍的语言都必定停机。\nChapter 10 Plotkin’s PCF\n\\mathcal L \\{\\text{nat} \\rightharpoonup \\} 是 Plotkin’s PCF。引入了一个 fix 操作，允许函数无限制的自我递归。\nPlotkin’s PCF 是图灵完备的。"},{"type":"post","id":"cuthair20250209","title":"2/9/2025","url":"/blog/cuthair20250209/","content":"陪伴我 4 年的及腰长发其实都到臀部了今日卒，谨以此发文对其表达深切的悼念（）"},{"type":"post","id":"zig-first-experience","title":"更好的 C 语言：Zig 初体验","url":"/blog/zig-first-experience/","content":"久闻 Zig 语言大名，作为一众底层语言的有力竞争者，Zig 被常常认为是 better C。Zig 自己也说，“Zig 与 C 竞争，而不是依赖于它”。前天用 Zig 写了一个简单的命令行跨平台贪吃蛇游戏，也算是体验了一下 Zig 的有趣功能。\n\nZig 核心\n照例先来写个 hello world 然后说一下 Zig 官方的简介：\nconst std = @import(\"std\");\n\npub fn main() !void {\n    std.debug.print(\"hello, world\\n\", .{});\n}\n\nZig 是一种简单的语言。\n专注于调试你的应用程序，而不是调试你的编程语言知识。\n\n没有隐式控制流。\n没有隐式内存分配。\n没有预处理器，没有宏。\n\n编译期代码执行\n基于编译期代码执行和惰性求值的全新元编程方法。\n\n编译期调用任意函数。\n在没有运行时开销的情况下，将类型作为值进行操作。\n编译期模拟目标架构。\n\n\n实际上在我的体验来看，Zig 这几个特色确实非常突出，可以说是这个语言最重要的特色甚至是基石了。\n没有隐式控制流\n其实我觉得这没什么特别大的必要，毕竟重载运算符还是一个很方便的语言特性的，但是 Zig 排除了它。\nZig 抛弃隐式控制流是为了可读性和可维护性。不过我觉得这更可能是一种 C with classes1 心理阴影（？\n一个不负责任的 C++C with classes 程序员有可能会写出这样的代码——\nvoid foo() {\n    auto some_resource = bar();\n    baz(&some_resource);\n    some_resource.close();\n}\n这看上去一点问题都没有，对吧。创建资源，使用资源，释放资源。这如果写成等价的的 C 语言是一点问题都没有的，可惜这是 C++。C++是有异常的，你在 baz 的时候说不定在调用栈的深处从哪抛出了一个异常，于是你的资源就没有释放——最常见的是内存泄漏，更坏一些的可能是网络资源或者文件资源，于是你的程序直接崩溃了，甚至丢失用户数据。\n拿 C with classes 的思路，抛弃 RAII2，不让人用异常却忽视 STL 中有大量异常。隐式控制流用好了非常好用，但是用得烂的话就是对可读性和可维护性的损失。而 Zig 是一门追求简洁的语言，于是它抛弃了它。\n如果 Zig 代码看起来不像是在调用一个函数，那么它就不是。这意味着你可以确定下面的代码只会先调用 foo()，然后一定会^[当然 foo() 有可能死循环或者在某处被你使用 panic 或者 std.process.exit(1) 之类的强制结束进程，导致 bar() 无法被执行。但是任何一个图灵完备的编程语言都没办法完全预防前者，这是停机问题。]调用 bar()，不需要知道任何元素的类型，这一点也是可以保证的：\nvar a = b + c.d;\nfoo();\nbar();\n没有隐式内存分配\n真是为嵌入式着想啊（赞美）\n对于许多桌面应用程序——也就是 Rust, C++, Go, Java 发光发热的地方，操作系统肯定会提供好的内存分配器，没有隐式内存分配完全就是增加复杂性，所以这个设计完全是为了 zig 一次编写到处运行的宏大理想而量身定制\nzig 语言完全没有任何隐式内存分配。包括标准库——除了那些本身就是用来做堆分配器的 API。所以只要你不用堆分配器，你的代码就不会有堆分配。这意味着你完全可以在裸金属环境下使用几乎全部标准库，而 C++ 和 Rust 都要排除掉依赖内存分配器的实用标准库。\n举个例子，当你想要一个双向链表的时候，Zig 提供的是这样的 API：\npub fn append(list: *Self, new_node: *Node) void\n// Insert a new node at the end of the list.\n\npub fn pop(list: *Self) ?*Node\n// Remove and return the last node in the list.\n\npub fn popFirst(list: *Self) ?*Node\n// Remove and return the first node in the list.\n\npub fn prepend(list: *Self, new_node: *Node) void\n// Insert a new node at the beginning of the list.\n注意到全部需要插入 *Node 类型！也就是说，Zig 把对 Node 进行内存分配的任务交给了你，你可以自由安排将它分配在什么位置，无论是堆上还是 buffer 上。Zig 给了程序员最大的自由来调配内存分配——这在底层开发、嵌入式开发中非常重要。\n当然这使得 Zig 程序需要到处传递 Allocator，使得在比较偏应用层的代码里比较难绷，不过 Zig 本来就不是设计出来干这种事情的——你也不会用 C 语言去写应用吧，自讨苦吃的事情还是少干（\n超强的 C 交互性\n说到嵌入式，许多嵌入式的机器，厂商只给了 C 库，如果是别的语言（除了 C++ ）的话，就不得不通过 C ABI 专门定义自己的函数来互操作了，到时候还得交叉编译，非常麻烦。所以就算 Rust 非常安全，也没什么人拿来用作嵌入式，大家还是老老实实写 C。\n而 Zig 就是破局者，因为 Zig 直接内置了 C 语言支持。和 C++ 不同的是，Zig 的 C 语言支持堪称十分明智，它提供了某种自动重写，你可以直接使用 @cImport 导入 C 语言的头文件，直接使用 C 语言的函数，而且还有完美的类型支持。\n比如我写的贪吃小游戏，为了直接读取键盘操作，需要用到操作系统给的库。Zig 没有对应的 std 支持怎么办？没关系，直接导入 windows.h\nconst std = @import(\"std\");\nconst c_windows = @cImport({\n    @cInclude(\"windows.h\");\n});\n\npub const GetchError = error{\n    CannotGetStdHandle,\n    ReadNotOk,\n};\n\npub fn getch_win() GetchError!i32 {\n    const stdin = std.os.windows.GetStdHandle(std.os.windows.STD_INPUT_HANDLE) catch {\n        return GetchError.CannotGetStdHandle;\n    };\n    var input_record: c_windows.INPUT_RECORD = undefined;\n    var _num_events_read: std.os.windows.DWORD = undefined;\n    while (true) {\n        const ok = c_windows.ReadConsoleInputW(stdin, &input_record, 1, &_num_events_read);\n        if (ok == 0) {\n            return GetchError.ReadNotOk;\n        }\n        if (input_record.EventType != c_windows.KEY_EVENT) {\n            continue;\n        }\n        if (input_record.Event.KeyEvent.bKeyDown != 0) {\n            continue;\n        }\n        return input_record.Event.KeyEvent.wVirtualKeyCode;\n    }\n}\n是的，只需要一个 @cImport， windows.h 里的所有函数就能为 zig 所用。 Zig 会自动将导入的 C 库重写成 Zig 的语法来提供合适的类型定义和语法高亮，完全和你用 zig 原生库一样简单——除了需要 C 风格的错误处理和字符串。真是应了深入了解 ⚡ Zig 编程语言那句话，Zig 比 C 更擅长使用 C 库。\n\n相比于 C++ 直接在语法上兼容 C 最后被 C 的历史遗留问题坑死，Zig 的做法简直明智多了，直接通过原生支持交叉编译互相导入来解决问题，一点历史包袱不负同时还兼顾了兼容性和迁移能力。\n另外，zig 编译器还可以直接编译和运行 C/C++代码。这更是为 zig 提供了逐步替换 C 项目的可能。想想看，想要为你的 C 项目引入 Zig 只需要把编译器换成 Zig，然后添加新的 Zig 文件愉快写代码就可以了，那有什么理由不试试呢？\n$ zig run prime_fast_cpp.cpp --library c++\nstart calculating\n1227 ms\n2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97, 101, 103, 107, 109, 113, 127, 131, 137, 139, 149, 151, 157, 163, 167, 173, 179, 181, 191, 193, 197, 199, 211, 223, 227, 229, 233, 239, 241, 251, 257, 263, 269, 271, 277, 281, 283, 293, 307, 311, 313, 317, 331, 337, 347, 349, 353, 359, 367, 373, 379, 383, 389, 397, 401, 409, 419, 421, 431, 433, 439, 443, 449, 457, 461, 463, 467, 479, 487, 491, 499, 503, 509, 521, 523, 541,\n\n$ zig run prime_fast.c --library c\nstart calculating\n1411 ms\n2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97, 101, 103, 107, 109, 113, 127, 131, 137, 139, 149, 151, 157, 163, 167, 173, 179, 181, 191, 193, 197, 199, 211, 223, 227, 229, 233, 239, 241, 251, 257, 263, 269, 271, 277, 281, 283, 293, 307, 311, 313, 317, 331, 337, 347, 349, 353, 359, 367, 373, 379, 383, 389, 397, 401, 409, 419, 421, 431, 433, 439, 443, 449, 457, 461, 463, 467, 479, 487, 491, 499, 503, 509, 521, 523, 541,\n\n$ zig run prime_fast.zig\nstart calculating\ndone, executed in 1274900500 nanoseconds\n2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97, 101, 103, 107, 109, 113, 127, 131, 137, 139, 149, 151, 157, 163, 167, 173, 179, 181, 191, 193, 197, 199, 211, 223, 227, 229, 233, 239, 241, 251, 257, 263, 269, 271, 277, 281, 283, 293, 307, 311, 313, 317, 331, 337, 347, 349, 353, 359, 367, 373, 379, 383, 389, 397, 401, 409, 419, 421, 431, 433, 439, 443, 449, 457, 461, 463, 467, 479, 487, 491, 499, 503, 509, 521, 523, 541,\n上述代码是我用 C，C++，Zig 分别写的快速筛素数。算法相同。\n更好的错误处理\n和 Rust 一样，zig 抛弃了 null 的空处理和 exception 的错误处理。Null 的事情不用我说，大家应该都知道 Null References: The Billion Dollar Mistake\n\nI call it my billion-dollar mistake. At that time, I was designing the first comprehensive type system for references in an object-oriented language. My goal was to ensure that all use of references should be absolutely safe, with checking performed automatically by the compiler. But I couldn’t resist the temptation to put in a null reference, simply because it was so easy to implement. This has led to innumerable errors, vulnerabilities, and system crashes, which have probably caused a billion dollars of pain and damage in the last forty years.\n\nZig 没有对 Rust 那样 enum 的原生支持（大概是因为它是 better C 而不是 C++），而是引入了两种类型，?T 和 Error!T 分别代表 Option<T> 和 Result<T, Error>。\n与 C 完全不一样的是，Zig 的普通指针 *T 不能为 null，只有 optional pointer ?*T 可以为 null。这样以来，人们就不需要担心一个 *T 被意外的传入 null 而不停地编写重复的 if (xxx == null) return; 了\nZig 的错误处理也非常有意思。Zig 的错误类型能且仅能是一个 enum，我对此只能说有好有坏吧，坏处是没法返回 struct 来得到更详细的错误信息，好处大概是其实它就是 C 语言错误码的对应——毕竟 Zig 一心设计为一个更好的 C 而不是 C++（不然就和 Rust 生态位重了）我们最常见到 C 语言中使用\nint foo(Foo* res, Args args);\n来表示一个可能出错的函数，然后查表每个错误码代表着什么。然后又有 Linux 风格和 Windows 风格，有的返回 0 代表成功，有的返回 1 代表成功，还有的返回一串 bit，每一位代表哪一个参数成功了……而 Zig 就不需要这一堆混乱的东西，错误类型已经在 enum 的名字里告诉你了。\npub const GetchError = error{\n    CannotGetStdHandle,\n    ReadNotOk,\n};\n\npub fn getch_win() GetchError!i32;\n更好的是，Zig 强制你处理这些错误。拿上面这段代码为例，你只有三种选择：\n_ = getch_win(); // 只执行，我管你出错不出错，当然也没法使用结果了\nconst v = try getch_win(); // 如果出错，就继续往上抛\nconst v = getch_win() catch |err| {\n\t// handle error ...\n\t// 处理错误\n};\n和 Rust 一样，哪里使用就在哪里处理错误，而不是 C++ 风格的 expection，会打穿整个调用栈，而 try ... catch ... 还可能抓到不属于自己想要的错误。\n另外，Zig 还原生自带 anyerror 功能。使用 Rust 的人应该都有印象，有时候其实根本不关心发生了什么错误，上头一个日志就完事了，但是还是得乖乖写 Result<T, E> 的类型，于是催生了 anyhow 库，用 anyhow::Result<T> 来表示随便什么错误我不关心。但是 Zig 就很好的解决了这个问题。同样的，如果你只是单纯的懒，也可以直接用 anyerror 的特性不定义 error 的 enum 就直接返回一个错误的名字。\ndefer 关键字\n\n你以为只有 go 语言有 defer？NO，NO，NO，zig 也有。\n\nC++ 和 Rust 选择用 RAII 来解决哪怕是经验老到的 C 程序员也可能忘记释放内存的问题。而 Zig 就不一样，它选择了和 Go 一样的做法： defer （和 errdefer）\n\n这里让我再 cue 一下，经常有知乎程序员觉得 Rust 算什么我们 C 手动释放内存也可以，borrow checker 多烦啊和编译器做斗争太难了——妈呀，想问你一下你都写不出过得了 Rust 编译的程序你凭什么觉得自己写得出内存安全的 C，你能给 GNOME 做贡献吗，而 GNOME 开发者们这样的经验老到的 C 程序员都会因为忘记 free 而搞出内存泄漏，你呢？\n\nZig 的思路是：在哪里分配就在哪里释放。这也是 Allocator 到处传的原因，在哪里创建资源，就在那里 defer destory 资源。就像这样（来自官方的示例）\npub fn main() !void {\n    const soundio = c.soundio_create();\n    defer c.soundio_destroy(soundio);\n\n    try sio_err(c.soundio_connect(soundio));\n\n    c.soundio_flush_events(soundio);\n\n    const default_output_index = c.soundio_default_output_device_index(soundio);\n    if (default_output_index < 0) return error.NoOutputDeviceFound;\n\n    const device = c.soundio_get_output_device(soundio, default_output_index) orelse return error.OutOfMemory;\n    defer c.soundio_device_unref(device);\n\n    std.debug.print(\"Output device: {s}\\n\", .{device.*.name});\n\n    const outstream = c.soundio_outstream_create(device) orelse return error.OutOfMemory;\n    defer c.soundio_outstream_destroy(outstream);\n\n    outstream.*.format = c.SoundIoFormatFloat32NE;\n    outstream.*.write_callback = write_callback;\n\n    try sio_err(c.soundio_outstream_open(outstream));\n\n    try sio_err(c.soundio_outstream_start(outstream));\n\n    while (true) c.soundio_wait_events(soundio);\n}\n注意到，defer 总是和资源的创建成对出现！zig 通过 defer 的设计让资源的释放变得一目了然，更不容易忘记释放。对比之下，C 经常需要使用大量的 goto 和宏，或者手动压栈来完成这样的操作，由于语法糖过于的少，导致语言丑陋不堪。\n当然，这也是不使用隐式控制流的思想的体现。这大概也是为什么 zig 没有选择 RAII\n编译期执行任意代码，超酷的\n如果说 Zig 给我留下的最大的最大的印象一定是编译期执行任意代码了。甚至 zig 的泛型（伪）都是用 compiletime 搞的\n举个例子，让我们看看 zig 的标准库链表如何构造：\npub fn DoublyLinkedList(comptime T: type) type {\n    return struct {\n        const Self = @This();\n\n        /// Node inside the linked list wrapping the actual data.\n        pub const Node = struct {\n            prev: ?*Node = null,\n            next: ?*Node = null,\n            data: T,\n        };\n\n        first: ?*Node = null,\n        last: ?*Node = null,\n        len: usize = 0,\n\n        ... // 后面是定义方法了\n是的，这个链表直接以一个类型为参数，传入了一个函数里面，然后捏皮球一样捏出了对应类型的链表——神奇吧。\n这样的泛型当然已经算是大家都有的东西了。但是 zig 的编译期执行可不止这点。举个例子，为了实现跨平台的贪吃蛇，为了捕获键盘按下事件，不同的系统需要引入不同的库，做不同的预处理。如果是 C 的话，那就得定义一个编译期符号，然后用 #ifdef 来选择性编译代码，显得非常突出，非常丑陋。而 Zig，我是这样做的：\npub fn main() anyerror!void {\n    switch (builtin.os.tag) {\n        .windows => {\n            // set utf-8\n            _ = std.os.windows.kernel32.SetConsoleOutputCP(65001);\n        },\n        .linux => {\n            const c = @cImport(@cInclude(\"ncurses.h\"));\n            const screen = c.initscr();\n            defer _ = c.endwin();\n            _ = c.raw();\n            _ = c.keypad(screen, true);\n            _ = c.noecho();\n        },\n        else => {\n            std.log.err(\"Unsupported platform\", .{});\n            return;\n        },\n    }\n\n\t// ... 程序代码\n}\nstd.os.windows.kernel32.SetConsoleOutputCP 这个函数在 Linux 上根本不存在？ ncurses.h 在 Windows 上没有？完全没关系！因为 builtin.os.tag 是编译期被 build.zig 填充的 compiletime struct，所以对应的 switch 语句自然也是 compiletime 的，编译器直接走到系统对应的分支，编译，链接，一点都不需要在乎其它分支。zig 将编译期处理的代码和运行时的代码统一了起来，完全使用相同的格式，这使得会了 zig 也就同时会了 compiletime zig，而不像 C++ 一样编译期模板和普通的 C++代码完全是两个天地。\n这使得 Zig 开发跨平台应用极其自然，非常简单，编译命令也保持完全一致，相比于虽然号称“一次编写处处运行”，实而脱离了平台的库以后寸步难行的 C 代码反而更容易写出跨平台的应用。\n当然这也有个意外的好处，zig 可以作为一个编译工具而使用，这在 zig 自己编译 zig 项目的时候尤其好用，build.zig 和你的 zig 代码是一个语法，一点也不用担心额外学一门标记法（目移 看向 CMake）\n当然，还有需要打磨的地方\n如果说 zig 有什么急需打磨的地方，或许是它到现在都还没有第一个正式版吧。zig 的标准库接口在过去几年里变了不少，以至于GPT 没法生成复制粘贴就能跑的代码。同时令人担忧的是，zig 语言的作者非常固执己见，比如他希望替换 LLVM 后端，就花了很长时间去弄它，哪怕社区很多人劝说也没用。zig 到现在拖了很久都是 0.13 版本，或许也只有勇于尝试的项目敢用它了。\nzig 还有一个让我很不满的地方是它不支持语法糖来创建闭包。当然你能用匿名结构体来创建闭包，但是主要是作者一人的意见——他不喜欢函数式的语法——而否决了闭包的提案。\n尾声\n如果说 C 语言是一坨汇编的封装，那 Zig 才是我理想中的，应该在 C 语言位置上的语言。简洁、底层、现代，既能一目了然地看出对应的汇编，又不至于和 C 一样过于简陋缺少语法糖而必须写出非常丑陋的代码。\n它或许不太适合应用开发，毕竟太偏向底层，但它一定能带来比 C 更好的体验。如果下次遇到需要用 C 的项目，不妨试试 zig 吧。\n\n本文以 CC BY-NC-SA 4.0 发布。\n脚注\n\n\n这里指代不好好学 C++ 拿 C 语言的经验写代码的傻瓜 ↩\n\n\n不要问我为什么要抛弃 RAII 这样的好东西。这就是活跃于编程话题下 C with classes 人，他们坚信 C with classes 就能满足 99% 的需求 ↩\n\n\n"},{"type":"post","id":"pfpl-note-2","title":"PFPL 笔记 - II Statics and Dynamics","url":"/blog/pfpl-note-2/","content":"Practical Foundations for Programming Languages 是 Robert Harper 的一本书，而这是我写的笔记 2\n\nChapter 4 Statics\n\nMost programming languages exhibit a phase distinction between the static and dynamic phases of processing. The static phase consists of parsing and type checking to ensure that the program is well-formed; the dynamic phase consists of execution of well-formed programs. A language is said to be safe exactly when well-formed programs are well-behaved when executed.\n\n一个语言如果是 safe 的，那说明 well-formed programs 在执行时是 well-behaved\n书中介绍了一种语言 \\mathcal L \\{\\text{num str}\\} 具有一些 statics：\n\n这些推理都比较显然，略。\nLemma 4.1：Typing 的唯一性。对任何 typing context \\Gamma 和表达式 e 只存在至多一个 \\tau s.t. \\Gamma \\vdash e : \\tau\nLemma 4.2：类型反转。Suppose that \\Gamma \\vdash e : \\tau If e = plus(e1;e2) 我们可以退出 e1 : num 和 e2 : num。\nChapter 5 Dynamics\nTODO"},{"type":"post","id":"not-so-nerdy-www-guidelines-for-bloggers","title":"Not so nerdy WWW guidelines for bloggers","url":"/blog/not-so-nerdy-www-guidelines-for-bloggers/","content":"A blogging guide, built for minimalists who aren’t quite as nerdy.\n\nAnd this blog is fucking more perfect than ⬇️ those shit.\nRead it before\n\nthis is a motherfucking website http://motherfuckingwebsite.com/\nthis is a better motherfucking website http://bettermotherfuckingwebsite.com/\nthis is the best motherfucking website https://bestmotherfucking.website/\n\nSeriously, what the fuck DO you really want?\nLet’s describe what the REAL prefect website should like:\n\nLight-weight, with superfast loading speed\nFit on all you screens\nLooks all good in all your browsers\nAcessible to everyone that visits your website, whether they are using a screen reader or a text-only browser in a terminal\nClear and easy to read, not something that ADHD people will faint after just a glance\n\nSomeone took a masterpiece and incrementally ruin it for the sake of design. And the other paranoids fiercely criticized those in front and then ruin theirs by the shitty default browser styles.\nDesign is to plan and make something for a specific purpose.  The most basic purpose of text on a website is to be read. You know? READ. To be read conveniently. To be read with minimal effort. Rather than to satisfy the fantasies of geeks or nerds.\nStop adding unnecessary animations\nLoad 5MB of your fucking Javascript just to put a mouse firework effect on the background or custom mousepointer? Slow down the loading speed by 10 seconds just to put an anime waife in the lower left corner whose eyes follow your mouse? Is this cool? Oh come on, okay this is very cool, but what does it have to do with what you wrote?\nThis shouldn’t need in-depth explanation, right?\nUse semantic HTML tags rather than div if possible\nYes, you can style anything with any element, and you can easily make a <div> look like a heading, a footnote, a card or anything else, but have you ever considered that someone other than a sighted person with chrominum browser might read what you write?\n\nScreen readers can use it as a signpost to help visually impaired users navigate a page\nSearch engines will consider its contents as important keywords to influence the page’s search rankings\nFinding blocks of meaningful code is significantly easier than searching through endless divs with or without semantic or namespaced classes\n\nWhenever possible, use semantic HTML tags.\nLimit your line width\n\nLooking at an LCD screen is strainful enough. Don’t make me read a line of text that’s 200 fucking characters long. Keep it to a nice 60-80 and users might actually read more than one sentence of your worthless dribble. If your text hits the side of the browser, fuck off forever. You ever see a book like that? Yes? What a shitty book.\n\nKeeping the maximum paragraph width is also more ADHD-friendly. If they’re on a widescreen browser and see your 30cm-long paragraph that sticks out like Mount Everest, do you think they’ll use a vernier caliper to read your shit? Or do you want them to shrink their browser down to a size where they can read a line a second?\nDon’t let your text look suffocating\nLet’s think about the most wonderful thing that computers have brought us, okay? Infinite length pages. Honey, you are not printing a book, there is no need to make the text close together, it won’t save you 50% the printing cost by reducing line height, nor will it save you any byte of bandwidth. So don’t let the text that is close together give ADHD a little reading shock, okay?\nMake your line height at least 1.6, don’t oppress the reader’s eyes.\nUse customized font or give your readers shit\n\nAre your users even going to notice that it’s not their default serif or sans-serif? Why do you even bother when Chrome is going to render it like ass anyways? Use a font stack your users already have.\n\nThank you holy shit, of course you would, if you don’t want someone opening your page to see math formulas rendered with sans-serif like earthworms and shitty text that doesn’t even fit the font, and they can’t even set the font in a mobile browser? Did the person who wrote this sentence ever think that a Chinese person far away on the other side of the Pacific Ocean would see that the only damn single quotation mark ’ in the entire article was displayed in full-width, which was out of place? They don’t know because they damn well thinks that everyone in the world should have a good default Latin font.\nPut loading fonts in JS, they’re not important enough to slow down your first screen load time, but important enough to set. The only people who disable JS anyway are nerds who can handle the shitty visual effects of the default fonts.\nStop use decorative non-relevant images\nEspecially random anime girls, okay?\nIf the image is contextual, that’s great. But what’s the point of putting a completely unrelated image at the bottom of your blog? You might say, “It makes my blog look better” - maybe better, but people who read your blog are not come here for random pretty pictures, and this will only waste the viewer’s bandwidth and about 3 mousewheels time.\nEspecially putting a picture of a random anime waife in every article would only make you look like a fucking horny incel. If you like to put a random anime waife on your blog, you’d better have a worthable content of wasting 3 mousewheels time.\nAnd for nerds\nStop saying your fucking misogyny slurs in your next post, please?\nDid anyone tell you that blasting words like “motherfucking” all over your fucking website will only make you look like a fucking stupid uncastrated dog? If not, go find some radfem and get fucked off.\n\n本文在 CC-BY-NC-SA 4.0 下发布。"},{"type":"post","id":"pfpl-note-1","title":"PFPL 笔记 - I Judgments and Rules","url":"/blog/pfpl-note-1/","content":"Practical Foundations for Programming Languages 是 Robert Harper 的一本书，而这是我写的笔记\n\n第一章 Syntactic Objects 句法对象\nThe structural, or abstract, syntax is concerned with the structure of phrases, specifically how they are composed from other phrases. At this level a phrase is a tree, called an abstract syntax tree, whose nodes are operators that combine several phrases to form another phrase.\nstructural or abstract, syntax 与短语的结构有关，特别是它们是如何由其他短语组成的。 在这个级别上，phrase 是一棵树，称为抽象语法树，其节点是将几个短语组合成另一个短语的运算符。\nThe binding structure of syntax is concerned with the introduction and use of identifiers: how they are declared, and how declared identifiers are to be used. At this level phrases are abstract binding trees, which enrich abstract syntax trees with the concepts of binding and scope.\n语法的 binding 结构与标识符的引入和使用有关：如何声明它们，以及如何使用已声明的标识符。在这个级别上，短语是抽象绑定树，它用绑定和范围的概念丰富了抽象语法树。\nAST\nfor example,\n2 + (3 * x)\nplus(num[2];times(num[3];x))\n考虑我们希望证明某个属性 properity \\mathcal P(a) 对所有给定类型的 ast a 都成立，只需要考虑生成 a 的所有方式，并证明该属性在每种情况下都成立\nSo, in the case of the sort Exp just described, we must show\n\nThe property holds for any variable, x, of sort Exp: P(x).\nThe property holds for any number, num[n]: for every n \\in \\mathbb N, \\mathcal P( num[n] )\nAssuming that the property holds for a_1 and a_2, show that it holds for plus(a_1; a_2) and times(a_1; a_2): if \\mathcal P(a_1) and \\mathcal P(a_2), then \\mathcal P( plus(a_1; a_2) ) and \\mathcal P( times(a_1; a_2) )\n\nAbstract binding trees ABT\n抽象绑定树 abt 丰富了 ast，使其能够引入新的变量和参数，称为绑定，具有指定的重要范围，称为作用域。\nChapter 2 Inductive Definitions\nAn inductive definition of a judgment form consists of a collection of rules of the form\n\\dfrac {J1 \\quad...\\quad J_k}{J}\nin which J1 \\quad...\\quad J_k and J are all judgments of the form being defined.\nfor example\n\\dfrac {}{\\text{zero nat}}\n\\dfrac {a\\text{ nat}}{\\text{succ}(a)\\text{ nat}}\nModes\nWe already know that Theorem 2.4. For every a nat and b nat, there exists a unique c nat such that sum(a;b;c)\n对任意 a, b nat 存在 c 有 a + b = c\nThe statement that one or more arguments of a judgment is (perhaps uniquely) determined by its other arguments is called a mode specification for that judgment. For example, we have shown that every two natural numbers have a sum according to Rules (2.9). This fact may be restated as a mode specification by saying that the judgment sum(a; b; c) has mode (∀, ∀, ∃). The notation arises from the form of the proposition it expresses: for all a nat and for all b nat, there exists c nat such that sum(a; b; c).\nIf we wish to further specify that c is uniquely determined by a and b, we would say that the judgment sum(a; b; c) has mode (∀, ∀, ∃!), corresponding to the proposition for $all a nat and for all b nat, there exists a unique c nat such that sum(a; b; c).\nIf we wish only to specify that the sum is unique, if it exists, then we would say that the addition judgment has mode (∀, ∀, ∃≤1), corresponding to the proposition for all a nat and for all b nat there exists at most one c nat such that sum(a; b; c).\nA given judgment may satisfy several different mode specifications. For example, addition also has the mode (∀, ∃≤1, ∀), stating that the sum and the first addend uniquely determine the second addend, if there is any such addend at all. Put in other terms, this says that addition of natural numbers has a (partial) inverse, namely subtraction.\nChapter 3 Hypothetical and General Judgments\nFor a given set, \\mathcal R, of rules, we define the derivability judgment\nWe use capital Greek letters, frequently \\Delta or \\Gamma, to stand for a finite collection of basic judgments, and write \\mathcal R[\\Gamma] for the expansion of \\mathcal R with an axiom corresponding to each judgment in \\Gamma.\nThe judgment \\Gamma \\vdash_\\mathcal R K means that K is derivable from rules \\mathcal R[\\Gamma] and the judgment \\vdash_\\mathcal R \\Gamma means that \\vdash_\\mathcal R J for each J in \\Gamma.\nFor example\na \\text{ nat} \\vdash \\text{succ(succ(} a \\text{)) nat}\nAdmissibility,\nAdmissibility, written \\Gamma \\models_\\mathcal R J, is a weaker form of hypothetical judgment stating that \\vdash_\\mathcal R \\Gamma implies \\vdash_\\mathcal R J. That is, the conclusion J is derivable from rules \\mathcal R whenever the assumptions \\Gamma are all derivable from rules \\mathcal R. In particular if any of the hypotheses are not derivable relative to \\mathcal R, then the judgment is vacuously true.\nFor example\n\\text{succ}(a)\\text{ nat} \\models_{\\text{Theorem (2.2)}} a \\text{ nat}\nis valid, because any derivation of succ(a) nat from Rules (2.2) must contain a sub-derivation of a nat from the same rules, which justifies the con clusion.\nIn contrast to derivability the admissibility judgment is not stable under extension to the rules. For example, if we enrich Rules (2.2) with the axiom\n\\dfrac {}{\\text{succ(junk) nat}}\n(where junk is some object for which junk nat is not derivable), then the admissibility above is invalid.\nGeneral Judements\n\\vec x \\mid \\Gamma \\vdash_{\\mathcal R}^{\\mathcal X} J\n\\quad\\text{iff}\\quad\n\\forall \\pi : \\vec x \\leftrightarrow \\vec x'\\ \\pi \\cdot \\Gamma \\vdash_{\\mathcal R}^{\\mathcal X, \\vec x'} \\pi \\cdot J\nwhere:\n\n\\Gamma \\vdash_{\\mathcal R}^{\\mathcal U; \\mathcal X} J means J is derivable from \\Gamma according to rules \\mathcal R with objects consisting of abt’s over parameters \\mathcal U and variables \\mathcal X\n\\pi : \\vec x \\leftrightarrow \\vec x' is a renaming\n\n说人话：后面是 iff 对任意 renaming，把它作用到 \\Gamma 上 可以推出 renamed J\nFor example\nx \\mid x \\text{ nat} \\vdash_{(2.2)}^{\\mathcal X} \\text{succ(succ(} x\\text{)) nat}"},{"type":"post","id":"gleam-intro","title":"仿生电子锈会梦到自己变成纯函数式吗：gleam 语言初见","url":"/blog/gleam-intro/","content":"Gleam is a friendly language for building type-safe systems that scale! —— https://gleam.run/\n虽然我倒不觉得纯函数式语言能有多 friendly……\n\n事情的起因是刷到知乎提问如何评价 gleam 语言，然后有人说在 rust 和 go 之间应该有一门中间态的语言 balabala\n于是就跑过去看了，最开始看语法如此像 rust，再加上安利的描述，还以为是 GC 的过程式语言加点函数式糖，直到看到 Gleam is an immutable language 才发现啊被骗了怎么是纯函数式（）\n先来看看 hello world：\nimport gleam/io\n\npub fn main() {\n  io.println(\"Hello, world!\")\n}\n非常好懂（点头\nImmutable\n虽然 immutable 比过程式语言通常写起来更容易遇到一些不得不搞一些奇怪的递归函数的情况，但是也是一个不错的选择。\nGleam 会编译到 Erlang（可以编译到 js，但是因为语言特性很容易爆递归），听说过 Erlang 的人大概都知道这个传闻：写 Erlang/Elixir 的人习以为常地开几万甚至几十万个进程1，这也是得益于 immutable 的特性让并发操作变得非常简单好写\n对于 mutable 的语言，需要担忧一块内存空间被并发地同时读和写，进而引出了一堆的互斥锁/原子操作之类的概念，而 immutable 根本不需要担心这个问题，因为你根本没有编写“覆写”一块内存区域的代码，（虽然 Erlang 虚拟机可能会优化这个操作，从而实际上覆写），所有的变量都是只读的。\n这也是大多数 immutable 函数式语言共享的优势，许多纯函数连状态都没有，自然也就不存在状态不一致的问题。对于函数式而言并发、scale 都是天然的事情。\nPipeline\nGleam 支持 pipeline 操作\n我是链式调用狂热粉丝（？）所以非常需要这个！对我来说一个语言能吸引我的一个重要的 sugar 就是类似 pipeline 的机制 i.e.\n(|>) :: a -> (a -> b) -> b\nx |> f = f x\n这意味着任何一个 f: a \\to b 都能 pipeline 一个 a 进去得到 b，非常好用，因为很多现实世界的操作本来就是串联起来的\n比如你可以在 gleam 中写这样的：\nimport gleam/io\nimport gleam/string\n\npub fn main() {\n  // Without the pipe operator\n  io.debug(string.drop_start(string.drop_end(\"Hello, Joe!\", 1), 7)) // \"Joe\"\n\n  // With the pipe operator\n  \"Hello, Mike!\"\n  |> string.drop_end(1)\n  |> string.drop_start(7)\n  |> io.debug // \"Mike\"\n\n  // Changing order with function capturing\n  \"1\"\n  |> string.append(\"2\")\n  |> string.append(\"3\", _)\n  |> io.debug  // \"312\"\n}\n中缀表示法 a f b 就是比前缀表示法 f a b 在链式调用下好看多了！这或许是一种比 Ruby 的 Open Class 更好的方案来给对象添加“成员函数”，因为实际上成员函数就是一个 fn(self, ...)\nPattern matching\n说到函数式语言最重要的特色当然是 Pattern matching！\nGleam 的 Pattern matching 基本上就是 rust 的形状，不过更强大，和大多数其它函数式语言一样可以匹配一些内置运算：\nimport gleam/io\n\npub fn main() {\n  io.debug(get_name(\"Hello, Joe\"))            // \"Joe\"\n  io.debug(get_name(\"Hello, Mike\"))           // \"Mike\"\n  io.debug(get_name(\"System still working?\")) // \"Unknown\"\n}\n\nfn get_name(x: String) -> String {\n  case x {\n    \"Hello, \" <> name -> name\n    _ -> \"Unknown\"\n  }\n}\nGleam 也能写类似 Rust 的 let，但是 Gleam 不存在 if 所以没法写 if let 也没有 let mut 这些东西，let 就是一个纯的 irrefutable 的 pattern matching 而已。当然更多的时候可以用来给变量“赋值”（）\nimport gleam/io\n\npub type Teacher {\n  Teacher(name: String, subject: String)\n}\n\npub fn main() {\n  let teacher = Teacher(\"Mr Schofield\", \"Physics\")\n  let Teacher(tname, _) = teacher\n\n  io.debug(tname) // \"Mr Schofield\"\n}\n只有递归\n和很多纯函数式语言一样，Gleam 没有循环结构只有递归，老实说我不觉得这很好，因为这让一些简单的事情变得更复杂……\n经典的 list 求 sum 可以写这样的函数\nfn sum_list(list: List(Int)) -> Int {\n  case list {\n    [first, ..rest] -> first + sum_list(rest)\n    [] -> 0\n  }\n}\n有过函数式经验的人应该非常好理解，也就是每次取第一位递归地加末尾。写成 haskell 就是：\nsumlist :: [Int] -> Int\nsumlist [] = 0\nsumlist (x:xs) = x + sumlist xs\n看上去 gleam 还更长一点，没有 haskell 的韵味 xd\nUse sugar\n比较喜欢的是 Gleam 的 use sugar，类似 Javascript 的 async/await 一样，负责简化嵌套层级。\n\nGleam’s use expression helps out here by enabling us to write code that uses callbacks in an unindented style, as shown in the code window.\nGleam 的 use 表达式使我们能够编写以未缩进样式使用回调的代码，从而在此处提供帮助，如代码窗口中所示。\nThe higher order function being called goes on the right hand side of the <- operator. It must take a callback function as its final argument.\n被调用的高阶函数位于 <- 运算符的右侧。它必须将回调函数作为其最终参数。\nThe argument names for the callback function go on the left hand side of the <- operator. The function can take any number of arguments, including zero.\n回调函数的参数名称位于 <- 运算符的左侧。该函数可以接受任意数量的参数，包括零。\nAll the remaining code in the enclosing {} block becomes the body of the callback function.\n封闭的 {} 块中的所有剩余代码都成为回调函数的主体。\n\n直接放官方示例：\nimport gleam/io\nimport gleam/result\n\npub fn main() {\n  let _ = io.debug(without_use())\n  let _ = io.debug(with_use())\n}\n\npub fn without_use() -> Result(String, Nil) {\n  result.try(get_username(), fn(username) {\n    result.try(get_password(), fn(password) {\n      result.map(log_in(username, password), fn(greeting) {\n        greeting <> \", \" <> username\n      })\n    })\n  })\n}\n\npub fn with_use() -> Result(String, Nil) {\n  use username <- result.try(get_username())\n  use password <- result.try(get_password())\n  use greeting <- result.map(log_in(username, password))\n  greeting <> \", \" <> username\n}\n\n// Here are some pretend functions for this example:\n\nfn get_username() -> Result(String, Nil) {\n  Ok(\"alice\")\n}\n\nfn get_password() -> Result(String, Nil) {\n  Ok(\"hunter2\")\n}\n\nfn log_in(_username: String, _password: String) -> Result(String, Nil) {\n  Ok(\"Welcome\")\n}\n这里其实 use xxx <- result.try(foo()) 翻译成 rust 就是 foo 会返回一个 Result<T, E>，然后\nlet xxx = foo()?\n如果匹配到 Err 就直接返回了，否则再对 Ok(T) 做某种映射\n实战：写个 JSON Parser\n其实本来是想在 rust 里写 json parser 的但是看到有这么像 rust 的 gleam 以后就干脆拿 gleam 了（\n由于 parse number 比较复杂这又是个玩具就不写 number parser 了\n首先定义节点的类型，长得很像 rust 的语法（整个语言都很像啊喂！）\npub type Node {\n  Nul\n  Bol(val: Bool)\n  Num(val: Int)\n  Str(val: String)\n  Arr(val: List(Node))\n  Obj(val: dict.Dict(String, Node))\n}\n我们大致定义一个 parse 函数返回的成功类型可能长这样：\ntype ParseObjResult {\n  ParseObjResult(result: dict.Dict(String, Node), rest: String)\n}\nresult 是 parse 出来的内核，rest 是剩下的字符串，用来继续 parse：\n然后就能写出大概这样的 parser\n可以看到，use sugar 在简化层级上有多么必要，use 可以极大程度简化代码防止过多的层级嵌套\nfn parse_obj(str: String) -> Result(ParseObjResult, String) {\n  case str |> string.trim_start {\n    \"}\" <> rest -> Ok(ParseObjResult(dict.from_list([]), rest))\n    x -> {\n      use ParseStrResult(key, rest) <- result.then(parse_str(x))\n      use rest <- result.then(parse_col(rest))\n      use ParseNodeResult(node, rest) <- result.then(parse_node(rest))\n\n      case rest |> string.trim_start |> string.pop_grapheme {\n        Ok(#(\",\", next)) ->\n          next\n          |> string.trim_start\n          |> parse_obj\n          |> result.map(fn(res) {\n            ParseObjResult(res.result |> dict.insert(key, node), res.rest)\n          })\n        Ok(#(\"}\", rest)) ->\n          Ok(ParseObjResult(dict.from_list([#(key, node)]), rest))\n\n        Ok(#(x, _)) -> Error(\"unexpected token \" <> x)\n        Error(_) -> Error(\"unexpected eof\")\n      }\n    }\n  }\n}\n\n\nfn parse_node(str: String) -> Result(ParseNodeResult, String) {\n  let str = str |> string.trim_start\n  case str {\n    \"null\" <> rest -> Ok(ParseNodeResult(Nul, rest))\n    \"true\" <> rest -> Ok(ParseNodeResult(Bol(val: True), rest))\n    \"false\" <> rest -> Ok(ParseNodeResult(Bol(val: False), rest))\n    \"\\\"\" <> _ ->\n      parse_str(str)\n      |> result.map(fn(res) { ParseNodeResult(Str(val: res.result), res.rest) })\n    \"{\" <> rest ->\n      parse_obj(rest)\n      |> result.map(fn(res) { ParseNodeResult(Obj(val: res.result), res.rest) })\n    \"[\" <> rest ->\n      parse_arr(rest)\n      |> result.map(fn(res) { ParseNodeResult(Arr(val: res.result), res.rest) })\n    x -> Error(\"unexpected token \" <> x)\n  }\n}\n\n完整代码\nimport gleam/dict\nimport gleam/io\nimport gleam/result\nimport gleam/string\n\npub type Node {\n  Nul\n  Bol(val: Bool)\n  Num(val: Int)\n  Str(val: String)\n  Arr(val: List(Node))\n  Obj(val: dict.Dict(String, Node))\n}\n\ntype ParseNodeResult {\n  ParseNodeResult(result: Node, rest: String)\n}\n\ntype ParseStrResult {\n  ParseStrResult(result: String, rest: String)\n}\n\ntype ParseListResult {\n  ParseListResult(result: List(Node), rest: String)\n}\n\ntype ParseObjResult {\n  ParseObjResult(result: dict.Dict(String, Node), rest: String)\n}\n\nfn read_str(str: String) -> Result(ParseStrResult, String) {\n  case str |> string.pop_grapheme {\n    Error(Nil) -> Error(\"Unexpected EOF\")\n    Ok(#(first, rest)) ->\n      case first {\n        \"\\\"\" -> Ok(ParseStrResult(\"\", rest))\n        _ ->\n          read_str(rest)\n          |> result.map(fn(res) {\n            ParseStrResult(first <> res.result, res.rest)\n          })\n      }\n  }\n}\n\nfn parse_str(str: String) -> Result(ParseStrResult, String) {\n  let str = str |> string.trim_start\n  case str {\n    \"\\\"\" <> content -> read_str(content)\n    x -> Error(\"unexpected token \" <> x)\n  }\n}\n\nfn parse_col(str: String) -> Result(String, String) {\n  let str = str |> string.trim_start\n  case str {\n    \":\" <> rest -> Ok(rest |> string.trim_start)\n    x -> Error(\"unexpected token \" <> x)\n  }\n}\n\nfn parse_obj(str: String) -> Result(ParseObjResult, String) {\n  case str |> string.trim_start {\n    \"}\" <> rest -> Ok(ParseObjResult(dict.from_list([]), rest))\n    x -> {\n      use ParseStrResult(key, rest) <- result.then(parse_str(x))\n      use rest <- result.then(parse_col(rest))\n      use ParseNodeResult(node, rest) <- result.then(parse_node(rest))\n\n      case rest |> string.trim_start |> string.pop_grapheme {\n        Ok(#(\",\", next)) ->\n          next\n          |> string.trim_start\n          |> parse_obj\n          |> result.map(fn(res) {\n            ParseObjResult(res.result |> dict.insert(key, node), res.rest)\n          })\n        Ok(#(\"}\", rest)) ->\n          Ok(ParseObjResult(dict.from_list([#(key, node)]), rest))\n\n        Ok(#(x, _)) -> Error(\"unexpected token \" <> x)\n        Error(_) -> Error(\"unexpected eof\")\n      }\n    }\n  }\n}\n\nfn parse_arr(str: String) -> Result(ParseListResult, String) {\n  case str |> string.trim_start {\n    \"]\" <> rest -> Ok(ParseListResult([], rest))\n    x -> {\n      use ParseNodeResult(node, rest) <- result.then(parse_node(x))\n      case rest |> string.trim_start |> string.pop_grapheme {\n        Ok(#(\",\", next)) ->\n          next\n          |> string.trim_start\n          |> parse_arr\n          |> result.map(fn(res) {\n            ParseListResult([node, ..res.result], res.rest)\n          })\n        Ok(#(\"]\", rest)) -> Ok(ParseListResult([node], rest))\n\n        Ok(#(x, _)) -> Error(\"unexpected token \" <> x)\n        Error(_) -> Error(\"unexpected eof\")\n      }\n    }\n  }\n}\n\nfn parse_node(str: String) -> Result(ParseNodeResult, String) {\n  let str = str |> string.trim_start\n  case str {\n    \"null\" <> rest -> Ok(ParseNodeResult(Nul, rest))\n    \"true\" <> rest -> Ok(ParseNodeResult(Bol(val: True), rest))\n    \"false\" <> rest -> Ok(ParseNodeResult(Bol(val: False), rest))\n    \"\\\"\" <> _ ->\n      parse_str(str)\n      |> result.map(fn(res) { ParseNodeResult(Str(val: res.result), res.rest) })\n    \"{\" <> rest ->\n      parse_obj(rest)\n      |> result.map(fn(res) { ParseNodeResult(Obj(val: res.result), res.rest) })\n    \"[\" <> rest ->\n      parse_arr(rest)\n      |> result.map(fn(res) { ParseNodeResult(Arr(val: res.result), res.rest) })\n    x -> Error(\"unexpected token \" <> x)\n  }\n}\n\npub fn parse_json(str: String) -> Result(Node, String) {\n  case parse_node(str |> string.trim) {\n    Error(e) -> Error(e)\n    Ok(ParseNodeResult(node, rest)) ->\n      case rest {\n        \"\" -> Ok(node)\n        _ -> Error(\"unexpected non EOF\")\n      }\n  }\n}\n\npub fn main() {\n  let _ = io.debug(parse_json(\"null\"))\n  let _ = io.debug(parse_json(\"true\"))\n  let _ = io.debug(parse_json(\"false\"))\n  let _ = io.debug(parse_json(\"\\\"wwww\\\"\"))\n  let _ = io.debug(parse_json(\"{}\"))\n  let _ = io.debug(parse_json(\"{\\\"a\\\": true, \\\"b\\\": [true, false, null]}\"))\n  let _ = io.debug(parse_json(\"[ true, false, null, \\\"abcd\\\" ]\"))\n\n  io.debug(\"done\")\n}\n\n还有一些缺陷\n可能是我不会用的原因，gleam 莫名不能 production build……build 的产物全是在 dev 文件夹下的，令人担忧它实际的能力\ngleam 也不能随便找个文件夹就开始编写单文件代码然后直接 build 一个可执行文件，必须新建一个 project\n总结\nGleam 是一个长得很像 rust 的纯函数式语言。由于我不怎么写函数式，写起来还是略微费劲了一点（）\n像下面 ⬇️ 这样的代码片段显得 gleam 很有魅力，但是因为没有 if，遇到只有两个的情况还不得不 case match 就有点令人抓狂了\nuse ParseStrResult(key, rest) <- result.then(parse_str(x))\nuse rest <- result.then(parse_col(rest))\nuse ParseNodeResult(node, rest) <- result.then(parse_node(rest))\n\ncase rest |> string.trim_start |> string.pop_grapheme {\n  Ok(#(\",\", next)) ->\n    next\n    |> string.trim_start\n    |> parse_obj\n    |> result.map(fn(res) {\n      ParseObjResult(res.result |> dict.insert(key, node), res.rest)\n    })\n  Ok(#(\"}\", rest)) ->\n    Ok(ParseObjResult(dict.from_list([#(key, node)]), rest))\n\n  Ok(#(x, _)) -> Error(\"unexpected token \" <> x)\n  Error(_) -> Error(\"unexpected eof\")\n}\n脚注\n\n\nElixir 的进程是 Erlang 虚拟机提供的“轻量级”进程，甚至比一般语言的线程还轻量 ↩\n\n\n"},{"type":"post","id":"cpp-toy-json-parser","title":"用 C++ 写一个玩具 JSON 库","url":"/blog/cpp-toy-json-parser/","content":"写这个解析器主要是为了看自己的 C++ 水平，毕竟 JSON 是一个同时能做到语法简单的同时考验人的编码水平的 data structure，其次是为了好玩。\n好玩吗？好玩。\n\n结构\n我们使用 https://www.json.org/json-en.html 作为解析的依据。因为是个玩具，这个解析器不打算遵循任何标准。\n一个 JSON 的“值” 分为六种可能，也就是\n\nNull: null, 空值\nBoolean: 布尔值\nNumber: 数字\nString: 字符串\nArray: 数组\nObject: key-value 映射\n\n其中 Array 和 Object 又会存放任何可能的 JSON 值。\n由于 C++ 显然会比较难写，先来看一下 Rust 大概会怎么写。\nenum JSONNode {\n    Null,\n    Bool(bool),\n    Number(i64),\n    String(String),\n    Array(Vec<JSONNode>),\n    Object(HashMap<String, JSONNode>),\n}\n\nfn parse(sv: &str) -> Result<JSONNode, String> {\n    let sv = sv.trim_start();\n    if let Some(first) = sv.chars().nth(0) {\n        match first {\n            'n' => Ok(parseNull(sv)),\n            't' => Ok(parseBool(sv)),\n            'f' => Ok(parseBool(sv)),\n            '\"' => Ok(parseString(sv)),\n            '0'..'9' => Ok(parseNumber(sv)),\n            '{' => Ok(parseObject(sv)),\n            '[' => Ok(parseArray(sv)),\n            _ => Err(format!(\"unexpected token {first}\"))\n        }\n    } else {\n        Err(\"expect json value\".to_string())\n    }\n}\n⬆️ 好了也就是看一下而已。但是对于 C++ 我们没有好的 enum，如果要写得比较方便而不是追求性能的话就要用到虚函数和虚继承。\n首先定义一个节点的可能性：\nenum class NodeType {\n  Null,\n  Boolean,\n  Number,\n  String,\n  Array,\n  Object,\n};\nJSON 中不会出现不属于上面六类“值”，因此“值”应该是一个虚基类，包含一些纯虚函数\nclass Node {\npublic:\n  inline static std::unique_ptr<Node> parse(std::string_view &sv, int dep) {\n    assert_depth(sv, dep);\n    removeWhiteSpaces(sv);\n    switch (sv[0]) {\n    case 'n':\n      return Null::parse(sv);\n    case 't':\n    case 'f':\n      return Boolean::parse(sv);\n    case '{':\n      return Object::parse(sv, dep + 1); // 控制递归深度，防止溢出\n    case '[':\n      return Array::parse(sv, dep + 1); // 同上\n    case '\"':\n      return String::parse(sv);\n    case '-':\n    case '0' ... '9':\n      return Number::parse(sv);\n    default:\n      throw getJSONParseError(sv, \"any JSON value\");\n    }\n  };\n\n  virtual inline NodeType getType() const noexcept = 0;\n\n  template <class T>\n    requires std::is_base_of_v<Node, T>\n  inline T &cast() noexcept {\n    return *(static_cast<T *>(this));\n  }\n  template <class T>\n    requires std::is_base_of_v<Node, T>\n  inline const T &cast() const noexcept {\n    return *(static_cast<const T *>(this));\n  }\n\n  virtual inline std::string dump() const {\n    switch (this->getType()) {\n    case NodeType::Null:\n      return this->cast<Null>().dump();\n    case NodeType::Boolean:\n      return this->cast<Boolean>().dump();\n    case NodeType::Number:\n      return this->cast<Number>().dump();\n    case NodeType::String:\n      return this->cast<String>().dump();\n    case NodeType::Array:\n      return this->cast<Array>().dump();\n    case NodeType::Object:\n      return this->cast<Object>().dump();\n    }\n    throw JSONException(\"unreachable: a JSON::Node has no nodetype\");\n  };\n\n  virtual ~Node() {};\n};\n一个节点显然最好是独占其资源的所有权的，所以返回一个 std::unique_ptr<Node>，帮我们免除手动释放内存的烦恼。\n因为是指针，可以简单的 cast 到子类，调用子类的方法。\n而一个 JSON 对象什么其它的都不存，只存放这个 std::unique_ptr<Node>，作为一个 unique_ptr<Node> 的包装器而存在。\nParse\nnull, boolean, number, string 的解析比较显然，略\narray 和 object 有共通性，这里只解释比较复杂的 object\nclass Object : public Node {\n  using ObjectVT = std::unordered_map<std::string, JSON>;\n  ObjectVT value_{};\n\npublic:\n  Object() {};\n  explicit Object(ObjectVT &&val) : value_(std::move(val)) {};\n  Object(Object &&) = default;\n  Object(const Object &) = delete; // 删掉拷贝构造函数 （虽然本来就被 JSON 删了）\n  Object &operator=(Object &&) = default;\n  Object &operator=(const Object &) = delete;\n\n  inline static std::unique_ptr<Object> parse(std::string_view &sv, int dep) {\n    assert_depth(sv, dep);\n    removeWhiteSpaces(sv);\n    if (sv[0] != '{')\n      throw getJSONParseError(sv, \"object start `{`\");\n    sv.remove_prefix(1);\n    removeWhiteSpaces(sv);\n    ObjectVT val;\n    bool isTComma = false; // 是不是尾随逗号\n    while (sv[0] != '}') {\n      auto key = String::parse(sv); // 解析 key\n      if (ENABLE_DUMPLICATED_KEY_DETECT && val.contains(key->value())) {\n        throw getJSONParseError(\n            sv, (\"unique key, but got dumplicated key `\" + key->value() + \"`\")\n                    .c_str());\n      } else {\n        removeWhiteSpaces(sv);\n        if (sv[0] != ':') // 解析 key :\n          throw getJSONParseError(sv, \"object spliter `:`\");\n        sv.remove_prefix(1);\n        val.insert({key->take(), JSON(Node::parse(sv, dep + 1))});\n        removeWhiteSpaces(sv); // 解析 key : value\n        switch (sv[0]) {\n        case '}': // 看看结束了没\n          sv.remove_prefix(1);\n          return std::make_unique<Object>(std::move(val));\n        case ',':\n          sv.remove_prefix(1);\n          isTComma = true;\n          continue;\n        default:\n          throw getJSONParseError(sv, \"object spliter `,` or object end `}`\");\n        }\n      }\n    }\n    if (isTComma && !ENABLE_TRAILING_COMMA)\n      throw getJSONParseError(sv, \"next json value\");\n    sv.remove_prefix(1);\n    return std::make_unique<Object>(std::move(val));\n  }\n\n  inline NodeType getType() const noexcept override {\n    return NodeType::Object;\n  }\n  inline std::string dump() const override {\n    std::string s = \"{\";\n    for (const auto &[key, val] : value_) {\n      s += String::toJSONString(key);\n      s += \":\";\n      s += val->dump();\n      s += \",\";\n    }\n    if (!value_.empty())\n      s.pop_back();\n    s += '}';\n    return s;\n  }\n\n  JSON &operator[](const std::string &s) { return value_[s]; }\n  const JSON &operator[](const std::string &s) const { return value_[s]; }\n};\n多么简单呐（赞赏）只需要用 general 的 Node::parse 解析 object 里面的任意 value，将得到的 value node 移动进自己的 unordered_map (hash map) 就写完了！\n想必看完上面的代码和注释大家都懂了吧（跑路）\n因此整个 json 的 parser 就非常好写了：\nstatic JSON parse(std::string_view sv) {\n  auto res = Node::parse(sv, 0);\n  removeWhiteSpaces(sv);\n  if (!sv.empty()) {\n    throw getJSONParseError(sv, \"EOF\"); // 希望整个 json 只有一个 root node\n  }\n  return JSON(std::move(res));\n}\n为了方便使用……\n现在雏形已经出来了，但是每个 JSON 必须要显式用 make_unique 构造，以至于你会看到类似这样的蠢蠢的语法：\njson[\"some_key\"] = std::make_unique<JSON::Boolean>(false);\n怎么将它简化呢？\nclass JSON {\npublic:\n  JSON() : _uptr(std::make_unique<Null>()) {}; // 一个 JSON 默认应该是个 null\n  JSON(JSON &&) = default;\n\n  template <typename T>\n    requires std::is_base_of_v<Node, T>\n  explicit JSON(std::unique_ptr<T> &&uptr) : _uptr(std::move(uptr)) {} // 用unique ptr构造\n\n  JSON &operator=(JSON &&) = default;\n  JSON &operator=(const JSON &) = delete;\n\n  inline JSON &operator=(std::unique_ptr<Node> &&uptr) {\n    _uptr = std::move(uptr);\n    return *this;\n  }\n\n  template <typename T>\n    requires std::is_base_of_v<Node, T>\n  explicit JSON(T &&node) : _uptr(std::make_unique<T>(std::forward<T>(node))) {} // 用 value 的类构造\n\n  template <typename T>\n    requires std::is_base_of_v<Node, T>\n  inline JSON &operator=(T &&node) {\n    _uptr = std::make_unique<T>(std::forward<T>(node));\n    return *this;\n  }\n\n  explicit JSON(std::nullptr_t) : JSON() {}\n  inline JSON &operator=(std::nullptr_t) { // 用 nullptr 赋值\n    _uptr = std::make_unique<Null>();\n    return *this;\n  }\n\n  explicit JSON(bool boolean) : _uptr(std::make_unique<Boolean>(boolean)) {}\n  inline JSON &operator=(bool boolean) { // 用 bool 赋值\n    _uptr = std::make_unique<Boolean>(boolean);\n    return *this;\n  }\n\n  template <typename IntN>\n    requires std::numeric_limits<IntN>::is_integer\n  explicit JSON(IntN integer)\n      : _uptr(std::make_unique<Number>(static_cast<int64_t>(integer))) {}\n  template <typename IntN>\n    requires std::numeric_limits<IntN>::is_integer\n  inline JSON &operator=(IntN integer) { // 用看上去是 integer 的任何类型赋值\n    _uptr = std::make_unique<Number>(static_cast<int64_t>(integer));\n    return *this;\n  }\n\n  explicit JSON(double float_number)\n      : _uptr(std::make_unique<Number>(float_number)) {}\n  inline JSON &operator=(double float_number) { // 用 浮点数 赋值\n    _uptr = std::make_unique<Number>(float_number);\n    return *this;\n  }\n\n  explicit JSON(std::string str)\n      : _uptr(std::make_unique<String>(std::move(str))) {}\n  inline JSON &operator=(std::string str) { // 用 string 赋值（因为总是要复制一遍的，不妨直接用 std::string 然后 move 进去\n    _uptr = std::make_unique<String>(std::move(str));\n    return *this;\n  }\n\n  explicit JSON(const char *c_str) : _uptr(std::make_unique<String>(c_str)) {}\n  inline JSON &operator=(const char *c_str) { // 用 C 风格 string 赋值\n    _uptr = std::make_unique<String>(c_str);\n    return *this;\n  }\n\n  std::unique_ptr<Node> &operator->() { return _uptr; } // 重载 ->\n  const std::unique_ptr<Node> &operator->() const { return _uptr; }\n}\n多么简单呐（赞赏）\n特别的，为了方便写 Array，我们写个 makeArray，用万能引用确保东西原样转发进去：\nstatic void pushArray_(Array &) {}\ntemplate <typename T> static void pushArray_(Array &arr, T &&t) {\n  arr.value_.emplace_back(JSON(std::forward<T>(t)));\n}\n\ntemplate <typename T, typename... Args>\nstatic void pushArray_(Array &arr, T &&t, Args &&...args) {\n  arr.value_.emplace_back(JSON(std::forward<T>(t)));\n  pushArray_(arr, std::forward<Args>(args)...);\n}\n\ntemplate <typename... Args> static Array makeArray(Args &&...args) {\n  Array res;\n  pushArray_(res, std::forward<Args>(args)...);\n  return res;\n}\n现在你可以这样 dump 一个 JSON 了\nJSON json{std::make_unique<JSON::Object>()};\nauto &root = json->cast<JSON::Object>();\nroot[\"123\"] = 456;\nroot[\"\\n\\n\"] = \"hello\";\nroot[\"\\b\\t\"] = 114.514;\nroot[\"true\"] = false;\nroot[\"null\"] = nullptr;\nroot[\"array\"] =\n    JSON::Array::makeArray(1, true, 11514.1919, -2147483648, \"miao\", nullptr);\nroot[\"array2\"] = JSON::Array::makeArray(\n    1,\n    JSON::Array::makeArray(1, JSON::Array::makeArray(4),\n                           JSON::Array::makeArray(JSON::Array::makeArray(5)),\n                           JSON::Array::makeArray(1)),\n    4, JSON::Array::makeArray());\n\nstd::cout << json->dump();\n输出（美化后）\n{\n  \"array2\": [1, [1, [4], [[5]], [1]], 4, []],\n  \"array\": [1, true, 11514.1919, -2147483648, \"miao\", null],\n  \"null\": null,\n  \"\\b\\t\": 114.514,\n  \"true\": false,\n  \"\\n\\n\": \"hello\",\n  \"123\": 456\n}\n真是简简又单单啊\n完整代码\nhttps://github.com/Lhcfl/cpp-json-learn/blob/main/cppjson.h\n684 行，实现了一个还可以的玩具 C++ 解析库，并且能 90% 情况下和 JavaScript 的 JSON 解析保持抛出一致的异常（）\n所以\n看到这坨东西的时候 ⬇️ 还写 C++ 吗.png 还写吗\ntemplate <typename IntN>\n  requires std::numeric_limits<IntN>::is_integer\nexplicit JSON(IntN integer)\n    : _uptr(std::make_unique<Number>(static_cast<int64_t>(integer))) {}\ntemplate <typename IntN>\n  requires std::numeric_limits<IntN>::is_integer\ninline JSON &operator=(IntN integer) { // 用看上去是 integer 的任何类型赋值\n  _uptr = std::make_unique<Number>(static_cast<int64_t>(integer));\n  return *this;\n}\n别用 C++"},{"type":"post","id":"write-your-own-std-optional-universal-ref-in-c","title":"DIY std::optional: Using Universal References in C++","url":"/blog/write-your-own-std-optional-universal-ref-in-c/","content":"This blog was written entirely because of the item Familiarize yourself with alternatives to overloading on universal references in Effcetive Morden C++. We start with a practical problem trying to emulate std::optional in C++14, because optional monads are a good paradigm for expressing values ​​that may be null, rather than assuming everything is maybe null which can easily break through the type system.\n写下这篇文章完全是因为看到了 Effcetive Morden C++ 中的熟悉通用引用重载的替代方法。我们从一个现实的问题开始，即在 C++14 尝试模拟 std::optional，因为 optional 是表达可能为空的值的时候一个很好的范式，而不是假定一切都可能为 null 并轻易击穿类型系统。\n\nSimplest Approach\n最简单的方法\nObviously, a std::optional<T> is just a wrapper around two things: a T and a bool indicating whether T makes sense. We can easily write code like this:\n显然，一个 std::optional<T> 就是两个东西的包装：一个 T 和一个 bool，指示 T 是否有意义。我们可以很容易写下类似这样的代码：\nclass _None_t {};\nstatic constexpr _None_t None;\n\ntemplate <class T> class option {\n  T val;\n  bool has_val;\n\npublic:\n  option() : has_val(false) {};\n  option(const _None_t &) : has_val(false) {};\n  option(const T &x) : val(x), has_val(true) {};\n  option(T &&x) : val(std::move(x)), has_val(true) {};\n  option(const option &copy_from) = default;\n  option(option &&move_from) = default;\n\n  option &operator=(const option &x) = default;\n  option &operator=(option &&x) = default;\n  option &operator=(const T &x) {\n    val = x;\n    has_val = true;\n    return *this;\n  };\n  option &operator=(T &&x) {\n    val = std::move(x);\n    has_val = true;\n    return *this;\n  }\n  option &operator=(const _None_t &) {\n    has_val = false;\n    return *this;\n  }\n}\nThe correctness of this is obvious, but it is not guaranteed to always compile. Obviously, T may have to be initialized with a meaningful parameter. This makes it impossible for our option<T> to be None in this case.\n这样做的正确性当然是显然的，但是它不保证总是能编译。显然，T 有可能必须要一个有意义的参数来初始化。这使得对于这种情况，我们的 option<T> 根本无法为 None。\nTo solve this situation, we naturally think of pointers. A pointer can always be nullptr unless it is allocated with a real value, so we can rewrite our option<T> as a alias of std::unique_ptr<T>, adding an additional function has_value() const to check if it is nullptr, and a copy constructor. Such a class is easy to write, but it obviously still has disadvantages. The biggest disadvantage is that it needs to dynamically allocate memory, and on the heap, which seriously slows down our option<T>.\n为了解决这个情况，我们自然会想到指针。指针在除非它被赋予一个真正的值之前可以一直是 nullptr，因此我们可以重写我们的 option<T> 为一个 std::unique_ptr<T> 的重命名，添加了一个额外的函数 has_value() const 判断它是不是 nullptr，并添加复制构造。这样的类很容易写出，但是它显然仍然有缺点。最大的缺点是它需要动态分配内存，而且是在堆上，这严重拖慢了我们的 option<T> 的速度。\nTo solve this problem, we will use union, a keyword inherited from C that allows multiple different types to coexist in the same memory position. But here union has another use: shielding the constructor and destructor of T and letting us manage it ourselves.\n为了解决这个问题我们会使用 union，这个继承自 C 的关键字可以将多个不同类型共存于同一块内存空间。但在这里 union 另一个用途：屏蔽 T 的构造函数和析构函数，让我们自己托管它。\ntemplate <typename T> class option {\n  union {\n    T val;\n  };\n  bool has_val;\n};\nIn the above definition we put T in a union, which disables the constructor and destructor of T. Next, when we need to make sure that option actually has a T, we use placement new to construct T in place.\n在上面的定义中我们把 T 放在 union 中，这禁用了 T 的构造和析构函数。接下来，当我们需要让 option 里面真的有 T 的时候，我们用 placement new 原地构造 T。\n  option(T &&f) : val(std::move(f)), has_val(true) {}\n  option(const T &f) : val(f), has_val(true) {}\n  option() : has_val(false) {};\n  option(const none_t &) : has_val(false) {};\n  option(const option &b) : has_val(b.has_val) {\n    if (has_val)\n      new (&val) T(b.val);\n  }\n  option(option &&b) : has_val(b.has_val) {\n    if (b.has_val) {\n      new (&val) T(std::move(b.val));\n    }\n  }\nThis looks perfect. In fact, it does roughly meet our needs, but is that enough? Suppose we have a custom class that needs to use string as a constructor. A string can certainly be constructed with const char*, so we naturally try to construct it with a string literal, like this. But does it really work as we wish? Guess if the following code will compile?\n这看上去非常完美。实际上，它也确实能很大程度上满足了我们的需求，但是让我们精益求精。假如我们有一个自定义类，需要用到 string 作为构造函数。一个 string 当然可以用 const char* 来构造，所以我们自然而然地尝试用字符串字面量来构造它，就像这样。但是它真的能如我所愿吗？猜猜下面的代码会不会通过编译？\nstruct StringWrapper {\n  std::string s;\n  StringWrapper(std::string str) : s(std::move(str)) {}\n};\nint main() {\n  option<StringWrapper> test(\"123\");\n  // opt_test.cpp: In function 'int main()':\n  // opt_test.cpp:123:45: error: no matching function for call to 'option<StringWrapper>::option(const char [4])'\n}\nThe answer is no! You need to explicitly construct a StringWrapper object to call the option<StringWrapper> constructor, because the option<StringWrapper> call function does not accept const char [4] as a parameter. C++ will not automatically “forward” it.\n答案是否定的！你需要显式构造一个 StringWrapper 对象才能调用 option<StringWrapper> 的构造函数，因为 option<StringWrapper> 的调用函数并不能接受 const char [4] 作为参数。C++ s 不会自动“转发”它。\nUniversal Referances\n通用引用\nIn order to forward the arguments to T’s constructor, as if our option<T> is actually T, we need to use perfect forwarding and universal references.\n为了转发参数到 T 的构造函数，就像我们的 option<T> 实际上是 T 一样，我们需要用到完美转发和通用引用。\n\nIn fact, “T&&” has two different meanings. One is rvalue reference, of course. Such references behave exactly the way you expect: they bind only to rvalues, and their primary raison d’être is to identify objects that may be moved from.\n事实上，“T&&”有两种不同的意思。第一种，当然是右值引用。这种引用表现得正如你所期待的那样：它们只绑定到右值上，并且它们主要的存在原因就是为了识别可以移动操作的对象。\nThe other meaning for “T&&” is either rvalue reference or lvalue reference. Such references look like rvalue references in the source code (i.e., “T&&”), but they can behave as if they were lvalue references (i.e., “T&”). Their dual nature permits them to bind to rvalues (like rvalue references) as well as lvalues (like lvalue references). Furthermore, they can bind to const or non-const objects, to volatile or non-volatile objects, even to objects that are both const and volatile. They can bind to virtually anything. Such unprecedentedly flexible references deserve a name of their own. I call them universal references.\n“T&&”的另一种意思是，它既可以是右值引用，也可以是左值引用。这种引用在源码里看起来像右值引用（即“T&&”），但是它们可以表现得像是左值引用（即“T&”）。它们的二重性使它们既可以绑定到右值上（就像右值引用），也可以绑定到左值上（就像左值引用）。 此外，它们还可以绑定到 const 或者 non-const 的对象上，也可以绑定到 volatile 或者 non-volatile 的对象上，甚至可以绑定到既 const 又 volatile 的对象上。它们可以绑定到几乎任何东西。这种空前灵活的引用值得拥有自己的名字。我把它叫做通用引用（universal references）。\nhttps://cntransgroup.github.io/EffectiveModernCppChinese/5.RRefMovSemPerfForw/item24.html\n\nAssuming that everyone already understands how to write perfect forwarding, or you can also read the relevant description in Effective Morden C++, I won’t go into details here. The only problem with perfect forwarding is that it is not convenient to overload. It is easy to write a perfect forwarding constructor:\n关于完美转发的写法假定大家都已经懂了，不懂的也可以看 Effective Morden C++ 相关的描述，这里不用多说了。完美转发唯一的问题是，它并不方便重载。我们很容易写出一个完美转发的构造函数：\n  template <typename Arg>\n  option(Arg &&f) : val(std::forward<Arg>(f)), has_val(true) {}  // <---- Perfect forwarding\n  option(const option &b) : has_val(b.has_val) {\n    if (has_val)\n      new (&val) T(b.val);\n  }\n  option(option &&b) : has_val(b.has_val) {\n    if (b.has_val) {\n      new (&val) T(std::move(b.val));\n    }\n  }\nBut these two overloads do not work as we expect. Compiling the following code will produce a compiler error:\n但是这两个重载并不会像我们想象的那样工作。编译以下代码，它会产生编译器错误：\nstruct StringWrapper {\n  std::string s;\n  StringWrapper(std::string str) : s(std::move(str)) {}\n};\n\nint main() {\n  option<StringWrapper> test1;\n  option<StringWrapper> test2(test1);\n  // In instantiation of 'option<T>::option(Arg&&) [with Arg = option<StringWrapper>&; T = StringWrapper]':\n  //    required from here\n  //  11 |   option<StringWrapper> test2(test1);\n  //     |                                    ^\n  // error: no matching function for call to 'StringWrapper::StringWrapper(option<StringWrapper>&)'\n  //  23 |   option(Arg &&f) : val(std::forward<Arg>(f)), has_val(true) {}\n}\nHow could that be! We did clearly declared option(const option &b)! But the overloading is not in this order. For more information on why the compiler overloads in this way, please see Avoid overloading on universal references, which I will not go into here. In short, when encountering option<T>, the compiler will expand the universal reference above to:\n怎么会呢！明明我们声明了 option(const option &b)! 但是重载并不是按这个顺序来的。关于编译器为什么会这样重载，请看 Avoid overloading on universal references，这里不赘述。总而言之，遇到 option<T> 的时候，编译器会将上面那个通用引用展开为：\n  // template <typename Arg> // <-- Arg = option&\n  option(option &f) : val(f), has_val(true) {}\nObviously it is a better match than the copy constructor of const option&, so the compiler chooses it.\n显然这相比于 const option& 的复制构造函数是一个更好的匹配，因此，编译器选择了它。\nUse enable_if\n使用 std::enable_if\n(Of course, C++20 introduces better practices, namely concepts, but let’s use the features of C++14 to build our option<T>.)\n（当然，C++20 引入了更好的做法即 concepts，但是我们这里先用 C++14 就有的功能来构建我们的 option<T>。）\n\nstd::enable_if gives you a way to force compilers to behave as if a particular template didn’t exist. Such templates are said to be disabled. By default, all templates are enabled, but a template using std::enable_if is enabled only if the condition specified by std::enable_if is satisfied.\nstd::enable_if 可以给你提供一种强制编译器执行行为的方法，像是特定模板不存在一样。这种模板被称为被禁止（disabled）。默认情况下，所有模板是启用的（enabled），但是使用 std::enable_if 可以使得仅在 std::enable_if 指定的条件满足时模板才启用。\n\nI am not going to explain the syntax of enable_if here. In short, after introducing enable_if, our constructors become like this;\n这里不打算解释 enable_if 的语法。总而言之，引入 enable_if 后，我们的构造函数变成了这样；\n  template <typename Arg,\n            typename std::enable_if< expression , bool>::type = true>\n  option(Arg &&f) : val(std::forward<Arg>(f)), has_val(true) {}\nWhere the expression is an expression that only when it is true will the overloaded function be called. Obviously, it is appropriate to call perfect forwarding only when Args can be used to construct T (for convenience, we do not consider meaningless duplicate types like option<option<T>>). Therefore, the expanded code becomes obvious (to highlight the type traits, I use not instead of !):\n其中 expression 是某个表达式，只有在它成立的时候，这个重载函数才会被调用。显然，我们只有在 Args 可以用来构造 T 的时候调用完美转发是合适的（为了方便，我们不考虑像 option<option<T>> 这样无意义的重复类型）因此，详细的写法就变得显然了（为了突出 type traits 的关系，我使用了 not 代替 !）：\n// ...\n  template <typename Arg>\n  using OptionConstructable =\n      std::is_base_of<option<T>,\n                      std::remove_reference_t<std::remove_const_t<Arg>>>;\n\npublic:\n  template <typename Arg,\n            std::enable_if_t<std::is_constructible<T, Arg>::value and\n                                 not OptionConstructable<Arg>::value,\n                             bool> = true>\n  option(Arg &&f) : val(std::forward<Arg>(f)), has_val(true) {}\n  option() : has_val(false) {};\n  option(const none_t &) : has_val(false) {};\n  option(const option &b) : has_val(b.has_val) {\n    if (has_val)\n      new (&val) T(b.val);\n  }\n  option(option &&b) : has_val(b.has_val) {\n    if (b.has_val) {\n      new (&val) T(std::move(b.val));\n    }\n  }\n// ...\nCode and Tests\n代码和测试\nFinally, our self-made std::optional<T> using universal references is ready! Here is what the code looks like:\n最后，我们使用通用引用的自制 std::optional<T> 就写好了！代码长这样：\n#pragma once\n#include <type_traits>\n#include <utility>\n\nstruct none_t {};\nconstexpr none_t None;\n\ntemplate <typename T> class option {\n  union {\n    T val;\n  };\n  bool has_val;\n\n  void release() {\n    if (has_val)\n      val.~T();\n    has_val = false;\n  }\n\n  template <typename Arg>\n  using OptionConstructable =\n      std::is_base_of<option<T>,\n                      std::remove_reference_t<std::remove_const_t<Arg>>>;\n\npublic:\n  template <typename Arg,\n            std::enable_if_t<std::is_constructible<T, Arg>::value and\n                                 not OptionConstructable<Arg>::value,\n                             bool> = true>\n  option(Arg &&f) : val(std::forward<Arg>(f)), has_val(true) {}\n  option() : has_val(false) {};\n  option(const none_t &) : has_val(false) {};\n  option(const option &b) : has_val(b.has_val) {\n    if (has_val)\n      new (&val) T(b.val);\n  }\n  option(option &&b) : has_val(b.has_val) {\n    if (b.has_val) {\n      new (&val) T(std::move(b.val));\n    }\n  }\n\n  option &operator=(none_t) {\n    release();\n    return *this;\n  }\n  template <typename Arg>\n  std::enable_if_t<std::is_constructible<T, Arg>::value and\n                       not OptionConstructable<Arg>::value,\n                   option &>\n  operator=(Arg &&fwd) {\n    if (has_val) {\n      val = std::forward<Arg>(fwd);\n    } else {\n      new (&val) T(std::forward<Arg>(fwd));\n    }\n    has_val = true;\n    return *this;\n  }\n  template <typename Arg>\n  std::enable_if_t<OptionConstructable<Arg>::value, option &>\n  operator=(Arg &&fwd) {\n    has_val = fwd.has_val;\n    val = std::forward<T>(fwd.val);\n    return *this;\n  }\n\n  constexpr bool has_value() const noexcept { return has_val; }\n  T &value() { return val; }\n  const T &value() const { return val; }\n\n  T *operator->() { return &val; }\n  T const *operator->() const { return &val; }\n\n  ~option() { release(); }\n};\nWhat a lovely code! Comparing to the real std::optional, the behavior of our’s is very consistent in allocation and moving or copying.\n多么优美的代码！将它和真正的 std::optional 对比，无论是分配内存还是移动/拷贝的行为都非常一致。\nAnd C++20\n以及 C++20\nWhen using C++20, a great improvement is that we can use concepts to replace complex and difficult std::enable_if to get more semantic error prompts. So the original std::enable_if can be replaced with requires, like this:\n当我们使用 C++20 的时候，一个很大的特点是我们可以用 concepts 来替换复杂难用的 std::enable_if 并且获得更加语义化的错误提示。所以原先的 std::enable_if 可以替换成 requires，就像这样：\n template <typename Arg>\n    requires(std::is_constructible<T, Arg>::value and\n             not OptionConstructable<Arg>::value)\n  option(Arg &&f) : val(std::forward<Arg>(f)), has_val(true) {}\n  option() : has_val(false) {};\n  option(const none_t &) : has_val(false) {};\n  option(const option &b) : has_val(b.has_val) {\n    if (has_val)\n      new (&val) T(b.val);\n  }\n  option(option &&b) : has_val(b.has_val) {\n    if (b.has_val) {\n      new (&val) T(std::move(b.val));\n    }\n  }\n\n  option &operator=(none_t) {\n    release();\n    return *this;\n  }\n  template <typename Arg>\n    requires(std::is_constructible<T, Arg>::value and\n             not OptionConstructable<Arg>::value)\n  option &operator=(Arg &&fwd) {\n    if (has_val) {\n      val = std::forward<Arg>(fwd);\n    } else {\n      new (&val) T(std::forward<Arg>(fwd));\n    }\n    has_val = true;\n    return *this;\n  }\n  template <typename Arg>\n    requires OptionConstructable<Arg>::value\n  option &operator=(Arg &&fwd) {\n    has_val = fwd.has_val;\n    val = std::forward<T>(fwd.val);\n    return *this;\n  }\nWhat a simpler code!\n真是简单了不少呢！\nAnd Rust\n以及 Rust\nAfter writing a lot of C++ dark magic, let’s see how Rust’s Option is defined.\n写完了丰富的 C++ 黑魔法，让我们看看 rust 的 Option 是怎么定义的。\nenum Option<T> {\n    None,\n    Some(T),\n}\nFuck.\n操。\nConclusion 结论\nDon’t use C++.\n别用 C++"},{"type":"post","id":"pass-test-joke","title":"Introduction to Pass Principles","url":"/blog/pass-test-joke/","content":"\nLinca Insania†    My Cat†    No one\nXYN University\n{me,cat,none}@joke.fake.email\nlhcfl.github.io\n\n\nAbstract: Passness is part of the terminology of transition. Passness is the degree of likelihood that a transgender person is socially identified as the gender they identify with, and is a core part of pass theory, which is crucial to the quality of life of transgender people. However, distinguishing passness is not an easy task, and existing theories cannot address this issue well. There are several reasons. First, most known descriptions of passness are non-theoretical and cannot be accurately described by mathematical language. Second, there is a lack of rigorous specifications as a reference to classify a test trans as pass. Third, passness is stateful, and stateful pass testing remains challenging due to the large input space.\nIn this paper, we propose several new passness testing systems called CBA to address the above challenges related to passness testing.\n\n\n1 Introduction\nPassing is when a person is perceived as gender by which they identify or which they are attempting to be seen. For transgenders, passing is a very important part of life. Passness, the degree of passing, directly determines the quality of their life.\nTo discover potential transgenders in life and send them to the conservative™ criticism network, transphobia attackers often deploy trans-aware attacks.\nSuch attacks typically take one of two forms: (1) they target genitalia, for example, by requiring genital identification before entering certain places, a typical example being radfem-safe toilets. These attacks are costly for attackers because such identification costs a lot of money and requires them to have privileges, and is unwelcome because of privacy violations. Or (2) they target gender expression itself, by analyzing the victim’s behavior extensively to predict whether the victim has a dick or a pussy or even both. As such, they are typically performed in a humachine learning manner, with the attacker constructing vectors by comparing the differences between trans and cis in certain behaviors, and reducing the loss rate through a backpropagation function. If an effective recognition model is eventually trained, the cost and effort for the attacker is minimal.\n2 Related Work\nEarly work on learning to guess the presence or absence of a dick using the stare method. For better appeal, the method discretizes the feature dimensions and generates an adversarial network using a cross-entropy loss. Nonsense, naked eye X-rays, “remove your female status!” has been used to learn from multimodal demonstrations in TERF. Radfem is a class of powerful generative models because they model ideal conditions, or what they think the current situation is, rather than reality itself. The key idea behind Radfem is to losslessly and iteratively transform simple behavioral features into target features by applying a sequential denoising process. They have been used to model state-conditional action distributions in imitation learning from low-dimensional inputs as well as visual sensory inputs. And show poor pattern coverage and extremely low fidelity in trans prediction compared to other methods.\n3 Method\nOur attack methods are divided into two types of naive attack models, BOA and CBA.\n3.1 Behaviour-Only Attack (BOA)\nThis is most often the case when one person sees another person engaging in a behavior and tries to distinguish whether or not they are transgender. We assume that the attacker is not looking to extensively review the person’s history, but is simply trying to identify the person through a single behaviour. In this type of attack, only some of the behaviors being expressed are known, and the attacker tries to find the person who performed the corresponding actions. This is the most difficult attack, but also the most likely attack, as only the behavior expression is required.\nA general batch behaviour-only attack is carried out as follows:\n\nThe simulator randomly selects a cisgender woman m_0 and a transgender woman m_1 as the subject.\nThe simulator uniformly generates a bit c \\gets \\{0, 1\\} at random.\nThe simulator lets m_c pick some actions to behave and sends the behavior result b to the adversary.\nThe adversary receives the behaviour b of m_c, and attempts to “guess” whose behaviour it received, and outputs a bit c'.\n\nA transgender has indistinguishable passness under a behaviour-only attack if after running the above experiment the adversary can’t guess correctly c'=c with probability non-negligibly better than \\frac 1 2.\n3.2 Chosen-Behaviour Attack (CBA)\nIn practice, however, a hateful transphobia may observe, and even, interact with a person over a long period of time to infer their assigned gender. We therefore propose a stronger attack, the chosen-behaviour attack. In this type of attack, the attacker chooses random actions and obtains the corresponding behaviours and tries to find the transgenders. This attack is easier as a lot of information is already available.\nA general batch chosen-behaviour attack is carried out as follows:\n\nThe oracle randomly selects a cisgender woman m_0 and a transgender woman m_1 as the subject.\nThe oracle uniformly generates a bit c \\gets \\{0, 1\\} at random.\nThe adversary may choose aribitary n actions.\nThe adversary then sends these n actions to the behaviour oracle.\nThe behaviour oracle will then let m_c to behave these actions send the result back to the adversary.\nThe adversary receives n behaviours back from the oracle, in such a way that the attacker knows which behaviour corresponds to m_c.\n\nBased on these behaviours, the adversary will have lots of information to try to guess the keyword c that the oracle uses to select trans or cis women. After that,\n\nThe oracle lets m_c pick some action to do and sends the behavior result b to the adversary.\nThe adversary receives the behaviour b of m_c, and attempts to “guess” whose behavior it received, and outputs a bit c'.\n\nA transgender has indistinguishable passness under a chosen-behaviour attack if after running the above experiment the adversary can’t guess correctly c'=c with probability non-negligibly better than \\frac 1 2.\n4. Conclusion\nWe present Chosen-Behaviour Attack, a cryptographically-inspired approach to trans identification. Our approach sets a new state-of-the-art in imagination, outperforming existing strategies for identifying trans. CBA builds on recent advances in cryptographically-secure passes and shows how their combination can be a powerful approach for identifying trans from behavior. Our future work includes learning and expanding training data in both simulation and the real world.\n5. Acknowledgements\nThanks to my Schrodinger’s cat which steadily got nothing when I observe and ChatGPT for their contributions to this article, and thanks to you for the boring time before the final exam. Without you, I would not be able to write such boring things.\nReferences\n"},{"type":"post","id":"programing-language-impressions","title":"Programing Language Impressions","url":"/blog/programing-language-impressions/","content":"Impressions of the programming languages I have come across\n\nC\n老登语言，不如说我非常难以理解为什么这玩意几乎就是个汇编的封装器却会成为各大高校的入门教材……？\nC 语言根本谈不上什么设计，因为它可以说就是没有设计。它就是个被造出来的人类可读的汇编简记法，然后碰巧火了而已。所以我不承认什么 C 的优秀，C 优秀根本就不在于它是 C，而在于用 C 写的那些 killer app，比如 UNIX。\n的确，实事求是的说，C 语言是最通用、最可移植的语言，但是这并不是因为 C 的设计优秀，恰恰相反其实是因为 C 就是一个汇编的封装，可移植的其实不是“优秀的语法”，而是汇编。如果你要说 C 优秀，那么汇编也优秀。\n关于 C 语言的缺点也许我能说一箩筐。在这里说几个很重要的\n\n\n类型环绕： C 的变量类型既不是后置也不是前置，可以说完全就是反人类的环置。C 语言为了省几个标记，整出了一套奇丑无比的类型标记。让我们举个例子\nvoid (*signal(int, void(*)(int)))(int);\n猜猜它是什么？一个浸淫 C 语言多年的人或许能马上说出来，但我懒得用 C 的类型规则详细解释。总而言之，它的作用是\nfn signal(x: i32, f: fn (sig: i32)) -> fn(a: i32);\nfn signal(s: i32, f: *const fn (a: i32) void) *const fn (a: i32) void\n类型扭曲成环状，需要你瞻前顾后，解方程一样地解出一个 variable 到底是什么类型。你可别说这是什么构造出的用不上的东西。这是 signal 库函数，《C 陷阱与缺陷》讲过如何逐渐写出这样一个类型。\n这种环置的做法不仅成为了经久不衰的 C 语言考题（在现代的语言里你都不需要考——类型非常直观），而且给 C++ 带来了极大的麻烦，让 C++ 的文法不得不非常复杂。可笑的是，不少习惯了 C 语言的人觉得这种扭曲的环状类型才是自然，反而觉得 typescript 那样的类型后置是错误。\n\n\n简陋：图灵完备又怎么样？要知道 brainfuck 也是图灵完备的。C 的一大缺点就是它简陋的没话说。没有泛型，很难避免 void* 满天飞。没有 namespace，随时要小心名字冲突。没有哪怕是 defer 这样的东西，错误处理/垃圾回收纯靠 goto 仙人，或者写宏手动把代码压栈这样的奇妙技巧。当然你可以说写 C 就是为了底层为了手动操作内存为了对机器有全面控制——先不说“我能管好内存”的自信带来了多少亿美元的损失，多少个印象深远的 0 day，C 也不是真正的底层啊？C Is Not a Low-level Language: Your computer is not a fast PDP-11. 这篇文章讲述了理由：\n\n低级语言的一个共同属性是它们速度很快。特别是，它们应该易于转换为快速代码，而不需要特别复杂的编译器。一个足够聪明的编译器可以使语言变得快的论点是 C 语言的支持者在谈论其他语言时经常不屑一顾的论点。\n不幸的是，提供快速代码的简单翻译对于 C 来说并非如此。尽管处理器架构师投入了英勇的努力来尝试设计能够快速运行 C 代码的芯片，但 C 程序员期望的性能水平只能通过极其复杂的编译器转换才能实现。Clang 编译器（包括 LLVM 的相关部分）大约有 200 万行代码。即使只计算使 C 快速运行所需的分析和转换传递，加起来也接近 200,000 行（不包括注释和空行）。\n\nC 在它诞生的年代确实是底层语言——但现在 ​ 已经 53 年过去了。PDB-11 早就已经成老古董了。现在随便哪家流行 CPU 都有一堆复杂的指令预测，三级缓存，向量计算，而所有这些东西在 C 语言里都需要付出更多的努力来完成，例如，像 Zig 和 Rust 这样的现代底层语言早就提供了原生的向量运算。Rust 的所有权系统也允许编译器做极其激进的优化，where C/C++ 许多人口口相传的是“不要开 O3”——为什么？当然是因为语言提供的约束不足，编译器无从做优化假设，甚至有时候程序员还直接写了未定义行为。\nC 语言程序员，嵌入式的或许不算，但是通用架构下 C 语言根本就很难说是在接近底层。它只是给了人底层的幻觉。\n\n\nC++\nAwesome language only when for algorithm competitions. 内存泄露？让它漏呗我们要的是超快速度！\n但是除了算法竞赛以外 C++ 实在是拉胯得让人无话可说。\n其实 C++ 挺遗憾的，C++0x 几乎就是个废物，在 90 年代末相对高级的语言群魔乱舞起来的时候只有 C++ 在那里不思进取吃老本，终于等 C++11 出来了挺大江山已经流失了，笑\n你很难找到一门语言又进步又过时，既简单又难……除了 C++\n可以说 C++ 其实很 fancy，它融入了很多新概念，但是它融入得不够好。都怪那该死的兼容性（乐）。到现在 C++ 的语法可以称得上一句沉重，但是沉重中又没有多少用得上的……\n举个例子吧 std::optional<T>. 这玩意好吗？太好了。Null 的发明者都亲口说 null 完全是一次数十亿美元级的错误了。而我得说 C++ 简直就是这场错误的集大成者。C++ 里到处都是类似 Null 的东西。拿特殊的值标记无效的内存区域。灾难中的灾难。\n为此明明有 Rust 可以学的，结果 C++ 就学了一个皮毛——把 optional<T> 抄过来了，然后就不管了。std::map 都有好多不同的取值方式了，什么 [] 在 key 不存在的时候返回默认 constructor，什么 at 抛出 std::out_of_range 异常， find 返回 end 迭代器，妈呀结果就是没有用上 STL 自己的 optional<T> 的——excuse me？所以你弄一个 optional<T> 是为了走时髦吗？\n至于 C++ 很难的问题，其实倒是可以接受，因为 C++ 简单——你可以同时觉得 C++ 简单和难得要死。听上去很离谱，但是是 C++，倒也正常.png\nC++ 就是那种非常适合算法竞赛、非常适合学生上课的语言。反正内存安全去他爹，裸指针乱飞，嵌套结构稍微学学就会，性能还超级高，还封装了一堆常用数据结构，它不火谁火.png\n但是复杂度摆在那里。如果要简单，那就一定有复杂在反面等着你。一门面向底层的语言，讲究极致压榨性能极致压榨空间甚至到处都是直接操作内存、还有超级多历史包袱的语言居然还能做到让一个初学编程的人轻松写出一坨狗屎也能通过编译，那要写出“优雅”的代码它肯定会很难，这一点也不难理解吧。就是它有点难过头了而已。\n很难说如果 C++再这样赶时髦地加入新功能下去是不是某种自取灭亡，只能说希望不是吧\n\n以下是说怪话时间\nC++ 真是一门优美又简洁的语言啊 真是优优又美美啊\n你看别的语言还在 <T extends U | V> 真是难难又懂懂啊 extends 是什么？竖线又是什么？真是不说人话让人难以理解呢\n再看我们 C++ 啊跟念诗一样\ntemplate<typename T>\nrequires (std::is_base_of_v(T, U) or std::is_base_of_v(T, V))\nbar foo(T&& xyz);\n你看我写了一个 T 啊当然是模板啊 又 requires 啊 is base of 就是基类啊 用 or 取代竖线英英又语语啊 哪怕是不懂 C++ 的人看到也能马 ↑ 上 ↓ 理解这是在说什么呢\n真是容易理解呢呢呢这就是我们 C++ 啊真是 CC 又加加啊\n\nCrystal\n截止到本文的上次编辑 Crystal 还是一门非常初生（？）的语言，嗯就是语法描述也不全，生态少得可怜，连编辑器提示都没有，各种地方都透露着种种不成熟\n但这玩意确实是个静态、native 语言，还是 native 语言中的异类，在 native 中做到了可以尽可能地少写类型，而且居然还有类 Ruby 语法，弄得这语言跟个动态语言似的\n非常喜欢的是 Crystal 继承自 Ruby 的一个特性，你可以随意 Reopen 一个 class 然后添加进去自己的方法。甚至官方库都是这样做的，比如 JSON 库：它直接把 int 打开了然后往里面塞了一个 to_json 的成员函数，然后所有 int 就能 to_json 了，非常的好用\nstruct Int\n  def to_json(json : JSON::Builder) : Nil\n    json.number(self)\n  end\n\n  def to_json_object_key : String\n    to_s\n  end\nend\n这个真的很妙，虽然它有一个众所周知的缺点，要克制，小心和别的库添加了冲突的成员函数。但是相比之下这个带来的简直是致命的诱惑，可以通过 reopen 创造非常具有表达力的语法，就像 Rails 做的那样。\nElixir\n认识 Elixir 是因为在 Fediverse 上知道了 Pleroma 这个软件。Elixir 似乎是借鉴了许多 Ruby 的写法和不错的地方。\nGleam\n灵感来源于 Rust 的函数式语言。虽然但是，感觉有点……简陋……\n在 tour 里一开始被它的长相骗了，直到看到 Gleam is an immutable language, so using the record update syntax does not mutate or otherwise change the original record 才惊觉欸 www 怎么是 immutable 的\n暂且还非常不成熟，所以呈观望态度吧。\nGleam 语言初见文章见：仿生电子锈会梦到自己变成纯函数式吗：gleam 语言初见\nHaskell\n纯函数式编程教科书级别语言。\nHaskell 的语法写起来和不是函数式的语言真的完全不一样！在 haskell 里面 a = x 完全不是赋值啊是定义了一个函数 a 返回 x xd\n⬆️ 上面是完全没学的时候写的。\n在逐渐入门了函数式语言以后，其实觉得 Haskell 不是一门很适合入门的函数式语言，它应该是半工业半学术的函数式语言中最有名的那个，但它缺点是（可能比较老吧？）有很多不够的地方。\n比如 map :: (a -> b) -> [a] -> [b]，之前开玩笑说 Haskell 才是真正的 Lisp（列表处理器），因为 Haskell 在语法上给了列表太优先的支持…… List 的 map 比 general 的 functor 发现得更早，所以占了这个位置，然后 fmap :: Functor f => (a -> b) -> f a -> f b 就不得不加个 f 表示区别，但是对于 List 而言 fmap 和 map 其实完全是一个作用。\n同样的，Haskell 不是用 List a 表示一个元素类型为 a 的列表，而是 [a]，List 多么特殊以至于专门在类型里占了个符号。还有 : 表示 List 的 prepend，((:) :: a -> [a] -> [a]) 把类型的 : 都占了，那么类型就只好用 :: 去了。Lisp 这个名字颁发给你 Haskell 得了（不是）\n后来的函数式语言一般都 : 表示类型，:: 表示 List prepend 了。\n我学 Haskell 其实有很多次尝试了，毕竟 Haskell 实在是太有名了，\n\n\n（乱入一张梗图）\n\n但是考虑到我学了太久的命令式语言，在 2025 年前的尝试全部无功而返，甚至连 a + b problem 都写的非常吃力。更何况 haskell 学了数学人的不良习惯（我不管我不管我就要说不良习惯），写代码喜欢跳着看，比如 dot 这个宝贵的符号居然被 Prelude 占用了！ (.) f g x = f (g x) ，然后用了一个很丑的 (&) x f = f x 比 |> 还难受。我会笑话 Haskell 人眼睛是不是倒着长的，会非常习惯于 (f4 . f3 . f2 . f1) x1 x2 x3 x4 这种操作。还有 ($ x) 这个抽象东西。可以把 $ 念成 apply，($ x) f 其实就是 f $ x 也就是 f x。——这就要说到 pointless pointfree 样式了，Haskell 人喜欢用这个样式写出紧凑而 pointfree 的代码，爽了一时更难看懂了许多（）甚至当你写出\nsum xs = foldr (+) 0 xs\n的时候，linter 都会贴心提醒您 why not\nsum = foldr (+) 0\n我去，谁 ™ 会觉得后者更好啊，除了被 Haskell 腌入味的人。\n这些！全都是我在学了可能通常被看作更难的 Lean 4（写这句话的时候我没学证明，而是 Functional Programing in Lean 4）之后，由于 Lean 4 更好的习惯，才逐渐能进一步理解更超凡脱俗（原谅我找不到好的形容词）的 Haskell。比如 Lean 4 的 · 记号和数学上的 cdot 很像，我很喜欢这个糖，(·+1) 会被 desugar to fun x => x + 1 : Nat → Nat，很好的诠释了“占位符”的概念。你也可以造出 ·/· 这个东西相当于除法函数。 嗯，于是我才意识到小学数学教会我们的 ÷ 记号其实就是分数线上方下方都用 cdot 代替了。\n不过 Haskell 给我的另一个印象是，因为这种自由性，可以不用自定义语法而类似自定义语法。例如，因为 haskell 比较的激进 pure functional，它是没有 return 这个 keyword 的。但是你却能写出\nfoo bar = do\n  baz <- bar\n  if bar then\n    return 42\n  else\n    -- do\n    -- some\n    -- logic\n    return baz\n那么 return 是什么呢？其实 return 是 pure （），就 Monad 里面那个。感觉 Haskell 应该是为了让你感觉更像命令式编程搞了这玩意\nclass Monad m where\n  return :: a -> m a\n  (>>=)  :: m a -> (a -> m b) -> m b\n这玩意只能说，虽然不如 Lean 4 直接，Lean 4 直球搞了一套 while for return break 这些东西的语法糖，但是作为一个糖吃吃味道也不错。\nIdris / Idris 2\nidris 是一门有趣的语言。但它大概需要你先学 Haskell。说不定可以说它是 better haskell，不过 idris 的生态实在是太差了，windows 支持完全是狗屎，所以我没来得及更多探索。\nidris 是一门 dependent type 支持的语言。相比于 haskell 它更好地支持了许多有趣和实用的东西。\nDependent Type 允许你还有类型安全的带长度的 List（Vect n）。解答了我多年的疑问（不是）我们为什么不能干脆把长度视为一个泛型丢进 vector 里呢？ Idris 说行，当然行：\ndata Vect : Nat -> Type -> Type where\n   Nil  : Vect Z a\n   (::) : a -> Vect k a -> Vect (S k) a\nVect 这个类型有了一个 Nat n 做参数，Idris2 基于量化类型理论实现了一个神奇的事情，如果你不用这个 n，它就能安全的在编译期被擦除，如果你用到它，它就会被保留。这里的 Nat 是一个 inductive type 可能实现成：\ndata Nat = Z      -- Zero\n         | S Nat  -- Successor\n一进制自然数有一个非常方便的结构，容易推理，而且容易与其他数据结构联系起来，比如上面的 Vect，可以很好的推理。尽管如此，我们当然并不希望这种方便是以牺牲效率为代价的。但是！Idris 它能知道 Nat（和类似的结构化类型）和数字之间的关系。这意味着它可以优化表示，以及诸如 plus 和 mult 等函数。\n有了 Vect 你就能容易写出常数时间的 len 函数（相反，List 需要遍历获取长度），\nimport Data.Vect\n\nvlen : { n : Nat } -> Vect n a -> Nat\nvlen xs = n\n\ntest_vect : Vect ?len Nat\ntest_vect = 1 :: 1 :: 4 :: 5 :: 1 :: 4 :: Nil\n\nmain : IO ()\nmain = do\n  printLn test_vect\n  printLn $ vlen test_vect\n-- [1, 1, 4, 5, 1, 4]\n-- 6\n还有 Linear Type 这个东西。\n\nIdris 2 是基于 量化类型理论（QTT） ，这是由 Bob Atkey 和 Conor McBride 开发的核心语言。在实践中，Idris 2 中的每个变量都有一个 数量 与之相关。数量是的取值是下列其中之一：\n\n0 ，表示变量在运行时被 擦除\n1 ，表示变量在运行时 正好使用一次\n不受限制 ，这与 Idris 1 的行为相同\n\n\n在 Idris 2 中你可以原生的用一些 Linear Type 的东西。这玩意核心思想大概是在结构性规则上去掉了收缩规则和弱化规则（参照： https://zhuanlan.zhihu.com/p/630206189 ）意味着 Linear 的 Type 只能使用，且必须使用一次。这种形式在一些东西上比较方便，比如说某种 resource，像 Connection 之类的，打开-关闭 总是成对出现。或者你写《编译原理》的时候你可能申请了一个 Label，那么你必须接下在 IR 中生成一个 Label declearion。\nRAII 当然可以保证一次释放，但是当一个东西的“生命周期”比较动态、甚至可能交叉的时候，常见的 RAII 模式就没那么好用了。\nJavascript / Typescript\nJavaScript 系的缺点太多我觉得没必要说了，毕竟一个 10 天写出来的语言，蹭 Java 的热度，然后意外成了互联网标准这种事情……只能说这就是现实（）\n简单说些不好的地方：\n\n没法重载运算符，写带计算的代码很丑陋（不过作为为网页服务的语言，遇到大量计算就上 WASM 了\n你永远不知道是坨什么的 this\n到现在都没扯皮出公认的标准，都是 ES6 和 CommonJS 分立\n==\n\nJavaScript 系最大的优点大概是非常原生非常友好的 async/await。单线程的设计又让你根本不用在乎资源加锁之类的异步噩梦。\n而且 JavaScript 可能可以说是流行语言里最把 lambda 函数发扬光大的语言。也是动态类型语言里类型标记做的最好的——它甚至演化出了专门的 typescript\n也是因此，TypeScript 的类型系统实在是过于完备了，以至于大家仍然某种习惯于 JS 写法然后通过复杂的体操来保证 JS 写法是类型安全的，这其实有点呃呃\n并且 TypeScript 其实不完全是 null safe 的，比如说\nconst a: string[] = [];\na[1]; // ts says string, but actually undefined\ntypescript 不检查 out of range 的可能性，以至于当你给出 string[] 这样的类型的时候 ts 会认为任何一个 number 作为 index 传入都能得到一个 string —— 但致命的是，实际上翻译出的 js 它可能是 undefined\n这个非常的坑，可以说是 TypeScript 上巨大的一个洞，直接导致 undefined 可以打穿 ts 的类型系统。可惜木已成舟便是了。\nJulia\n没学了.png\n不太喜欢它把一些常用函数丢到全局里面（比如 length），不过这语言也不是很工业的语言（？），似乎也没什么问题\n函数能管道调用，好评，就爱管道调用（）\nKoka\nhttps://koka-lang.github.io/koka/doc/book.html\n一门 research 语言，语法看起来比较的 kotlin（？），博客的 Koka 语法高亮直接偷的 Kotlin 的。特色是 first class 级的支持 algebraic effect。\ndot selection 的糖吃得我很爽，我其实不是很喜欢 |> 运算符 (|> x f = f x) 主要是因为这玩意不是很好打，一个不需要按 Shift 另一个需要。Koka 语言的 dot 运算符就是 |> 的功能，很爽。\nfun showit( s : string )\n  s.encode(3).count.println\n// the body desugars as println(count(encode(s,3)))\n这玩意不支持 currying 有点意外，但是考虑到这个语法，直觉来看，似乎 effect 和 currying 不是很搭配。\n然后还有 Trailing Lambdas, 这个糖让我想起了 Ruby 的 block 和 Kotlin 的 scope functions\n\nKoka allows anonymous functions to follow the function call instead – this is also known as trailing lambdas\n\nfun hello-ten()\n  var i := 0\n  while { i < 10 }\n    println(\"hello\")\n    i := i + 1\n比如这个 while，它看上去很像一个语法，但其实是个函数 desugared to while( fn(){ i < 10 }, fn(){ ... } )\n这样，许多的 control flow 都其实是一些用来当 control flow 的语法糖而已，看上去能很好的允许你自定义语法\nLean 4\n在学.png\n之前一直被这玩意恐怖的语法和恐怖的 unicode 符号吓退了不敢学，但是学起来发现还是很有趣（？\n可以当成定理证明器，也能作为 fp 用\nLean 4 的开发环境是真的爽啊，右侧直接显示当前所在光标位置需要什么类型，给出的是什么类型（虽然这就是定理证明器要干的事情吧（））\n据说 Haskell 适合学习函数式编程，Lean 4 适合作为实践。实际上感觉……确实（？），Lean 4 的 std 是安装好的，所有类型都可以直接跑去看 std 的源码，享受 clangd/rust analyzer 级别的顶级 lsp 体验（）\n显然这玩意完全就不是一门工程语言，所以就不在工程上评价了，但是 Lean 4 无论是平时做题还是研究抽象还是学习 functional programing 都是极好的！赞了\n虽然入门的时候讨厌符号因为不知道怎么打和是什么意思 但是用起来的时候只能说真香 数学符号真好用（）\n以及，作为 pure functional 语言有 for 和 let mut 这些东西（内部似乎是靠 rebind 和/或 state monad 做到的？），爽爽的，不像 Haskell 上手真的很……需要思维大变（（\n以及，作为学习函数式编程的语言的话，Lean4 编程真的好爽啊！！！！作为交互式定理证明器的它提供了一个非常爽的界面和 #check 和 #eval 接口，允许你快速检查一些复杂表达式的类型和求值。举个例子，看到 List.span 的描述：\n\nO(|l|). span p l splits the list l into two parts, where the first part contains the longest initial segment for which p returns true and the second part is everything else.\n\n你可以随手就写一个\n#eval \"12345abced12345\".data.span (·.isDigit)\n右侧就会直接显示运算结果\n(['1', '2', '3', '4', '5'], ['a', 'b', 'c', 'e', 'd', '1', '2', '3', '4', '5'])\n这可比 REPL 要爽多了！！！可以说连 jupyter notebook 都做不到这么爽实时交互（毕竟 Lean4 本职工作之一就是交互式定理证明器 233）\nLua\nTODO\nMoonBit\nhttps://www.moonbitlang.com/\n中国自研编程语言，长得很像带 GC 的 Rust，实际上看上去也确实是带 GC 的 Rust\n语法看下来可以说几乎全抄的 Rust，改改说不定都能直接 cargo run 了（雾），但我完全不觉得这是 MoonBit 的缺点，反而觉得是优点\n如果 MoonBit 能通过各种各样的原因发达起来，一个是继承了 Rust 的各种特性的它基本上可以算作 ML 家族，直接几乎避免了类型错误出现的可能性，相信一定能一定程度上获得人的喜爱，另一方面可以说是像 Rust 和 ML 的敲门砖。觉得 Rust 太难的人或许可以用 MoonBit，二者相辅相成，同时 MoonBit 若能流行又能一定程度上扭转 C family 和 OOP 语言带来的一些走偏了的刻板印象，或能带动人们更加接受 functional 的思想，\n另外 MoonBit 的 functional 似乎比 Rust 做得还好诶，这是官网的示例，可以看出为函数式的写法做了不少优化：\nenum Resource {\n  Text(String)\n  CSV(content~: String)\n  Executable\n}\n\nlet resources : Map[String, Resource] = {\n  \"hello.txt\": Text(\"Hello, world! A long text.\"),\n  \"test.csv\": CSV(content=\"name, age\\nAlice, 25\\nBob, 30\"),\n  \"ls.exe\": Executable\n}\n\nfn main {\n  resources\n  .iter()\n   .map_option(fn {\n    (name, Text(str)) | (name, CSV(content=str)) => Some((name, str))\n    (_, Executable) => None\n  })\n  .map(fn {\n    (name, content) => {\n      let name = name.pad_start(10, ' ')\n      let content = content\n        .pad_end(10, ' ')\n        .replace_all(old=\"\\n\", new=\" \")\n        .substring(start=0, end=10)\n      \"\\{name}: \\{content} ...\"\n    }\n  })\n  .intersperse(\"\\n\")\n  .fold(init=\"Summary:\\n\", String::op_add)\n  |> println\n}\n我很喜欢的 |> 记号也是有的\nOCaml\n在学.png\n是 ML(Meta Language)的方言，并非 pure 的函数式语言。\n感觉像是试图变得工业一点，但没完全变（？）。感觉 OCaml 很适合一个已经被 OOP 和 过程式调教好了的人去接触函数式语言，毕竟它不是纯的，只要你想就能爆改状态，但是又鼓励用函数式的方法解决问题。感觉很适合学习函数式（大概吧，学的时候其实我已经逐渐开始函数式化了 可能感受不到之前那种整个世界都不再熟悉的感觉了（）\nModules 的设计不太喜欢，没有 typeclass / trait 有点令人烦躁\n必须要吐槽一下的是 OCaml 这类 ML 系语言有点文化霸权的意味在里面，它们把字母的大小写用作了 identifer 的区分，直接造成了引入 Unicode 比较困难，然后 OCaml 大手一挥说我觉得 English 作为编程的事实标准很满意啊，然后直接抛弃了 Unicode 支持，我：？\n关键是还不是完全抛弃，它还允许了一些 Latin letters 的扩展：\n\nIdentifiers are sequences of letters, digits, _ (the underscore character), and ' (the single quote), starting with a letter or an underscore. Letters contain the 52 lowercase and uppercase letters from the ASCII set, letters ÀÁÂÃÄÅÆÇÈÉÊËÌÍÎÏÐÑÒÓÔÕÖØÙÚÛÜÝÞßàáâãäåæçèéêëìíîïðñòóôõöøùúûüýþÿ from the Latin-1 Supplement block, letters ŠšŽžŒœŸ from the Latin Extended-A block and upper case ẞ (U+189E). Any byte sequence which is equivalent to one of these Unicode characters under NFC1 is supported too.\n\n明晃晃的文化霸凌啊喂喂\nPureScript\n生成出的 JavaScript 闭包层数多得令人安息，性能不难想象了只能说\nPython\nPython 的火爆完全来自于优秀的库而不是优秀的语言设计，夸张点说 Python 完全展示了什么叫糟糕的语言设计硬被优秀的库带飞。\n完全不觉得 Python 是很适合工程实践的语言。它更多的是一门教科书语言，类似以前的 BASIC，很适合初学者浅尝辄止地入门，但是稍微复杂一点就完全是噩梦，更何况 Python 的语言设计还很糟糕\n我不喜欢 Python 设计者的审美，比如认为 lambda 函数没有必要可以用具名函数取代。也不喜欢缩进表示一个块。\n并且 Python 真的不思进取。换其它语言如果有这么多优秀的库这么多资金绝对不会放任自己的性能烂成这样，但是 Python 到写下这一段的时候都还没有成熟的 JIT。\nReScript\nOCaml in Javascript!（不是\n可以看出有很多参考了 OCaml 的地方。似乎把自己和 JSX 很绑定在了一起，感觉某种程度上是一个语言和库的混合物。\n生成的变量全部是 var 有点哈人，但是确实也没有问题，可能 var 性能要好一点？\n看到 for 循环也绑定的 var 第一反应是吓了一跳，因为有一个著名的闭包问题，如果\nfor (var i = 1; i <= 10; i++) setTimeout(() => console.log(i), i * 10);\n会输出 10 个 11，因为 i 绑定的是外部的 var，换成 let 就会正常输出 1 ~ 10 了。于是看了 ReScript 的代码生成：\nfor i in 1 to 10 {\n  Js.Global.setTimeout(() => {\n    Js.log(\"This is a test log: \" ++ i->Int.toString)\n  }, i * 100) -> ignore\n}\n这份代码生成出的是\nfor (var i = 1; i <= 10; ++i) {\n  setTimeout(\n    (function (i) {\n      return function () {\n        console.log(\"This is a test log: \" + i.toString());\n      };\n    })(i),\n    Math.imul(i, 100)\n  );\n}\n直接用传统手段把 var 用参数穿进闭包里了，这样或许会兼容性好一点（都什么年代了还在乎 IE 兼容性？），也可能快一点吧？\n很讨厌 ReScript 的 jsx 里不能插入文本自动转变成 React.string 的设计，以至于必须写成\n<div className=\"p-6\">\n  <h1 className=\"text-3xl font-semibold\"> {\"What is this about?\"->React.string} </h1>\n  <p>\n    {React.string(\"This is a simple template for a Vite project using ReScript & Tailwind CSS.\")}\n  </p>\n  <h2 className=\"text-2xl font-semibold mt-5\"> {React.string(\"Fast Refresh Test\")} </h2>\n  <Button onClick={_ => setCount(count => count + 1)}>\n    {React.string(`count is ${count->Int.toString}`)}\n  </Button>\n  <p>\n    {React.string(`Edit `)}\n    <code> {React.string(\"src/App.res\")} </code>\n    {React.string(\" and save to see Fast Refresh.\")}\n  </p>\n</div>\n哦我的上帝啊，不觉得满天的 React.string 极其的视觉噪音吗？\n当然一个成熟的项目所有这里的文本都应该（几乎应该）替换成 I18n，但是还是改变不了这个设计很恶心的事实\n我觉得 ReScript 要能达到“知名”，哪怕不是稍微撼动一点 ts 的地位，都是几乎不可能做到的\nRuby\n相当优雅的设计，动态到叛逆。我对 Ruby 最大的好感来自它不试图用各种什么哲学什么风格指南约束程序员，如果 Ruby 有哲学，那就是最大的让程序员幸福\n因此写 Ruby 代码确实很舒服——如果抛开过于动态导致的特别容易出运行时类型错误不谈的话……\nRuby 最使我影响深刻的或许是类似这样的代码\n3.times do\n  say \"hello!\"\n  sleep 1.seconds\nend\n这是我在其他任何语言都没感受到的神奇的 magic，或者说其它语言当然也能写出类似的代码，但只有 Ruby 鼓励这样做，并且到处都是这样做，让整个代码特别具有“阅读感”，哪怕一个什么都不知道的新人看到这样的代码估计也能瞬间理解它在干什么，只是可能不知道具体是什么原理而已。\nRails 宣言有说：\n\n另一个例子仅用了些许代码实现，却几乎引发了惊愕的程度。Array#second 到 #fifth（以及挑衅意味的 #forty_two）。这些别名的存取器，非常严重地冒犯了常发表意见的支持者，他们说：这简直太过度设计了（几乎是编程时代的结束），这些写成 Array#[1]、Array#[2]（以及 Array[41]）不就可以了嘛。\n但时至今日，主要的抉择还是，让我自己开心。我喜欢在终端或测试里编写 people.third。不，这不合理，也不高效。可能我有病吧，但这仍能让我发自内心地微笑，满足了这个理念，也丰富了我的人生，帮我在过了 12 年之后，还仍继续参与 Rails。\n\n这个真的非常叛逆，在许多语言都在宣传“做事情只有一个最好的方式”（盯 Python），甚至直接在程序语言上拒绝和故意劣化某些风格的时候，Ruby 的想法缺是做事情可以有很多种方式，程序员来选择最让自己幸福的方式。大家都在把程序员当成 思路 -> 代码 的翻译工具，而 Ruby 选择将程序员视为作家。Ruby 的放纵让人感到某种幸福。\n另外一个令我有些感动的是 Ruby 到现在已经逐渐不再流行，但是仍然在努力做出改善，Ruby YJIT 已经可以进入生产环境并且被 Rails 默认开启。以前 Ruby 最大的诟病是它慢，慢地出奇，比 Python 还慢，但是现在 Ruby 的速度已经逐渐追上的 Python。\n说完优点，Ruby 一个很大的缺点是：你家语言三个闭包.png\n在 Ruby 中有三种不同方式去声明一个闭包，我觉得这完全是没必要的，\nRust\n虽然 Rust 社群的名声不好 语言原神，但是不得不承认的是 Rust 是一门非常优秀的语言。我对 Rust 最大的好感度其实不是内存安全性 —— 毕竟合格的程序员应该能用任何语言写出内存安全的代码 —— 而是 Rust 非常优秀的模式匹配和语法。\nOption<T> 是现代且优秀的思路，我觉得所有可能带 null 的语言都应该引入它。而 Rust 在这一类功能上做得非常好。虽然 Result<T, E> 和异常的优劣可能有待商榷。但是大部分情况，Rust 的 enum 的设计做得非常的不错，完全改变了 enum 曾经只是个不蕴含实际信息的“标记”的情况。\n如果 rust 没有内存安全作为梗小鬼的吹嘘资本，哪怕是优秀的语法设计也能让它成为一门优秀的语言。\n更新：后面我发现这是来自于 ML 语言家族的特征（xd\nRust 或许不够优雅（确实不够），但它是 C++ 竞争生态位上的唯一选手（zig 是和 C 在竞争）。原先底层语言+没有 GC 很大程度上就意味着即使是顶尖高手也可能失手写出缓冲区溢出、use after free、线程不安全等种种问题，Rust 提供了一种哪怕是初学者也能保证程序安全的方案，这是它最大的好处，也是最大的竞争力所在。\n同时，Rust 的高性能还直接带来了更多在应用层使用与 C++ 接近的性能的无 GC 原生语言的可能。比如 Discord 为什么从 Go 迁移到 Rust，在延迟敏感网络服务器上，GC 逐渐变得难以承受的时候，Rust 提供了一种安全的选择从有 GC 迁移到无 GC，这之前很大概率需要更加经验丰富的 C++ 程序员花费更多时间来确保安全性。\nStandard ML\nML 语言的老东西。\n详见 Standard ML 尝旧 这篇文章\nZig\nbetter c，相比 C 而言有出色得多的设计。\n比较喜欢 zig 似乎是从 go 上继承来的思路： defer 关键字，保证在各种情况下退出当前 scope 的时候执行，这意味着相比于 C，Zig 能更简单的确保内存分配总是伴随着释放，更不容易写出内存问题\n比如经常可能看到这样的 zig 代码：\npub fn create(\n    alloc: Allocator,\n) CreateError!*App {\n    var app = try alloc.create(App);\n    errdefer alloc.destroy(app);\n\n    // ...\n}\ndefer 比傻傻的手动在函数最后释放，一不小心还可能忘掉可高级太多了！\n不那么喜欢的是 zig 不支持方便的闭包，或者说，虽然可以写出闭包来但是很麻烦。\n然后 zig 的 compiletime 非常的神奇，我很喜欢这个，编译期间执行任意函数，把编译期干的活和普通代码融合在一起，简直太好用了\n专门为 zig 写了一篇 intro，见：更好的 C 语言：Zig 初体验"},{"type":"post","id":"讨厌python的n个理由","title":"讨厌Python的N个理由","url":"/blog/讨厌python的n个理由/","content":"谁喜欢 Python 啊，反正我不喜欢。\n\n缩进噩梦\n如果要说 Python 给一个普通人（不是语言律师或者数学家）带来的最大印象是什么，我想缩进决定代码块绝对是其中之一。\n喜欢 Python 的人会觉得这种缩进非常的方便，少敲一个大括号，还不用在文件末尾看到 }}}}} 这样的经典 lisp 笑话（？）。但是稍微深入一点就会意识到这种缩进方式给 Python 带来了很大的先天缺陷。\nPython 的缩进在发明之出或许是友好的，毕竟它强迫初学者写出“能看”的代码，便于老手查看，而无须跑 formatter。（并且据 Python 发明者所说，当年的格式化工具并没有现在好用）。但是现在的 formatter 技术已经非常成熟，为 JavaScript 设计的格式化工具随便就能说出五六种。缩进给 Python 带来的益处已经消失不见了，反而带来无数的问题。\n最简单的，编辑是否方便的问题。别人写好的 Python 代码片段难以直接复制粘贴到编辑器中，你得先调好缩进。这也反应在现代编辑器中，想象你有这段代码：\n\n\n\nconst a = 1;\nif (foo()) {\n  a = 2;\n  bar();\n}\nother();\n\n\na = 1\nif foo():\n  a = 2\n  bar()\n\nother()\n\n\n\n在 VSCode 中你想要上下移动 a = 2 非常方便，只需要 Alt + ↑ / ↓ 就可以了。因为作用域是被括号明确标出的，编辑器很容易知道当 a = 2 移下两行的时候进入了另一个块中，可以自动调整这一行的缩进。但 Python 就不行，编辑器根本就看不出你是否打算让这一行进入另一个块中。这导致编码的时候你必须和缩进斗智斗勇，而不是你尽管写，由编辑器帮你跑 formatter，回车一下就能看到美观的代码。\n其次，这直接导致 Python 先天性地难以应用函数式思想。众所周知，Python 的 lambda 函数几乎是个废物，你必须控制 lambda 函数在一行以内\nlambda x : x + 1\n很显然，抛开 Python 设计者看不起 lambda 函数不谈，python 缩进决定层次的思想就直接重创了 lambda 函数，因为 lambda 函数很难决定缩进位置。1 而 lambda 函数在函数式编程范式的美观性上极其重要，python 在这里直接缺一个\n举个例子，工程上很容易遇到类似这样的例子：需要把一个数组 filter 几下，map 几下，得到新的数组，举个例子\nconst data = dataRaw\n  .filter((x) => x)\n  .map((x) => {\n    // balabala...\n    // something...\n    return y;\n  });\n这在 python 中必须要费力定义一个映射函数来用，因为你根本就没法在 lambda 函数里写多行！\n这在静态语言中都没这么致命，起码，要在外面定义一个函数，你得定义 arguments 的类型和 return 的类型，这样你起码知道一个函数传入了啥，返回啥\n而 lambda 函数巧妙避免了这个问题，因为调用链上每一个函数的类型都是可以肉眼看出的，并且肉眼看不出还可以自动推导。\n但是在 Python 里你必须得把这个函数拆出去，相当于分离了背景和逻辑。这个坑已经在 js 里犯过了，在 js 早期的“面向对象”中 this 完全就是梦魇，你根本就不知道 this 是个啥；在 Python 中这个问题以另一种方式体现，这些“本来没有被拆分的必要但是被拆分”的函数你难以肉眼瞪出参数和返回值。它不仅平添了代码的复杂性，让代码变得更丑陋，而且还更容易出错。\n糟糕的设计\nDigg’s v4 launch: an optimism born of necessity. | Irrational Exuberance 讲述了当年曾可以与 Reddit 匹敌的科技网站 Digg，因为 Python 默认参数的特性导致了一个内存泄露问题，让 Digg 的用户迅速流失，最终在一年以后被 Beatworks 以 50 万美金的价格收购的故事。\n这个特性几乎可以说是 Python 独家。只要看下面的 REPL 过程，你就知道这是什么了：\n>>> def push1(arr = []):\n...     arr.append(1)\n...     return arr\n...\n>>> push1()\n[1]\n>>> push1()\n[1, 1]\n>>> push1()\n[1, 1, 1]\n>>> push1()\n[1, 1, 1, 1]\nPython 选择了一种很蠢的默认传参方式，默认参数始终共用同一个对象。这在别的语言看来几乎是匪夷所思的，只有 Python 必须要写出这样的傻 x 代码来传入默认参数：\ndef push1(arr=None):\n  if arr is None:\n    arr = []\n  ...\n繁琐又愚蠢，完全不符合 DWIM 的思想。\n这可能只是 Python 糟糕设计的冰山一角。在我看来 Python 当得上最死板最没有表现力的流行语言的称号。（也可能要和 Java 竞争，不过我不写 Java，谁知道呢）。实际上，Python 整体就体现出一种思维，程序员不值钱，不需要有自己的思想，只需要把思路翻译成 Python 代码让计算机跑就好了。可能这种特性让 Python 作为教学语言会很合适，但是真的不适合成为最流行的语言之一。\nPython 的风格死板又诡异。既试图融入一些面向对象的元素，又摆脱不了过程式的影子，还想融一点函数式的元素。可以从简单的 len() 函数就能看出来，长度应该是某个对象的属性，但是 Python 选择用一个全局函数（What the fuck？）len 去处理。但是 Python 又确实提供了面向对象风格的类。Python 提供了函数式的 map ，却对 lambda 表达式嗤之以鼻。这些都让 Python 代码充满了一种诡异的不协调感。\n有点极端的反面教材是 Ruby，以自由浪漫闻名的同样的动态语言。Rails 信条如是说：\n\n是 Ruby 造就了 Rails，所以第一条信条便是从创造 Ruby 的核心理念所提炼出來。\n早期 Ruby 的极端邪说就是把程序员的幸福度放到第一位。还把追求幸福置于驱动编程语言与生态圈前进的考量之上。\n然而 Python 可能对于“用一种方法，最好只有一种方法来完成一件事”而感到自豪，而 Ruby 则喜欢自身表现力与巧妙。Java 是饱受软件工程师的强力推崇，Ruby 则在欢迎工具里就附上了自尽的绳子。Smalltalk 专注于消息传递的纯粹性，Ruby 则累积关键字和臃肿的语法构造。\n\n举个例子，这是一段来自 discourse/discourse 的 Ruby 代码。它要做的就是定义一个 TrashMessage 的过程。\nclass TrashMessage\n  include Service::Base\n\n  params do\n    attribute :message_id, :integer\n    attribute :channel_id, :integer\n\n    validates :message_id, presence: true\n    validates :channel_id, presence: true\n  end\n\n  model :message\n  policy :invalid_access\n\n  transaction do\n    step :trash_message\n    step :destroy_notifications\n    step :update_last_message_ids\n    step :update_tracking_state\n    step :update_thread_reply_cache\n  end\n\n  step :publish_events\n\n  private\n\n  def fetch_message(params:)\n    ...\nend\nRuby 的放纵允许程序员定义出向上面这样离经叛道的写法，直接把步骤写成任务列表的格式，然后在按照列表里定义的名字编写每个小任务的函数。这使得 Ruby 程序非常富有表现力，可能看上去非常天马行空。\n相比而言，Python 的语法就死板得完全不懂变通。\n糟糕的……大儒\n\n“入关之后，自有大儒为我辩经”\n\n我还是很尊重真心的语言爱好者的，但是当谈论起一些流行语言——不只是 Python 的时候，总是有一种自有大儒为我辩经的既视感\nPython 采用缩进？大儒们会说这是深思熟虑的选择，非常方便，大括号多么无用（哪怕 Python 之父后来自己承认这是一个败笔）Python 有意忽视 lambda 函数？大儒们会说又不是不能定义一个带名字的函数。反正大儒们终会找到理由。他们还有终极武器：Python 那么多库本身就说明搞底层的大佬接受这个语言的逻辑！\n（那还有银行在用 1960s 的 COBOL 呢，怎么，是因为 COBOL 设计得让它们爱不释手吗？）\n或者说大众语言本身是一种不好的话语权。如果大家都在用，那怕这语言设计得跟屎一样，你也得硬吃。典型的例子就是 Java 以后的语言花了 30 年的时间弥补 Java 的各种不足。典型的例子就是现代前端框架已经演变了好几代了还有人抱着 PHP 大喊 PHP 是世界上最好的语言，转手就写出一堆 SQL 注入的程序。\n脚注\n\n\n实际上这是可以解决的，经典函数式语言 Haskell 就是使用的空白字符缩进。但是 Haskell 在多行 lambda 函数上也同样有游标卡尺的问题，而且 Haskell 支持显式使用大括号缩进，也可以用更加函数式的方式规避这个问题。 ↩\n\n\n"},{"type":"post","id":"类型体操入门slice","title":"类型体操入门：Slice","url":"/blog/类型体操入门slice/","content":"Extreme 难度的 Slice 过关了，终于可以自称类型体操入门了（喜）\n\n题面\ntype-challenges/questions/00216-extreme-slice/README.md at main · type-challenges/type-challenges\nSlice  \n\nby Anthony Fu @antfu\n\n\nImplement the JavaScript Array.slice function in the type system. Slice<Arr, Start, End> takes the three argument. The output should be a subarray of Arr from index Start to End. Indexes with negative numbers should be counted from reversely.\nFor example\ntype Arr = [1, 2, 3, 4, 5];\ntype Result = Slice<Arr, 2, 4>; // expected to be [3, 4]\n\n\n \n\n\n\n思路\n看上去很简单？这真的是 Extreme 难度吗？\n难度主要在数字的转换上。TypeScript 不支持直接做类型的加减法，所以需要体操一下获得 Add1<N> 和 MinusXY<X, Y>\ntype Push1<X extends any[]> = [...X, 1];\ntype ArrFrom<N, A extends any[] = []> = A[\"length\"] extends N\n  ? A\n  : ArrFrom<N, Push1<A>>;\ntype Add1<N> = [...ArrFrom<N>, 1][\"length\"];\ntype Minus1<N> = ArrFrom<N> extends [infer _1, ...infer Rest]\n  ? Rest[\"length\"]\n  : never;\ntype MinusXY<X, Y> = Y extends 0 ? X : MinusXY<Minus1<X>, Minus1<Y>>;\ntype Abs<X extends number> = `${X}` extends `-${infer R extends number}`\n  ? R\n  : X;\ntype IsNeg<X extends number> = Abs<X> extends X ? false : true;\n剩下的就很简单了\ntype RemoveFirstN<N, Arr extends any[], Removed = 0> = N extends Removed\n  ? Arr\n  : Arr extends [infer _1, ...infer Rest extends any[]]\n  ? RemoveFirstN<N, Rest, Add1<Removed>>\n  : [];\ntype KeepFirstN<\n  N,\n  Arr extends any[],\n  Ret extends any[] = [],\n  Kept = 0\n> = Kept extends N\n  ? Ret\n  : Arr extends [infer _1, ...infer Rest extends any[]]\n  ? KeepFirstN<N, Rest, [...Ret, _1], Add1<Kept>>\n  : [];\ntype SliceNoNeg<Arr extends any[], From, To> = RemoveFirstN<\n  From,\n  Arr\n> extends infer Res extends any[]\n  ? KeepFirstN<To, Res, [], From>\n  : never;\ntype ConvertToPositive<N, X extends number> = IsNeg<X> extends true\n  ? MinusXY<N, Abs<X>>\n  : X;\ntype Slice<\n  Arr extends any[],\n  From extends number = 0,\n  To extends number = Arr[\"length\"]\n> = SliceNoNeg<\n  Arr,\n  ConvertToPositive<Arr[\"length\"], From>,\n  ConvertToPositive<Arr[\"length\"], To>\n>;\n所以\n这类型体操纯属在折磨自己了吧"},{"type":"post","id":"package-manager-the-history","title":"Package Manager: The History","url":"/blog/package-manager-the-history/","content":"This blog post was inspired by my classmate who encountered pip’s dependencies hell when configuring machine learning python code. Yeah, for my academics-immersed amateur of industy, environment configuration and package managers are very unfamiliar things. It’s not strange to crash into hell.\n\nSometimes it’s simply impossible to find a combination of package versions that do not conflict. Welcome to dependency hell.\n\n\nThe era without package managers\nThere was no so-called package manager for the early era programming languages. This can be seen from C and/or C++ (although for C family it is largely because C family programmers like to reinvent the wheel, squeezing out the best performance). In this primitive period if you need to include something you must either use compiled dynamic link libraries or directly copy-paste the code into your own source code dir.\nThis method is obviously flawed. It is difficult to manage the versions of dependencies, lacking security updates, and the installation is cumbersome and prone to errors, etc. For this reason, package managers came into being.\nEarly era package managers\nEarly package managers resolve dependencies and install packages in a certain location. This is based on the usual virtue of saving disk space. If two dependencies A and B both depend on a C, then we can obviously install only one copy of C for both A and B to use. Furthermore, if I have two projects that both depend on A, then putting A directly in the public directory e.g., python’s ~/.local/lib/python3.12/site-packages is also a good choice.\nThis has been the advantage of Linux for a long time. Due to historical reasons, Windows has long lacked a system built-in package manager and a unified installation location. Although it is still possible to reuse common libraries with dll, it is normaly time-consuming and laborious. Therefore, Windows software tends to prepare all the dlls it needs in its own directory, or even bundle them directly in the exe files. This makes Windows programs often larger than Linux programs.\nBut the virtue leads to a big problems, the conflicting dependencies.\nThis dependency issue arises when several packages have dependencies on the same shared packages or libraries, but they depend on different and incompatible versions of the shared packages. Solving the dependencies for one software may break the compatibility of another in a similar fashion to whack-a-mole. If app1 depends on libfoo 1.2, and app2 depends on libfoo 1.3, and different versions of libfoo cannot be simultaneously installed, then app1 and app2 cannot simultaneously be used. 1\nUnfortunately, many early era package managers simply could not install different versions of a library at the same time. What’s even more terrifying is that pip, package manager of python the most popular language nowadays is among them.\nIn order to solve this problem, the package manager of programming languages has roughly derived several approaches. Here we introduce nodejs, docker and nix.\nPackage management of Node.js\nIn order to solve the coflicting dependencies hell, npm, the default package manager of nodejs, chose to placed dependencies in a fixed folder node_modules of the project from the beginning. Each dependency has its own node_modules, so that dependencies do not interfere with each other.\nFor example if we want to add two dependencies A and B, but A depends to C 1.0.0, and B depends to C 2.0.0. Then the project’s node_modules will probably look like this:\n/node_modules\n/node_modules/A\n/node_modules/B\n/node_modules/...\n\n/node_modules/A/node_modules/C@1.0.0\n/node_modules/A/node_modules/... (other dependencies)\n/node_modules/B/node_modules/C@2.0.0\n/node_modules/B/node_modules/...\ngraph TD\nProject --> nm1[node_modules]\nnm1 --> A\nnm1 --> B\nA --> nmA[node_modules]\nB --> nmB[node_modules]\nnmA --> c1[C 1.0.0]\nnmB --> c2[C 2.0.0]\nThis effectively solves the problem of conflicts between sub-dependencies.\nHowever, npm’s approach also causes other problems.2 One problem comes from a design flaw in the file system. Some systems, such as older versions of Windows, cannot handle path names longer than 255 characters. However, a path like package_name/node_modules often reaches 20 characters or more, causing problems with less than 10 levels of recursive dependencies. npm’s approach also leads to a huge number of duplicate dependencies in the deep recursive dependency tree that people joke that node_modules is heavier than a black hole.\n\nTo solve these problems, the currently popular nodejs package manager, pnpm, uses some clever ideas. pnpm will install the package locally shared, defaultly in ~/.pnpm-store. Instead of storing complete dependencies in each project’s node_modules, it will create symbolic links (symlinks) point to shared dependencies in the global store. At the same time, pnpm will flatten the dependencies, so dependency chains like A -> B -> C -> D will be flattened into node_modules in the root directory.\nnpm:\nnode_modules/A/node_modules/B/node_modules/C/node_modules/D/...\n\npnpm:\nnode_modues/A\nnode_modues/B\nnode_modues/C\nnode_modues/D\nAlso, pnpm use a strict dependency tree structure pnpm-lock.yaml to ensure that each package can only access its declared direct dependencies to prevent accidental access. (i.e, You didn’t directly include D then you won’t access D by A -> B -> C -> D chain)\nThrough these technologies, pnpm saves disk space and solves the problem of dependency hell to a large extent.\nVirtual Environment of Python\nLanguages ​​like Python choose to use virtual environments (venv) instead of improving pip’s dependencies resolution architecture.\n\nThe venv module supports creating lightweight “virtual environments”, each with their own independent set of Python packages installed in their site directories. A virtual environment is created on top of an existing Python installation, known as the virtual environment’s “base” Python, and may optionally be isolated from the packages in the base environment, so only those explicitly installed in the virtual environment are available. 3\n\nIn short, venv creates an independent, virtual runtime environment instead of using the common site-packages. In this way, projects using different virtual environments will never interfere with each other, solving the dependency conflict problem between different projects.\nUnfortunately, python venv does not solve the dependency conflicts between sub-dependencies. Usually, pythoneans need to manually solve dependency problems, such as boldly adjusting dependency versions, directly forking confilcted dependencies, or nesting another venv in some venv.\nDocker, the last solution\nInstead of working hard on algorithmic improvements on the package manager, Docker took a different approach. Docker packages the application into a container and runs it in a Linux virtual environment. Programs inside and outside the container can communicate with each other like ordinary programs through methods such as IPC communication and sockets.\nPackaging an application into a container will involves not only the application itself, but all dependencies into a portable image. We don’t need to worry about any dependency conflicts at all, because the inside of the docker container is more like an independent “lightweight virtual machine”, and the docker containers will not interfere with each other in any way other than the pre-planned interface. Dependency handling is something that the publisher of the docker image needs to worry about, and as a user, you can use the image just after getting it, becaues everything in it is already packaged.\nOf course, Docker also has huge drawbacks. The most obvious one is its huge space and resource usage, which is although obviously much smaller than installing a real virtual machine, but larger than a well-designed package manager installation. but hard disk space is becoming less valuable nowadays. If Docker can save 8 hours of painful installation and conflicted dependencies resolving process, what does it matter if there are just 500MB larger of space?\nFurther: Nix\nNix is a purely functional package manager. This means that it treats packages like values in purely functional programming languages such as Haskell — they are built by functions that don’t have side-effects, and they never change after they have been built. Nix stores packages in the Nix store, usually the directory /nix/store, where each package has its own unique subdirectory such as /nix/store/b6gvzjyb2pg0kjfwrjmg1vfhh54ad73z-firefox-33.1/ where b6gvzjyb2pg0... is a unique identifier for the package that captures all its dependencies (it’s a cryptographic hash of the package’s build dependency graph). This enables many powerful features.\n\nYou can have multiple versions or variants of a package installed at the same time. This is especially important when different applications have dependencies on different versions of the same package — it prevents the “DLL hell”. Because of the hashing scheme, different versions of a package end up in different paths in the Nix store, so they don’t interfere with each other.\nAn important consequence is that operations like upgrading or uninstalling an application cannot break other applications, since these operations never “destructively” update or delete files that are used by other packages.\n\nHow Nix Works | Nix & NixOS\n\nThis blog post is licensed under CC-BY-SA 4.0. Sources are cited throughout the footnotes.\n脚注\n\n\nDependency hell - Wikipedia ↩\n\n\nThese problems are generally solved in the new version (≥7) of npm ↩\n\n\nvenv — Creation of virtual environments — Python 3.13.0 documentation ↩\n\n\n"},{"type":"post","id":"random-sentence-generator-and-wasm","title":"随机句子生成器与一场有趣的WASM尝试","url":"/blog/random-sentence-generator-and-wasm/","content":"一时兴起想写一个随机句子生成器。正巧在学上下文无关语言 (Context-Free Language, CFL)，意识到句子的结构很大程度上是一个上下文无关语法。查阅 X-bar 理论得到也确实类似如此。\n同时正好在学 Rust，所以试了一下拿 Rust 编写这个生成器，并编译到 WebAssembly (WASM)。效果很成功！\n\nContext Free Language\nA context-free grammar is a notation for describing languages.\nIt is more powerful than finite automata or RE’s, but still cannot define all possible languages.\nUseful for nested structures, e.g., parentheses in programming languages. But it also works for natural language.\nThe basic idea of CFL to use “variables” to stand for sets of strings (i.e., languages). These variables are defined recursively, in terms of one another. The recursive rules (“productions”) involve only concatenation.\nLets start with a example. Consider these productions:\n\nS \\to 01\nS \\to 0S1\n\nIt means 01 is in the language. And recursively, if w is in the language, then so is 0w1.\nDefinations:\n\nTerminals: symbols of the alphabet of the language being defined.\nVariables (nonterminals): a finite set of other symbols, each of which represents a language.\nStart symbol: the variable whose language is the one being defined.\n\nA production has the form \\text{variable (head)} \\to \\text{string of variables and terminals (body)}. Then we derive strings in the language of a CFG by starting with the start symbol, and repeatedly replacing some variable A by the body of one of its productions.\nFor example,\nS \\to 0S1 \\to 00S11 \\to 000S111 \\to 00001111\nWe are not going to introduce CFL in detail, so let’s talk about how does it related to natural language. Let us consider a classic subject-verb-object structure (SVO), where a sentence consists of a subject, a verb, and an object in that order.\n\nS_\\text{sentence} \\to SVO\nS \\to 我\nV \\to 打\nO \\to 宿傩\n\nS_\\text{sentence} \\to SVO \\to 我VO \\to 我打O \\to 我打宿傩\nCFG of natural language grammar\n现在继续考虑自然语言。我们只考虑最简单的句子结构，不考虑时态、时体的话，可以构造这样一个 CFG\n\nS \\to N_PV_P \\qquad (句子 → 名词短语 + 动词短语)\nN_P \\to N \\qquad (纯名词)\nN_P \\to A_{adj}N \\qquad (形容词 + 名词)\nV_P \\to V \\qquad\nV_P \\to A_{adv}V \\qquad\nV \\to V_{int} \\qquad (不及物动词 e.g. 上班)\nV \\to V_{tra}N_P \\qquad (及物动词 e.g. 打宿傩)\nV \\to V_{dit}N_PN_P \\qquad (双宾语及物动词 e.g. 给它一本书)\nA_{adj} \\to ...\nN \\to ...\nV_{int} \\to ...\n\n现在考虑一个从句也可以修饰一个名词，例如 “打宿傩的我”，因此又可以构造回环\n\nN_p \\to V_P\\text{的}N\n\nImplement by Rust\n现在已经有了 CFG，需要考虑的是如何实现它。显而易见的，我们可以用一个 enum 存放可能出现的 Variables，并用 match 匹配 terminals. 因此我们能写出类似这样的代码：\nenum CFGSymbol {\n    Sentence,\n    NP,\n    VP,\n    N,\n    VInt,\n    VTra,\n    VDit,\n    ADJ,\n    ADV,\n}\n\nfn expand_str(symbol: &CFGSymbol) -> Option<&'static [&'static str]> {\n    Some(match symbol {\n        N => &[\"小豆泥\", \"薯条\", \"葡萄\", \"咖啡\"],\n        VInt => &[\"上班\", \"发疯\"],\n        VTra => &[\"吃\", \"摸\"],\n        VDit => &[\"给\", \"送给\"],\n        ADJ => &[\"可爱的\", \"好吃的\"],\n        ADV => &[\"超大声地\", \"超小声地\"],\n        _ => return None,\n    })\n}\n关于 Rules，如果打算用常量存储，就不能用 Vec。但没关系，我们可以用固定的数组配合元组描述一个规则。可以让\nS \\to A_1A_2A_3...A_n\n写作\n(S, &[A1, A2, /* ... */, An])\n于是我们可以写出 CFG 规则\nconst CFG_RULES: &[(CFGSymbol, &[CFGSymbol])] = &[\n    (Sentence, &[NP, VP]),\n    (NP, &[Ns]),\n    (Ns, &[N]),\n    (Ns, &[ADJ, N]),\n    (Ns, &[VP, CharDe, N]),\n    (Ns, &[ADJ, N]),\n    (VP, &[Vs]),\n    (VP, &[ADV, Vs]),\n    (Vs, &[VInts]),\n    (Vs, &[VTras]),\n    (Vs, &[VDits]),\n    (VInts, &[VInt]),\n    (VTras, &[VTra, NP]),\n    (VDits, &[VDitts, NP, NP]),\n];\n剩下的工作就简单了：从规则一条条推导，随机选择一条推导规则继续，直到所有 Symbol 都是 terminal 就生成了一条随机的句子。\n\n完整代码（没必要看的）\nextern crate rand;\nextern crate wasm_bindgen;\nuse rand::seq::SliceRandom;\nuse wasm_bindgen::prelude::*;\n\n#[derive(std::fmt::Debug, PartialEq, Eq)]\nenum CFGSymbol {\n    /// 句子\n    Sentence,\n    /// 名词短语\n    NP,\n    Ns,\n    /// noun. 名词\n    N,\n    /// 动词短语\n    VP,\n    Vs,\n    /// adj. 形容词\n    ADJ,\n    /// Transitive （单宾语）及物动词\n    VTra,\n    /// 单宾语及物动词，后置\n    VTra2,\n    VTras,\n    /// Intransitive 不及物动词\n    VInt,\n    VInts,\n    /// Ditransitive 双宾语及物\n    VDit,\n    VDitts,\n    VDits,\n    /// adv. 副词\n    ADV,\n    // 把/被\n    CharBaBei,\n    // 的\n    CharDe,\n}\nuse crate::CFGSymbol::*;\n\n// S -> SS, + 概率权重\nconst CFG_RULES: &[(CFGSymbol, &[CFGSymbol], i32)] = &[\n    (Sentence, &[NP, VP], 5),                      // S V O 结构\n    (Sentence, &[NP, CharBaBei, NP, VTra2], 1),    // noun. 把/被 noun. verb-tra.\n    (Sentence, &[NP, CharBaBei, NP, VDit, NP], 1), // noun. 把/被 noun. verb-tra.\n    (NP, &[Ns], 3),\n    (Ns, &[N], 6),\n    (Ns, &[ADJ, N], 3),\n    (Ns, &[VP, CharDe, N], 1),\n    (Ns, &[ADJ, N], 1),\n    (VP, &[ADV, Vs], 1),\n    (VP, &[Vs], 3),\n    (Vs, &[VInts], 1),\n    (Vs, &[VTras], 1),\n    (Vs, &[VDits], 1),\n    (VInts, &[VInt], 1),\n    (VTras, &[VTra, NP], 1),\n    (VDits, &[VDitts, NP], 1),\n    (VDitts, &[VDit, NP], 1),\n];\n\nfn expand_str(symbol: &CFGSymbol) -> Option<&'static [&'static str]> {\n    Some(match symbol {\n        // nouns\n        N => &[\n            \"小豆泥\",\n            \"猫\",\n            \"纸\",\n            \"鬼\",\n            \"薯条\",\n            \"KFC\",\n            \"麦当劳\",\n            \"霸王龙\",\n            \"饮料\",\n            \"皇上\",\n            \"甜点\",\n            \"毛球\",\n            \"狸花\",\n            \"葡萄\",\n            \"咖啡\",\n            \"茶\",\n            \"兔子\",\n            \"鳄鱼\",\n            \"小黑猫\",\n            \"undefined\",\n            \"错误\",\n            \"芝士\",\n            \"自助餐\",\n            \"蛋挞\",\n            \"Windows11\",\n        ],\n        VTra => &[\n            \"打\",\n            \"吃\",\n            \"啃\",\n            \"摸\",\n            \"揉\",\n            \"喝\",\n            \"买\",\n            \"是\",\n            \"吃掉了\",\n            \"拿走了\",\n        ],\n        VTra2 => &[\"吃掉了\", \"拿走了\"],\n        VInt => &[\n            \"喵喵叫\",\n            \"睡觉\",\n            \"做深蹲\",\n            \"写作业\",\n            \"学习\",\n            \"画画\",\n            \"emo\",\n            \"吃饭\",\n            \"蹦蹦跳跳\",\n            \"摸鱼\",\n            \"看电视\",\n            \"ypt启动\",\n            \"关闭ypt\",\n            \"打maimai\",\n            \"写代码\",\n            \"不知道在干什么\",\n            \"思考中\",\n            \"呜呜呜\",\n            \"刷TL\",\n            \"上班\",\n            \"工作\",\n            \"发疯\",\n            \"正在更新\",\n            \"看同人\",\n        ],\n        VDit => &[\"给\", \"送给\"],\n        ADJ => &[\n            \"可爱的\",\n            \"好吃的\",\n            \"无聊的\",\n            \"开心的\",\n            \"美味的\",\n            \"刚重生的\",\n            \"你主页上的\",\n            \"谁的\",\n            \"终末时的\",\n            \"无限的\",\n            \"超厉害的\",\n        ],\n        ADV => &[\n            \"悄悄\",\n            \"静静\",\n            \"想\",\n            \"轻轻地\",\n            \"不想\",\n            \"正在\",\n            \"在\",\n            \"在你身后\",\n            \"几乎处处\",\n            \"随时\",\n            \"超大声地\",\n            \"超小声地\",\n            \"又开始\",\n            \"重新\",\n        ],\n        CharBaBei => &[\"把\", \"被\"],\n        CharDe => &[\"的\"],\n        _ => return None,\n    })\n}\n\nconst TO_STR_POSSIBILITY: f64 = 0.5;\n\nfn generate(ctx: &mut String, symbol: &CFGSymbol) -> String {\n    ctx.push_str(&format!(\"[{:?} \", symbol));\n\n    let mut symbol_rules = Vec::<&[CFGSymbol]>::new();\n\n    for (sym, rule, weight) in CFG_RULES.iter() {\n        for _ in 0..if sym == symbol { *weight } else { 0 } {\n            symbol_rules.push(rule);\n        }\n    }\n\n    let force_expand = symbol_rules.len() == 0;\n    let res = match expand_str(symbol) {\n        Some(strs) if force_expand || rand::random::<f64>() < TO_STR_POSSIBILITY => {\n            let res = strs\n                .choose(&mut rand::thread_rng())\n                .unwrap_or_else(|| &\"\")\n                .to_string();\n            ctx.push_str(&format!(\"{}\", res));\n            res\n        }\n        Some(_) | None => {\n            if let Some(chosen) = symbol_rules.choose(&mut rand::thread_rng()) {\n                chosen\n                    .iter()\n                    .map(|sym| generate(ctx, sym))\n                    .collect::<Vec<String>>()\n                    .join(\"\")\n            } else {\n                \"\".to_string()\n            }\n        }\n    };\n    ctx.push_str(&format!(\"] \"));\n    res\n}\n\n#[wasm_bindgen]\npub struct SentenceRes {\n    ctx: String,\n    res: String,\n}\n\n#[wasm_bindgen]\nimpl SentenceRes {\n    #[wasm_bindgen(getter)]\n    pub fn ctx(&self) -> String {\n        self.ctx.clone()\n    }\n    #[wasm_bindgen(getter)]\n    pub fn res(&self) -> String {\n        self.res.clone()\n    }\n}\n\n#[wasm_bindgen]\npub fn generate_sentence() -> SentenceRes {\n    let mut ctx = String::new();\n    let res = generate(&mut ctx, &Sentence);\n    SentenceRes { ctx, res }\n}\n\nWASM\n上述的 Rust 代码依照 MDN web docs 的教程编译成了 WASM，可以在下面按按钮体验一下随机句子生成器。\n\n  重新生成\n  \n    [Sentence [NP [Ns [N 芝士] ] ] [VP [Vs [VInts [VInt 喵喵叫] ] ] ] ]\n  \n  芝士喵喵叫\n  \n\n\nCopyright\n上图的 Syntax Generator 代码来自 https://github.com/mshang/syntree ，许可证如下\nCopyright (C) 2011 by Miles Shang <mail@mshang.ca>\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n\nThis software uses the following libraries:\n\nbase64.js\n\tCopyright (C) 1999 Masanao Izumo <iz@onicos.co.jp>\n\tVersion: 1.0\n\tLastModified: Dec 25 1999\n\tThis library is free.  You can redistribute it and/or modify it.\n\ncanvas2image.js\n\tCanvas2Image v0.1\n\tCopyright (c) 2008 Jacob Seidelin, jseidelin@nihilogic.dk\n\tMIT License [http://www.opensource.org/licenses/mit-license.php]\n\njQuery v1.7.1\n\tCopyright (c) 2011 John Resig, http://jquery.com/\n\tMIT license [jquery.org/license]\n\njQuery UI v1.8.18\n\tCopyright (c) 2011 Paul Bakaus, http://jqueryui.com/\n\tMIT license [jquery.org/license]\n\n\n\n"},{"type":"post","id":"so-simple","title":"一晚上搓出的 So Simple 博客主题","url":"/blog/so-simple/","content":"花了几个小时写下了 So Simple.\n\n这是一个致力于“尽可能少写 CSS”的主题。实际上也确实，整个主题几乎全部是裸的 HTML。排列从上到下，没有什么值得插入的元素，就像在读报纸一样。\n这个主题是返璞归真的一次尝试。希望它能让我满意。"},{"type":"post","id":"reindex-misskey","title":"为 Misskey 开启 Meilisearch 后，重新索引过去的帖子","url":"/blog/reindex-misskey/","content":"一篇简短的笔记，为 Misskey 开启 Meilisearch 后，重新索引过去的帖子。\n\n首先编写这样一个 SQL 文件\nSELECT json_agg(row_to_json(n.*)) FROM (\n      SELECT \"id\", \"userId\", \"channelId\", \"cw\", \"text\", \"tags\"\n      FROM \"note\"\n      WHERE (\"note\".\"visibility\" = 'public' OR \"note\".\"visibility\" = 'home') AND\n      (\"note\".\"text\" IS NOT NULL) AND\n      (\"note\".\"uri\" IS NULL)\n      ORDER BY id desc\n) n\n我们不妨保存它为 get_notes.sql\n这个 SQL 的意思很显然，就是从帖子表中找到 public 或 home 可见性的本地帖子 (uri is null) 并输出成 JSON\n然后执行它，得到一个 notes.json\npsql -d {your_db_name} -t -f get_notes.sql > notes.json\n然后创建一个 send_notes.mjs。最前方的 config 请用你的 misskey 的 .config/default.yml 内关于 Meilisearch 的部分替换。\nimport fs from \"fs\";\n\nconst config = {\n  ms_url: \"http://127.0.0.1:7700\",\n  api_key: \"YOUR_API_KEY\",\n  index: \"YOUR_INDEX\",\n};\n\nconst headers = {\n  \"Content-Type\": \"application/json\",\n  Authorization: `Bearer ${config.api_key}`,\n};\n\n/** @typedef {{id: string, userId: string, channelId: string, cw: string | null, text: string, tags: string[]}} {Note} */\n\n/** @type {Note[]} */\nconst notes = JSON.parse(fs.readFileSync(\"notes.json\"));\n\n/**\n * @see https://github.com/misskey-dev/misskey/blob/4b295088fd6b4bead05087537415b10419eee78f/packages/backend/src/misc/id/aid.ts#L34\n */\nfunction parseAid(id) {\n  const TIME2000 = 946684800000;\n  const time = parseInt(id.slice(0, 8), 36) + TIME2000;\n  return time;\n}\n\nfor (const note of notes) {\n  note.createdAt = parseAid(note.id);\n  note.userHost = null;\n}\n\nconsole.log(\"Reindexing\", notes.length, \"notes\");\n\nfetch(\n  config.ms_url + `/indexes/${config.index}---notes/documents?primaryKey=id`,\n  {\n    method: \"POST\",\n    headers,\n    body: JSON.stringify(notes),\n  }\n)\n  .then((res) => res.text())\n  .then((text) => {\n    console.log(text);\n  });\n执行 node send_note.mjs, 如果成功把帖子送给了 Meilisearch 进行索引，我们应该能看到像这样的输出内容：\n{\n  \"taskUid\": 9241,\n  \"indexUid\": \"shonk_social---notes\",\n  \"status\": \"enqueued\",\n  \"type\": \"documentAdditionOrUpdate\",\n  \"enqueuedAt\": \"2024-09-07T06:31:44.177026811Z\"\n}\n如果要查看索引进度，记下 taskUid。使用像这样命令就可以查看索引进度了：\ncurl -s 'http://localhost:7700/tasks/{taskUid}' -H \"Authorization: Bearer {your_api_key}\" | jq ."},{"type":"post","id":"sayonara-firefish","title":"再见 Firefish (Firefish 迁移 Sharkey 指北)","url":"/blog/sayonara-firefish/","content":"我是去年的 11 月知道的 Firefish。它是我当时找到的最美丽的联邦宇宙软件，相比于死板的 Mastodon，过于倾向于日语又太娱乐的 Misskey，它同时兼具美观大方与功能丰富。管理员可以自由配置最大帖子长度，Nodejs 的后端也让它比 Ruby on Rails 编写的 Mastodon 对性能要求更低。我欣然安装上了它，并把它作为自己的主要联邦宇宙软件。\n可惜，当时我还不知道它的状态已经岌岌可危。就在当时，原有的主要贡献者大多已经离开，panos 和 namekuji 离开了这摊烂摊子开启了新项目 Catodon。数个月后，Firefish 的 maintainer Kainoa 就直接撒手不管，在没有事先告知的情况下将 maintainer 更改给 naskya。naskya 非常负责且具有热爱，在伊的代理下 Firefish 回光返照了一段时间 —— 我也是那个时候尝试了为 Firefish 进行贡献。\n可惜 maintainer 的名头为伊带来了巨大的压力与恶心的网络骚扰者。 naskya 的身体和精神状态都无法负担这样的项目，不到一年之后，Firefish 再次被抛弃。这次，大约再也没人能救 Firefish 了。\n\nGoodbye Firefish\n我很难不把 Kainoa 的行为称为一种残忍，他将一团糟的 Firefish 项目丢给毫无准备的 naskya ，此时伊甚至还没有过什么编程经验。但 naskya 的确是一个非常负责的人。伊接手 Firefish 的时候就知道自己的身体和精神状态糟糕，但还是努力维护了 Firefish 一段时间。\nnaskya 留给 Firefish 最后的体面。 伊维护了 Firefish 代码库中的 downgrade.sql （/docs/downgrade.sql），这份文件提供了 Firefish 从当前版本降级到 Firefish 1.05 rc-1 的能力，也为迁移提供了可能。没有这份文件，目前运营 Firefish 的服务器很可能都会再也无法迁移到其他版本。\n这篇笔记也将告诉你如何用这份文件迁移你的 Firefish 到 Sharkey.\nSharkey 是基于 Misskey 的另一个 Fork，其功能与 Firefish 相似。\n本笔记适用于 Firefish 1.05 （即 v20240206 ）以上。如果您的 Firefish 版本低于 1.05，可以直接按照其他软件的官方说明迁移。您完全不升级的吗？那还迁移什么呢？\n准备工作\n在接下来的操作前，请务必备份你的数据库。 迁移前请务必备份你的数据库，因为这是一个非常非常危险的操作，一旦失误会弄坏你的数据库。\n请先在本地测试环境中按该笔记进行操作，再在生产环境操作。 原因同上。\n本教程基于 Manual 安装而非 Docker 安装，如果你使用的是 Docker 安装，关于数据库的操作很可能有区别。抱歉我无法提供这方面的帮助，请自行将下面的命令翻译为 Docker 上的数据库操作。\n备份\n如果你要正式开始迁移工作，请务必在备份前停止 Firefish。 但如果你只是现在本地环境中进行测试，就不必了。\n使用 pg_dump 将你的数据库进行备份。命令大约如下：\npg_dump {your_database_name} -f {backupname}.sql\n例如，如果你的数据库名是 firefish，可以这样：\npg_dump firefish -f firefish_20240906.sql\n对于整篇笔记，我们假定您的数据库名是 firefish 。数据库用户名也是 firefish， 密码是 firefish_pswd。请在下文自行替换对应名称。\n数据库的用户名和密码可以在 Firefish 目录下的 .config/default.yml 找到\n你可以考虑在导出 sql 的时候不导出权限和用户名，这样可以方便迁移到其他用户和其他数据库名上。否则，如果你不是原地迁移。后面的迁移可能会遇到权限问题。如果遇到了这样的问题，你可以看看 附录：权限错误与解决方法 。\n\n--no-owner：不导出对象所有者信息。\n--no-privileges 或 --no-acl：不导出对象的权限（访问控制列表）。\n\n还原\n如果您在本地测试环境，或者其他服务器中尝试接下来的步骤，您现在已经可以将您的备份文件下载到对应环境了。\n或者，如果您的 Firefish 还在使用 Postgres 12 甚至以下，数据库的版本已经过旧，您可以趁机升级一下数据库版本。\n您接下来可以使用这样的命令恢复数据库：\npsql postgres\n进入 postgres。\n如果你是还原备份，此时已经存在 firefish 数据库，请把它删掉：\nDROP DATABASE firefish;\n此后，执行：\nCREATE DATABASE firefish;\nexit\n创建 firefish 数据库。\n现在，执行这样的命令：\npsql -U {your_username} -d {your_database} -f {your_backup}.sql\n例如，对 firefish 用户还原 firefish 数据库，你可以：\npsql -U firefish -d firefish -f path/to/backup.sql\n降级\n该内容来自 Firefish 官方降级文档，有使用自己经验的修改。\n不要升级你现在使用的 Firefish 版本。在 firefish 软件的根目录原地进行此操作：\npsql --file=docs/downgrade.sql --user=your_user_name --dbname=your_database_name\n例如，本案例中是\npsql --file=docs/downgrade.sql --user=firefish --dbname=firefish\nIf you get the FATAL: Peer authentication failed error, you also need to provide the --host option (you will be asked the password):\npsql --file=docs/downgrade.sql --user=your_user_name --dbname=your_database_name --host=127.0.0.1\n因为你是要迁移到 Sharkey，成功执行到这里后就不必按官方降级文档的继续了。到这里，你可以对 Firefish say bye-bye 了，后面不再需要用到它。\n安装 Sharkey 仓库\n选你中意的位置，跳过新建用户的步骤（因为你的 Firefish 已经有用户了！）安装 Sharkey 直到 initialize 数据库的步骤：\ngit clone --recurse-submodules -b stable https://activitypub.software/TransFem-org/Sharkey.git\ncd Sharkey\npnpm install --frozen-lockfile\ncp .config/example.yml .config/default.yml\n编辑 .config/default.yml 使其与你的 Firefish 使用相同的数据库\nvim .config/default.yml\nBuild\npnpm run build\n接下来按照迁移说明进行操作，这里为了 Manual install 做了修改：\npsql 到你的 firefish 数据库，执行这样的 SQL:\n-- start a transaction, so we won't leave the db in a halfway state if\n-- things go wrong\nBEGIN;\n\n-- we need to add back some columns that Firefish removed, but that\n-- Sharkey migrations expect\nALTER TABLE \"user_profile\" ADD \"integrations\" JSONB NOT NULL DEFAULT '{}';\nALTER TABLE \"meta\" ADD \"twitterConsumerSecret\" VARCHAR(128);\nALTER TABLE \"meta\" ADD \"twitterConsumerKey\" VARCHAR(128);\nALTER TABLE \"meta\" ADD \"enableTwitterIntegration\" BOOLEAN NOT NULL DEFAULT false;\nALTER TABLE \"meta\" ADD \"enableGithubIntegration\" BOOLEAN NOT NULL DEFAULT false;\nALTER TABLE \"meta\" ADD \"githubClientId\" VARCHAR(128);\nALTER TABLE \"meta\" ADD \"githubClientSecret\" VARCHAR(128);\nALTER TABLE \"meta\" ADD \"enableDiscordIntegration\" BOOLEAN NOT NULL DEFAULT false;\nALTER TABLE \"meta\" ADD \"discordClientId\" VARCHAR(128);\nALTER TABLE \"meta\" ADD \"discordClientSecret\" VARCHAR(128);\n\n-- also an extra table, for the same reasons\nCREATE TABLE antenna_note();\n\n-- Misskey used to have a Reversi game, Firefish dropped the tables,\n-- now Misskey uses them again\nCREATE TABLE \"reversi_game\" (\"id\" character varying(32) NOT NULL, \"createdAt\" TIMESTAMP WITH TIME ZONE NOT NULL, \"startedAt\" TIMESTAMP WITH TIME ZONE, \"user1Id\" character varying(32) NOT NULL, \"user2Id\" character varying(32) NOT NULL, \"user1Accepted\" boolean NOT NULL DEFAULT false, \"user2Accepted\" boolean NOT NULL DEFAULT false, \"black\" integer, \"isStarted\" boolean NOT NULL DEFAULT false, \"isEnded\" boolean NOT NULL DEFAULT false, \"winnerId\" character varying(32), \"surrendered\" character varying(32), \"logs\" jsonb NOT NULL DEFAULT '[]', \"map\" character varying(64) array NOT NULL, \"bw\" character varying(32) NOT NULL, \"isLlotheo\" boolean NOT NULL DEFAULT false, \"canPutEverywhere\" boolean NOT NULL DEFAULT false, \"loopedBoard\" boolean NOT NULL DEFAULT false, \"form1\" jsonb DEFAULT null, \"form2\" jsonb DEFAULT null, \"crc32\" character varying(32), CONSTRAINT \"PK_76b30eeba71b1193ad7c5311c3f\" PRIMARY KEY (\"id\"));\nCREATE INDEX \"IDX_b46ec40746efceac604142be1c\" ON \"reversi_game\" (\"createdAt\");\nCREATE TABLE \"reversi_matching\" (\"id\" character varying(32) NOT NULL, \"createdAt\" TIMESTAMP WITH TIME ZONE NOT NULL, \"parentId\" character varying(32) NOT NULL, \"childId\" character varying(32) NOT NULL, CONSTRAINT \"PK_880bd0afbab232f21c8b9d146cf\" PRIMARY KEY (\"id\"));\nCREATE INDEX \"IDX_b604d92d6c7aec38627f6eaf16\" ON \"reversi_matching\" (\"createdAt\");\nCREATE INDEX \"IDX_3b25402709dd9882048c2bbade\" ON \"reversi_matching\" (\"parentId\");\nCREATE INDEX \"IDX_e247b23a3c9b45f89ec1299d06\" ON \"reversi_matching\" (\"childId\");\n\n-- move aside some FireFish columns; Sharkey migrations will\n-- re-create them; we don't `DROP` them because we want to keep the data\nALTER TABLE \"user\" RENAME COLUMN \"movedToUri\" TO \"ff_movedToUri\";\nALTER TABLE \"user\" RENAME COLUMN \"alsoKnownAs\" TO \"ff_alsoKnownAs\";\nALTER TABLE \"user\" RENAME COLUMN \"isIndexable\" TO \"ff_isIndexable\";\nALTER TABLE \"user\" RENAME COLUMN \"speakAsCat\" TO \"ff_speakAsCat\";\nALTER TABLE \"user_profile\" RENAME COLUMN \"preventAiLearning\" TO \"ff_preventAiLearning\";\nALTER TABLE \"meta\" RENAME COLUMN \"silencedHosts\" TO \"ff_silencedHosts\";\n\n-- this column was added by both Firefish and Misskey, but with\n-- different names, let's fix it\nALTER TABLE \"meta\" RENAME COLUMN \"ToSUrl\" TO \"termsOfServiceUrl\";\n\n-- update antenna types, this is only needed on some instances but\n-- recommend to run anyway\n--\n-- this *removes* any antennas of types not supported by Sharkey!\nCREATE TYPE public.new_antenna_src_enum AS ENUM ('home', 'all', 'list');\nALTER TABLE antenna ADD COLUMN new_src public.new_antenna_src_enum;\nDELETE FROM antenna WHERE src NOT IN ('home', 'all', 'list');\nALTER TABLE antenna DROP COLUMN src;\nALTER TABLE antenna RENAME COLUMN new_src TO src;\nDROP TYPE public.antenna_src_enum;\nALTER TYPE new_antenna_src_enum RENAME TO antenna_src_enum;\n\n-- optional but recommended: delete all empty moderation log entries\nDELETE FROM moderation_log WHERE info = '{}';\n\n-- only needed on some instances, run this if\n-- `\\dT+ user_profile_mutingnotificationtypes_enum`\n-- does not show `note` in the \"elements\" section\nALTER TYPE \"public\".\"user_profile_mutingnotificationtypes_enum\" ADD VALUE 'note';\n如果有任何报错信息，请停止迁移！除非你真的知道自己在干什么，不要乱动数据库。去 Sharkey 提供的 Matrix or Discord 求助。\n如果没有报错，你就可以接着输入\nCOMMIT;\n提交这些变更。\n好了，现在你可以启动 Sharkey 的 migrations 了。在 Sharkey 的目录：\npnpm run migrate\npnpm run start\n如果两条命令都没有报错的完成了，并且 Sharkey 说它正在监听端口， Ctrl+C 关闭 Sharkey。现在，还要对数据库进行一些小小的按摩（？）\n仍然是\npsql firefish\n到你的数据库：\nBEGIN;\n\n-- all existing users are approved, because Firefish doesn't have a\n-- concept of approvals\nUPDATE \"user\" SET approved = true;\n\n-- now we put back the data we moved aside\nUPDATE \"user\" SET \"movedToUri\" = \"ff_movedToUri\" WHERE \"ff_movedToUri\" IS NOT NULL;\nUPDATE \"user\" SET \"alsoKnownAs\" = \"ff_alsoKnownAs\" WHERE \"ff_alsoKnownAs\" IS NOT NULL;\nUPDATE \"user\" SET \"noindex\" = NOT (COALESCE(\"ff_isIndexable\", true));\nUPDATE \"user\" SET \"speakAsCat\" = COALESCE(\"ff_speakAsCat\", false);\nUPDATE \"user_profile\" SET \"preventAiLearning\" = COALESCE(\"ff_preventAiLearning\", true);\nUPDATE \"meta\" SET \"silencedHosts\" = COALESCE(\"ff_silencedHosts\",'{}');\n\nALTER TABLE \"user\" DROP COLUMN \"ff_movedToUri\";\nALTER TABLE \"user\" DROP COLUMN \"ff_alsoKnownAs\";\nALTER TABLE \"user\" DROP COLUMN \"ff_isIndexable\";\nALTER TABLE \"user\" DROP COLUMN \"ff_speakAsCat\";\nALTER TABLE \"user_profile\" DROP COLUMN \"ff_preventAiLearning\";\nALTER TABLE \"meta\" DROP COLUMN \"ff_silencedHosts\";\n如果没有报错，你就可以接着输入\nCOMMIT;\n提交这些变更。\n现在，Sharkey 的迁移已经完成了。你可以继续 Sharkey 的启动，比如配置 Systemd 项目。如果你之前配了 S3, 请去管理面板查看一下这些设置项，因为可能会迁移出类似这样的 URL： https://https://yourdomain.com, 你可以修复它。\n附录：权限错误与解决方法\n通常发生于备份文件的用户名、数据库名、权限和你的数据库内的设置不一致的时候。\n以下 SQL 全部需要 psql firefish （或对应的数据库名）后使用。需要将 your_user 替换成你的用户名。\nerror: 对表 xxx 权限不够\n直接把 firefish 数据库内的所有表格权限授予给你的用户：\nGRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA public TO your_user;\n然后将所有表格的 owner 设置成你的用户\nDO $$\nDECLARE\n  r RECORD;\nBEGIN\n  FOR r IN\n    SELECT table_schema, table_name\n    FROM information_schema.tables\n    WHERE table_schema NOT IN ('pg_catalog', 'information_schema') AND table_type = 'BASE TABLE'\n  LOOP\n    EXECUTE 'ALTER TABLE ' || r.table_schema || '.' || r.table_name || ' OWNER TO your_user';\n  END LOOP;\nEND;\n$$;\n必须是类型 notification_type_enum 的属主\n同样，将数据库中所有自定义类型的所有者更改为你的用户\nDO $$\nDECLARE\n  r RECORD;\nBEGIN\n  FOR r IN\n    SELECT n.nspname AS schema_name, t.typname AS type_name\n    FROM pg_type t\n    JOIN pg_namespace n ON n.oid = t.typnamespace\n    WHERE t.typowner <> (SELECT oid FROM pg_roles WHERE rolname = 'firefish')\n      AND n.nspname NOT IN ('pg_catalog', 'information_schema')\n      AND t.typtype = 'e'  -- 仅针对枚举类型（自定义类型）\n  LOOP\n    EXECUTE 'ALTER TYPE ' || r.schema_name || '.' || r.type_name || ' OWNER TO your_user';\n  END LOOP;\nEND;\n$$;\n附录：作者修订\n用户数和帖子数一直显示 0\n迁移后，有概率出现用户数和帖子数一直显示 0 的问题。这时可以进入后台作业队列，如果发现像这样的错误：\n\n可以去 psql 进入数据库。尝试输入：\n\\d __chart__federation\n它理应返回\n                                              数据表 \"public.__chart__federation\"\n               栏位               |        类型         | 校对规则 |  可空的  |                      预设\n----------------------------------+---------------------+----------+----------+-------------------------------------------------\n id                               | integer             |          | not null | nextval('__chart__federation_id_seq'::regclass)\n date                             | integer             |          | not null |\n unique_temp___deliveredInstances | character varying[] |          | not null | '{}'::character varying[]\n ___deliveredInstances            | smallint            |          | not null | '0'::smallint\n unique_temp___inboxInstances     | character varying[] |          | not null | '{}'::character varying[]\n ___inboxInstances                | smallint            |          | not null | '0'::smallint\n unique_temp___stalled            | character varying[] |          | not null | '{}'::character varying[]\n ___stalled                       | smallint            |          | not null | '0'::smallint\n ___sub                           | smallint            |          | not null | '0'::smallint\n ___pub                           | smallint            |          | not null | '0'::smallint\n ___pubsub                        | smallint            |          | not null | '0'::smallint\n ___subActive                     | smallint            |          | not null | '0'::smallint\n ___pubActive                     | smallint            |          | not null | '0'::smallint\n索引：\n    \"PK_b39dcd31a0fe1a7757e348e85fd\" PRIMARY KEY, btree (id)\n    \"IDX_36cb699c49580d4e6c2e6159f9\" UNIQUE, btree (date)\n    \"UQ_36cb699c49580d4e6c2e6159f97\" UNIQUE CONSTRAINT, btree (date)\n注意预设中的 nextval('__chart__federation_id_seq'::regclass)\n你很可能在迁移中丢失了该预设。因此，你可以在 Sharkey 已经可以运行后尝试执行：\nBEGIN;\nALTER TABLE public.__chart__active_users ALTER COLUMN id SET DEFAULT nextval('__chart__active_users_id_seq'::regclass);\nALTER TABLE public.__chart__ap_request ALTER COLUMN id SET DEFAULT nextval('__chart__ap_request_id_seq'::regclass);\nALTER TABLE public.__chart__drive ALTER COLUMN id SET DEFAULT nextval('__chart__drive_id_seq'::regclass);\nALTER TABLE public.__chart__federation ALTER COLUMN id SET DEFAULT nextval('__chart__federation_id_seq'::regclass);\nALTER TABLE public.__chart__hashtag ALTER COLUMN id SET DEFAULT nextval('__chart__hashtag_id_seq'::regclass);\nALTER TABLE public.__chart__instance ALTER COLUMN id SET DEFAULT nextval('__chart__instance_id_seq'::regclass);\nALTER TABLE public.__chart__network ALTER COLUMN id SET DEFAULT nextval('__chart__network_id_seq'::regclass);\nALTER TABLE public.__chart__notes ALTER COLUMN id SET DEFAULT nextval('__chart__notes_id_seq'::regclass);\nALTER TABLE public.__chart__per_user_drive ALTER COLUMN id SET DEFAULT nextval('__chart__per_user_drive_id_seq'::regclass);\nALTER TABLE public.__chart__per_user_following ALTER COLUMN id SET DEFAULT nextval('__chart__per_user_following_id_seq'::regclass);\nALTER TABLE public.__chart__per_user_notes ALTER COLUMN id SET DEFAULT nextval('__chart__per_user_notes_id_seq'::regclass);\nALTER TABLE public.__chart__per_user_pv ALTER COLUMN id SET DEFAULT nextval('__chart__per_user_pv_id_seq'::regclass);\nALTER TABLE public.__chart__per_user_reaction ALTER COLUMN id SET DEFAULT nextval('__chart__per_user_reaction_id_seq'::regclass);\nALTER TABLE public.__chart__test ALTER COLUMN id SET DEFAULT nextval('__chart__test_id_seq'::regclass);\nALTER TABLE public.__chart__test_grouped ALTER COLUMN id SET DEFAULT nextval('__chart__test_grouped_id_seq'::regclass);\nALTER TABLE public.__chart__test_unique ALTER COLUMN id SET DEFAULT nextval('__chart__test_unique_id_seq'::regclass);\nALTER TABLE public.__chart__users ALTER COLUMN id SET DEFAULT nextval('__chart__users_id_seq'::regclass);\nALTER TABLE public.__chart_day__active_users ALTER COLUMN id SET DEFAULT nextval('__chart_day__active_users_id_seq'::regclass);\nALTER TABLE public.__chart_day__ap_request ALTER COLUMN id SET DEFAULT nextval('__chart_day__ap_request_id_seq'::regclass);\nALTER TABLE public.__chart_day__drive ALTER COLUMN id SET DEFAULT nextval('__chart_day__drive_id_seq'::regclass);\nALTER TABLE public.__chart_day__federation ALTER COLUMN id SET DEFAULT nextval('__chart_day__federation_id_seq'::regclass);\nALTER TABLE public.__chart_day__hashtag ALTER COLUMN id SET DEFAULT nextval('__chart_day__hashtag_id_seq'::regclass);\nALTER TABLE public.__chart_day__instance ALTER COLUMN id SET DEFAULT nextval('__chart_day__instance_id_seq'::regclass);\nALTER TABLE public.__chart_day__network ALTER COLUMN id SET DEFAULT nextval('__chart_day__network_id_seq'::regclass);\nALTER TABLE public.__chart_day__notes ALTER COLUMN id SET DEFAULT nextval('__chart_day__notes_id_seq'::regclass);\nALTER TABLE public.__chart_day__per_user_drive ALTER COLUMN id SET DEFAULT nextval('__chart_day__per_user_drive_id_seq'::regclass);\nALTER TABLE public.__chart_day__per_user_following ALTER COLUMN id SET DEFAULT nextval('__chart_day__per_user_following_id_seq'::regclass);\nALTER TABLE public.__chart_day__per_user_notes ALTER COLUMN id SET DEFAULT nextval('__chart_day__per_user_notes_id_seq'::regclass);\nALTER TABLE public.__chart_day__per_user_pv ALTER COLUMN id SET DEFAULT nextval('__chart_day__per_user_pv_id_seq'::regclass);\nALTER TABLE public.__chart_day__per_user_reaction ALTER COLUMN id SET DEFAULT nextval('__chart_day__per_user_reaction_id_seq'::regclass);\nALTER TABLE public.__chart_day__users ALTER COLUMN id SET DEFAULT nextval('__chart_day__users_id_seq'::regclass);\n为所有的表格重新设置预设。\n如果没有错误提示，则可以 COMMIT; 提交这些更改。等待一天，帖子数和用户数就会重新显示了。\n"},{"type":"post","id":"renewhexo","title":"在 Hexo 老瓶装新酒","url":"/blog/renewhexo/","content":"我在 2018 年建立这个博客以后，就一直没有换过其它博客平台。试过 Wordpress，也试过 Writefreely，总还是没有 Hexo 之类的静态站点生成器来得又快又好。当然现在似乎更流行别的结构了，Hugo，vuepress，毕竟 Hexo 已经是个有十来岁的老家伙了。在前端，十年足以发生翻天覆地的变化，而 Hexo 已经被远远的甩在后头。\n实际上，我对 Hexo 多少有一点恋旧情绪，毕竟它是我第一次尝试自建博客，也是我第一次尝试 Contribute 到开源项目。截至我写的时候，这个博客使用的主题 Anatolo 还是我 Star 数最高的个人项目。\n但 Hexo 的确是老了。正如我的朋友所说，Hexo 的表演该落幕了，让它退场吧。 Hexo 大多数主题都是用的是裸的 <script> 标签引入前端库，少有主题加入代码压缩，几乎没有主题使用过 typescript。 文档也疏于维护， hexo-utils 更是代码奇奇怪怪 。\n但我还是不忍心彻底放弃 Hexo。因此，我花了一个晚上的时间，对我博客的 Client 进行了重写。同时也是为了探索，像 Hexo 这样的老东西还可不可能与现代化的前端技术相集成。\n\n引入 Rollup 和 typescript\n实际上，我这个博客的前端已经是进行重写过的。旧的 Anatolo 是在我学习 JavaScript 的时候写的，里面充斥着奇怪地全局变量与污染。类型检查更是完全没有，阅读代码难于登天（呃也没这么离谱了）\n后来我对它进行了重写。当时我并没有什么野心，只是将散乱的全局变量收拾到了 Anatolo 一个全局变量里，将 Anatolo 作为静态生成的模板中的简单 js 与复杂的 js 的交互桥梁。\n但是这种写法还是几乎没有什么类型提示。因为实际上所有文件还是简单地用 <script> 被引入，然后放在全局作用域里执行。\n所以我尝试了 rollup. 这个过程比我想象的甚至更简单。我编写 js， 然后 rollup 负责将它们塞进同一个 js 文件里，压缩，加载到静态文件中。有一瞬间，我甚至有些纳闷，为什么我之前没试试这样做呢？\n尤其是当你可以书写类型以后。我承认我真的不喜欢写测试，因此类型提示真的能帮我避免许多愚蠢的错误。\n抛弃 jQuery\njQuery 是我当时抄 hexo-theme-icarus 的时候引入的。但现在，现代化 js 内置的 HTML 操作已经足够方便，不再需要 jQuery 去方便对 HTML 进行操作了。\n更何况，jQuery 的 ajax 等不会返回 Promise，而是返回一些被包裹的 thenable，对于书写 typescript 会很烦躁。\n我大约花了三个小时去把原先的 jQuery 代码全部改造成原生 JS。将 jQuery 的以来去除后，需要加载的 js 文件甚至一下子就降低了上百 KB。\n引入 JSX\n当上面的工作做完以后，引入 JSX 也变得简单了很多。 JSX 本质上是由 typescript 引擎解析并转变成 h 函数的形式。比如下面的代码实际上会编译成这样：\nconst element = <h1 className=\"greeting\">Hello, world!</h1>;\nconst element = h(\"h1\", { className: \"greeting\" }, \"Hello, world!\");\n当然，为了我们这个小小的博客，我们还是不希望引入 React 或者 Vue 这种重量级的前端引擎的。至少这会导致数百 KB 的 js 膨胀。\n因此我们可以自己写 h 函数完成这样的事情。令我惊喜的是，的确可以。Anatolo 就使用了仅仅 30 行完成一个简单的 h 函数，用在 Anatolo 限定的，无需懒更新的场景上。这使得 Anatolo 的代码中用 JSX 格式构造在之前会很复杂的 HTML 模板变成可能。"},{"type":"post","id":"make-blog-support-lean","title":"使 Hexo 支持高亮 Lean","url":"/blog/make-blog-support-lean/","content":"说真的，Hexo 这么烂下去我真要换 Hugo 了——为什么它甚至不支持给 hljs 添加语言插件？\n好吧，这篇博客讲述如何让你的 Hexo 博客支持高亮 Lean，并且是后端渲染。\n\nStep 1. 安装 highlightjs-lean\n问题的起因就是 hljs 并不默认支持 lean，因此必须手动安装之。在你的 hexo 博客根目录进行：\nnpm install highlightjs-lean\n# 或者 yarn add highlightjs-lean\nStep 2. 将 Lean 语言支持添加到 hljs\n你需要创建一个简单的 hexo 插件做这件事情。在你的 hexo 博客根目录新建 scripts 文件夹，随意新建一个 javascript 文件，名字自取，例如 add-lean.js\n在该 js 文件中写入以下内容：\nconst hljs = require(\"highlight.js\");\nconst leanHljs = require(\"highlightjs-lean\");\nhljs.registerLanguage(\"lean\", leanHljs);\n这样就注册了 lean 的语言支持\nStep 3. 把 hexo-utils 的语言定义文件里添加上 Lean\n如果你做了上述操作，恭喜你，至少 autodetect 能尝试识别 Lean 了。但是 hljs 的 autodetect 众所周知的不准确，于是你尝试在代码块中指定语言为 lean，嘿，hexo 反而自动给你转成 plaintext 了~\n在这三行中揭示了原因。 hexo-utils 使用了一个 hard-coded 的 highlight_alias.json 文件，任何不在这个 json 文件中的语言都会直接被视作 plaintext， 我不懂它为什么要这样干，hljs 明明提供了 api 让你获得 available 的语言，但它就是这么干了。\nconst alias = require('../highlight_alias.json');\n\nfunction highlight(str: string, options: Options) {\n  //...\n  if (!lang || !alias.aliases[lang]) {\n    lang = 'plaintext';\n  }\n由于这个文件是硬编码的，你甚至不能更改它。所以插件在这里有些苍白无力。你不得不写一个 不是插件的脚本（比如 pre-deploy.js），在每次 deploy 前把该文件修改一下：\nconst fs = require(\"fs\");\n\nconst alias = JSON.parse(\n  fs.readFileSync(\"node_modules/hexo-util/highlight_alias.json\").toString()\n);\n\nalias.aliases[\"lean\"] = \"lean\";\nalias.languages.push(\"lean\");\n\nfs.writeFileSync(\n  \"node_modules/hexo-util/highlight_alias.json\",\n  JSON.stringify(alias)\n);\n然后在你每次 deploy 前，需要执行一下\nnode pre-deploy.js\n把该文件修改后，hexo 终于支持了 lean 语言的高亮。\n或者……\n不跟你 hexo 的 markdown 渲染器玩辣！\n安装 markdown-it-highlightjs，作为 markdown-it 的插件，关掉 hexo 的 highlight 处理。现在 Step3 的所有内容直接可以不看，Lean 4 高亮已经好了。\n成果展示\nimport MIL.Common\n\nopen Nat\n\n-- These are pieces of data.\n#check 2 + 2\n\ndef f (x : ℕ) :=\n  x + 3\n\n#check f\n\n-- These are propositions, of type `Prop`.\n#check 2 + 2 = 4\n\ndef FermatLastTheorem :=\n  ∀ x y z n : ℕ, n > 2 ∧ x * y * z ≠ 0 → x ^ n + y ^ n ≠ z ^ n\n\n#check FermatLastTheorem\n\n-- These are proofs of propositions.\ntheorem easy : 2 + 2 = 4 :=\n  rfl\n\n#check easy\n\ntheorem hard : FermatLastTheorem :=\n  sorry\n\n#check hard\n\n-- Here are some proofs.\nexample : ∀ m n : Nat, Even n → Even (m * n) := fun m n ⟨k, (hk : n = k + k)⟩ ↦\n  have hmn : m * n = m * k + m * k := by rw [hk, mul_add]\n  show ∃ l, m * n = l + l from ⟨_, hmn⟩\n\nexample : ∀ m n : Nat, Even n → Even (m * n) :=\nfun m n ⟨k, hk⟩ ↦ ⟨m * k, by rw [hk, mul_add]⟩\n\nexample : ∀ m n : Nat, Even n → Even (m * n) := by\n  -- Say m and n are natural numbers, and assume n=2*k.\n  rintro m n ⟨k, hk⟩\n  -- We need to prove m*n is twice a natural number. Let's show it's twice m*k.\n  use m * k\n  -- Substitute for n,\n  rw [hk]\n  -- and now it's obvious.\n  ring\n\nexample : ∀ m n : Nat, Even n → Even (m * n) := by\n  rintro m n ⟨k, hk⟩; use m * k; rw [hk]; ring\n\nexample : ∀ m n : Nat, Even n → Even (m * n) := by\n  intros; simp [*, parity_simps]"},{"type":"post","id":"lean4-intro","title":"Lean 初见笔记","url":"/blog/lean4-intro/","content":"Lean 4 是一个功能强大的交互式定理证明器和编程语言，结合了逻辑推理与编程，主要用于形式化验证、数学证明以及高可靠性软件开发。Lean 4 提供了一个灵活的类型系统和高性能的编译器，使其在理论研究和实际应用中都有出色表现。 —— GPT 说的。\nF*ck 我为什么要去看这种东西啊（悲） —— 我说的\n\n\n假装这是前言\n\\senioria/\n这篇博客我会尝试用英语写。\nPreparation\nInstall\nFollow the guide at https://leanprover-community.github.io/get_started.html\nThe book\nI’m firstly reading Mathematics in Lean to start. It is the standard mathematics-oriented reference is Mathematics in Lean, recommended by Lean Community. Unlike other popular languages, you may need a high perspective of math to learn Lean.\n\nSenioria: linca 这种动态语言迷居然觉得 lean 爽 x（超小声（\nMe: no 我是在用它作为定理证明 （看上去就好坐牢\n\n（……真的有人会用 Lean 这种语言去写代码吗……学术代码例外）\nUnlike other languages, in general, if you just open a single .lean file in your text editor and try to compile it, you’ll get a bunch of confusing errors.\nThus, you should strictly follow the guide, if you’re a starter. I suggest this because I messed up my environment just by swapping a step (oh…), that’s my personal experience.\n如果你是初学者，你应该严格的遵守安装指南。这是我的亲身体会，你只需要交换一个看上去微不足道的步骤就能搞坏你的环境。（毕竟初学者）\nEvery non-trivial piece of Lean code needs to live inside a Lean project (sometimes also called a Lean package). A “Lean project” is more than just a folder that you’ve named “My Lean stuff”. Rather, it’s a folder containing some very specific things: in particular, a git repository and a file lakefile.lean that gathers information about dependencies of the project, including for instance the version of Lean that should be used.\nBasics\nLearn requires us to justify each step in a calculation. For example:\nexample (a b c : ℝ) : a * b * c = b * (a * c) := by\n  rw [mul_comm a b]\n  rw [mul_assoc b a c]\nThe rw means “rewrite”. And the mul_comm here means Commutative property of multiplication（乘法交换律）. So, rw [mul_comm a b] means “rewrite patterns match (a * b) to (b * a)”.\nYou can see the replaced formula in VSCode here:\n\nAnd \\l (←) stands for right-to-left equation replacement. For example:\nexample (a b c : ℝ) : b * (a * c) = a * b * c := by\n  rw [← mul_assoc b a c]\n  rw [← mul_comm a b]\nIt is the reverse of the previous proof.\nTactic\nIt will be annoying to write duplicated basic formulas, for example if we are proving this:\nexample : g + a + d + e + b + h + f + c = a + b + c + d + e + f + g + h := by\n  rw [add_comm g]\n  rw [add_assoc a, add_comm g, ← add_assoc]\n  rw [add_assoc (a + d), add_comm g, ← add_assoc]\n  rw [add_assoc (a + d + e), add_comm g, ← add_assoc]\n  rw [add_assoc (a + d + e + b), add_assoc (a)]\n  rw [add_assoc a, add_comm (d + e), ← add_assoc a]\n  rw [add_assoc (a + b + (d + e)), add_comm (g + h)]\n  rw [add_assoc (a + b + (d + e)), add_comm (f + (g + h)), ← add_assoc]\n  rw [add_assoc (a + b), add_comm (d + e)]\n  rw [← add_assoc, ← add_assoc, ← add_assoc, ← add_assoc]\nWe reordered the items tediously, but this is something that a human would know is correct at first glance. In fact, Lean requires a rigorous proof, so this is essential, but we can let the computer do this boring work for us. We need to introduce a magic: Tactic\n\nThe ring tactic is imported indirectly when we import Mathlib.Data.Real.Basic, but we will see in the next section that it can be used for calculations on structures other than the real numbers. It can be imported explicitly with the command import Mathlib.Tactic. We will see there are similar tactics for other common kind of algebraic structures.\n\nThe ring tactic is designed to prove identities in any commutative ring as long as they follow purely from the ring axioms, without using any local assumption. So we can rewrite the tedious proof above, with only one line:\nexample : g + a + d + e + b + h + f + c = a + b + c + d + e + f + g + h := by\n  ring\n到这里 2.1. Calculating 的内容就结束了，今天就先写到这里。"},{"type":"post","id":"模拟一个vue的响应式操作","title":"试着复刻一个vue的计算属性","url":"/blog/模拟一个vue的响应式操作/","content":"之前对于 Vue 的响应式封装（这里主要思考的是 computed），主要是用用，其实是懒得思考背后的原理的。毕竟原理其实可以用一句话说明：计算属性对别的属性产生有向的依赖关系，这个依赖关系构成一个有向无环图（DAG），图上的某个节点更新后重新计算其所有后置节点即可。\n但是仔细想来，内部其实有一些时间复杂度的问题。显然，我们不能暴力调用回调函数（会卡出指数级时间复杂度 O(2^n) 下面会详细解释）。同时朴素的做法很难解决这样的问题：\nconst a = ref([]);\nconst b = computed(() => a.join(\",\"));\nfor (let i = 1; i <= n; i++) {\n  a.value = a.value.concat([i]);\n}\n注意到对于一个网页而言，我们实际上期望 b 能在整个宏任务跑完以后才更新。所以实际上a.value 的 setter 触发的更新必须要进行推迟。\n这篇文章讲讲我怎么在思考这些的过程中试着复刻一个 vue 的计算属性 computed 的\n\n关于 computed\nVue 的 computed 有多种，不过为了简化问题，这里我们只讨论最经典的那种：\nfunction computed(fn: () => T): ComputedRef<T>;\n这个 computed 函数接受一个 callback， 每当 callback 涉及到的其他响应式变量发生变化时，重新计算。具体请自行参考 vue 的文档。\n如果我们希望构建一个高性能的computed，就必须进行复杂度分析。\n复杂度分析\n现在假设我们有 n 个响应式状态，彼此之间总共有 m 的依赖关系。它们可以构成一个 DAG G = (V, E)。 其中， E = \\{(u, v) | u 的计算依赖于v \\}。显然出度为 0 的点是可写的 Ref，其余点是 ComputedRef.\n这里必须是 DAG，因为一旦计算属性出现环，那就会出现死循环。\n我们把 ComputedRef 的平均计算时间记为 T\n朴素写法复杂度分析\n考虑一个这样的朴素 computed 实现：\nfunction computed(fn) {\n  let cached = false;\n  let val;\n  let children = [];\n  const res = {\n    get value() {\n      children.push(useContext());\n      inContext(res, () => {\n        if (!cached) val = fn();\n        cached = true;\n      });\n      return val;\n    },\n    update() {\n      val = fn();\n      children.forEach((c) => c.update());\n    },\n  };\n}\n第一次尝试获得 .value 的时候，我们在 res 的 context 下跑一次 fn。 跑 fn 的过程中，每个响应式属性 .value 都会尝试把 context 设为自己的 children （也就是构建 u,v 边）\n容易发现，跑完第一次的 fn 以后再调用 .value 是 O(1) 的。也就是说，计算全图的所有属性只需要挨个计算一次，即为 O(nT)\n但是考虑更新。最坏条件下，我们会发现有类似这样的依赖关系：\ngraph LR;\nE --> D --> C --> B --> A\nE --> C --> A\nD --> B\nE --> B\nD --> A\nE --> A\n现在假设我们更新了 A 。A 的孩子是 [D, C, B]，我们发现递归树是这样的：\ngraph TD;\n\nA --> AB --> ABC --> ABCD --> ABCDE\nABC --> ABCE\nAB --> ABD --> ABDE\nAB --> ABE\nA --> AC --> ACD --> ACDE\nAC --> ACE\nA --> AD --> ADE\nA --> AE\n这里的问题在于 A 可能先用错误的 B,C,D 数据触发了对 E 的更新；然后对 D 更新时 D 又引起了依赖 D 的 E 的更新。E 在这个递归树中整整被计算了 8 次！\n显然树的叶子数即为 ABCDE 的全部以 A 开头 E 结尾的子串数。也就是说，如果我们有 n 个计算属性依次依赖前面的 n-1 个计算属性 （第一个计算属性依赖于 A）。最后再有一个计算属性 E 依赖于这 n 个计算属性，那么我们会得到 2^n 个不同的以 A 开头 E 结尾的子串。 更新 A 会导致整整 O(2^n) 次 E 的计算！\n优化\n很容易想到一个优化算法。既然依赖关系是 DAG，那么我们可以在 DAG 上跑一个拓扑排序，按照拓扑序更新不就好了？\n但问题来了，在这个隐形的有向图上优雅地跑拓扑排序呢？我们知道对于 n 个简单节点我们可以这样跑拓扑排序：\nconst sorted = [];\nfunction topo_sort(node) {\n  if (n.vis) return;\n  n.vis = true;\n  node.parents.forEach((n) => topo_sort(n));\n  sorted.push(node);\n}\nnodes.forEach((n) => topo_sort(n));\n由于每个顶点只访问了一遍，复杂度显然为 O(n)\n再考虑拓补排序回溯的过程本身已经求出了该点的前置，因此可以把 fn 放在这里计算。 computed 伪代码如下：\nfunction computed(fn) {\n  let cached_val;\n  let cached = false;\n  const calculate = () => {\n    in_context(closure, () => {\n      cached_val = fn();\n    });\n    cached = true;\n  };\n  const closure = {\n    get value() {\n      context.parents.add(closure);\n      if (!cached) calculate();\n      return cached_val;\n    },\n    uncache() {\n      if (!cached) return;\n      cached = false;\n      recursiveUncache(closure.children);\n    },\n  };\n  return ret;\n}\n这里的关键在于我们把整个得到的 ComputedRef 变成了静态的：上游更新某个节点以后，调用 recursiveUncache 递归地把其按拓扑序的所有子节点全部设为缓存失效状态，但不进行 fn 的计算。由于一个处于缓存失效状态的节点，其子节点必然已经先行被缓存失效，因此每个节点只会 uncache 一次。也就是说，更改的最坏时间复杂度为 O(n) 没有 T。\n此时，某个元素可以进行多次更改；由于都是懒计算的，多次更改也不会触发计算属性的计算。这一点我们可以用如下的 vue 代码证实：\nlet b_count = 0;\nconst a = ref(1);\nconst b = computed(() => {\n  b_count++;\n  return a.value + 1;\n});\n\na.value = 1;\na.value = 11;\na.value = 114;\na.value = 1145;\na.value = 11451;\na.value = 114514;\n\nconsole.log(b_count); // 0，因为b没有被访问过value属性，根本无需被计算\nconsole.log(b.value); // 114515\n\na.value = 114514;\na.value = 11451;\na.value = 1145;\na.value = 114;\na.value = 11;\na.value = 1;\n\nconsole.log(b.value); // 1\nconsole.log(b_count); // 2。b是懒计算的，因此实际上只计算了两次。\n这样我们就初步写好了一个 computed。其时间复杂度是 O(nT)\n完整的，可运行的代码会类似这样：\nfunction MyVue() {\n  let _newId = 0;\n  function newId() {\n    return _newId++;\n  }\n\n  /** @template T */\n  class Closure {\n    /**\n     * 依赖的其他响应式\n     * @type {Set<Closure>}\n     */\n    parents = new Set();\n    /**\n     * 被这些东西依赖\n     * @type {Set<Closure>}\n     */\n    children = new Set();\n    /**\n     * 闭包的其他状态\n     * @type {Record<string, any>}\n     */\n    state = {};\n    /** @param {T} ret  */\n    constructor(ret) {\n      this._ret = ret;\n    }\n    /** @returns {T} */\n    get ret() {\n      return this._ret;\n    }\n  }\n  let context = null;\n  const nextTickCalculates = new Set();\n\n  /**\n   * @param {Closure} closure\n   */\n  function triggerUncacheChain(closure) {\n    for (const child of closure.children) {\n      child.state.uncache?.();\n    }\n  }\n  /**\n   * 模拟nextTick触发的内容\n   * @param {Closure} closure\n   */\n  function queueRecalculate(closure) {\n    if (nextTickCalculates.size == 0) {\n      nextTickCalculates.add(null);\n      queueMicrotask(() => {\n        console.log(\"// Microtask:\");\n        for (const closure of nextTickCalculates) {\n          if (closure != null) {\n            for (const child of Array.from(closure.children)) {\n              console.log(\n                \"update = { id:\",\n                child.id,\n                \", val: \",\n                child.ret.value,\n                \"}\"\n              );\n            }\n          }\n        }\n        nextTickCalculates.clear();\n      });\n    }\n    nextTickCalculates.add(closure);\n  }\n  /**\n   * @param {Closure} closure\n   */\n  function cancelRecalculate(closure) {\n    nextTickCalculates.delete(closure);\n  }\n\n  /**\n   * 类似vue的shallowRef\n   * @template T\n   * @param {T} val\n   * @returns {{value: T}}\n   */\n  function ref(val) {\n    const closure = new Closure({\n      get value() {\n        context?.parents?.add(closure);\n        return closure.state.val;\n      },\n      set value(v) {\n        closure.state.val = v;\n        triggerUncacheChain(closure);\n        return true;\n      },\n    });\n    closure.id = newId();\n    closure.state.val = val;\n    return closure.ret;\n  }\n\n  /**\n   * @template {() => T} Fn\n   * @param {Fn} fn\n   * @returns {{value: ReturnType<Fn>}}\n   */\n  function computed(fn) {\n    const calculate = () => {\n      for (const parent of Array.from(closure.parents)) {\n        parent.children.delete(closure);\n      }\n      closure.parents.clear();\n\n      old_context = context;\n      context = closure;\n      closure.state.cached_val = fn();\n      context = old_context;\n\n      for (const parent of closure.parents) {\n        parent.children.add(closure);\n      }\n\n      cancelRecalculate(closure);\n      closure.state.cached = true;\n      return closure.state.cached_val;\n    };\n    const closure = new Closure({\n      get value() {\n        context?.parents?.add(closure);\n        if (!closure.state.cached) calculate();\n        return closure.state.cached_val;\n      },\n    });\n    closure.id = newId();\n    closure.state.cached = false;\n    closure.state.uncache = () => {\n      if (!closure.state.cached) return;\n      closure.state.cached = false;\n      queueRecalculate(closure);\n      triggerUncacheChain(closure);\n    };\n    return closure.ret;\n  }\n\n  return { ref, computed };\n}\n\nconst { ref, computed } = MyVue();\n\nfunction test(desc, fn) {\n  let prom = new Promise((res) => {\n    console.log(`// =========================================`);\n    console.log(`// =========================================`);\n    console.log(`// =========================================`);\n    console.log(\"// \", desc);\n    console.log(`// =====TEST ${desc} START========`);\n    fn();\n    console.log(`// =====TEST ${desc} OVER=========`);\n    res();\n  });\n  const res = {\n    thenTest: (desc, fn) => {\n      prom = prom.then(() => {\n        test(desc, fn);\n      });\n      return res;\n    },\n  };\n  return res;\n}\n\ntest(\"链\", () => {\n  const a = ref(1); // id: 0\n  const nums = [a];\n  const TEST_SIZE = 8;\n  for (let i = 1; i <= TEST_SIZE; i++) {\n    nums[i] = computed(() =>\n      Array.from({ length: i }, (_, index) => index)\n        .sort(() => Math.random() - 0.5)\n        .reduce((x, id) => x + nums[id].value, 0)\n    );\n  }\n\n  let cnt = 0;\n\n  const i = computed(() => {\n    cnt++;\n    return `last is: ${nums[TEST_SIZE].value}, computed ${cnt} times`;\n  });\n\n  console.log(\"/* NOW:  */  i.value =\", JSON.stringify(i.value));\n  console.log(\"/* STEP: */  a.value = 2\");\n  a.value = 2;\n  console.log(\"/* STEP: */  a.value = 3\");\n  a.value = 3;\n  console.log(\"/* STEP: */  a.value = 4\");\n  a.value = 4;\n  console.log(\"/* STEP: */  a.value = 5\");\n  a.value = 5;\n  console.log(\"/* STEP: */  a.value = 2\");\n  a.value = 2;\n  console.log(\"/* NOW:  */  i.value =\", JSON.stringify(i.value));\n\n  console.log(\"/* STEP: */  a.value = 3\");\n  a.value = 3;\n})\n  .thenTest(\"测试2\", () => {\n    const a = ref(1);\n\n    let cnt_c = 0;\n    let cnt_d = 0;\n    const c = computed(() => {\n      a.value;\n      return ++cnt_c;\n    });\n    const d = computed(() => {\n      a.value;\n      return ++cnt_d;\n    });\n\n    const b = computed(() => {\n      if (a.value) {\n        return c.value;\n      } else {\n        return d.value;\n      }\n    });\n\n    const msg = [];\n\n    msg.push(b.value + JSON.stringify({ cnt_c, cnt_d }));\n    a.value = 0;\n    msg.push(b.value + JSON.stringify({ cnt_c, cnt_d }));\n    a.value = 1;\n    msg.push(b.value + JSON.stringify({ cnt_c, cnt_d }));\n    a.value = 0;\n    msg.push(b.value + JSON.stringify({ cnt_c, cnt_d }));\n    a.value = 1;\n    msg.push(JSON.stringify({ cnt_c, cnt_d }));\n\n    console.log(msg);\n  })\n  .thenTest(\"两个依赖\", () => {\n    const a = ref(1);\n    const b = ref(1);\n    const a_then = ref(\"a_then\");\n    const b_then = ref(\"b_then\");\n    const c = computed(() => {\n      console.log(\"c发生了重新计算\");\n      if (a.value) {\n        return a_then.value;\n      }\n      if (b.value) {\n        return b_then.value;\n      }\n    });\n\n    console.log(c.value);\n    console.log(c.value);\n    b.value = 0;\n    console.log(c.value);\n    a.value = 0;\n    console.log(c.value);\n    b.value = 1;\n    console.log(c.value);\n  });"},{"type":"post","id":"latex-symbols-collection","title":"Latex符号大全","url":"/blog/latex-symbols-collection/","content":"Latex 符号大全\n\n\n\n\n\n\n\nOperators\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSymbolCommandSymbolCommandSymbolCommand\\pm\\pm\\mp\\mp\\times\\times\\div\\div\\cdot\\cdot\\ast\\ast\\star\\star\\dagger\\dagger\\ddagger\\ddagger\\amalg\\amalg\\cap\\cap\\cup\\cup\\uplus\\uplus\\sqcap\\sqcap\\sqcup\\sqcup\\vee\\vee\\wedge\\wedge\\oplus\\oplus\\ominus\\ominus\\otimes\\otimes\\circ\\circ\\bullet\\bullet\\diamond\\diamond\\lhd\\lhd\\rhd\\rhd\\unlhd\\unlhd\\unrhd\\unrhd\\oslash\\oslash\\odot\\odot\\bigcirc\\bigcirc\\triangleleft\\triangleleft\\Diamond\\Diamond\\bigtriangleup\\bigtriangleup\\bigtriangledown\\bigtriangledown\\Box\\Box\\triangleright\\triangleright\\setminus\\setminus\\wr\\wr\\sqrt{x}\\sqrt{x}x^{\\circ}x^{\\circ}\\triangledown\\triangledown\\sqrt[n]{x}\\sqrt[n]{x}a^xa^xa^{xyz}a^{xyz}a_xa_x\nRelations\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSymbolCommandSymbolCommandSymbolCommand\\le\\le\\ge\\ge\\neq\\neq\\sim\\sim\\ll\\ll\\gg\\gg\\doteq\\doteq\\simeq\\simeq\\subset\\subset\\supset\\supset\\approx\\approx\\asymp\\asymp\\subseteq\\subseteq\\supseteq\\supseteq\\cong\\cong\\smile\\smile\\sqsubset\\sqsubset\\sqsupset\\sqsupset\\equiv\\equiv\\frown\\frown\\sqsubseteq\\sqsubseteq\\sqsupseteq\\sqsupseteq\\propto\\propto\\bowtie\\bowtie\\in\\in\\ni\\ni\\prec\\prec\\succ\\succ\\vdash\\vdash\\dashv\\dashv\\preceq\\preceq\\succeq\\succeq\\models\\models\\perp\\perp\\parallel\\parallel\\mid\\mid\\bumpeq\\bumpeq\nNegations of many of these relations can be formed by just putting \\not before the symbol, or by slipping an “n” between the \\ and the word. Here are a couple examples, plus many other negations; it works for many of the many others as well.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSymbolCommandSymbolCommandSymbolCommand\\nmid\\nmid\\nleq\\nleq\\ngeq\\ngeq\\nsim\\nsim\\ncong\\ncong\\nparallel\\nparallel\\not<\\not<\\not>\\not>\\not=\\not= or \\neq or \\ne\\not\\le\\not\\le\\not\\ge\\not\\ge\\not\\sim\\not\\sim\\not \\approx\\not\\approx\\not\\cong\\not\\cong\\not\\equiv\\not\\equiv\\not\\parallel\\not\\parallel\\nless\\nless\\ngtr\\ngtr\\lneq\\lneq\\gneq\\gneq\\lnsim\\lnsim\\lneqq\\lneqq\\gneqq\\gneqq\nTo use other relations not listed here, such as =, >, and <, in LaTeX, you must use the symbols on your keyboard, as they are not available in \\LaTeX.\nGreek Letters\nLowercase Letters\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSymbolCommandSymbolCommandSymbolCommandSymbolCommand\\alpha\\alpha\\beta\\beta\\gamma\\gamma\\delta\\delta\\epsilon\\epsilon\\varepsilon\\varepsilon\\zeta\\zeta\\eta\\eta\\theta\\theta\\vartheta\\vartheta\\iota\\iota\\kappa\\kappa\\lambda\\lambda\\mu\\mu\\nu\\nu\\xi\\xi\\pi\\pi\\varpi\\varpi\\rho\\rho\\varrho\\varrho\\sigma\\sigma\\varsigma\\varsigma\\tau\\tau\\upsilon\\upsilon\\phi\\phi\\varphi\\varphi\\chi\\chi\\psi\\psi\\omega\\omega\nCapital Letters\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSymbolCommandSymbolCommandSymbolCommandSymbolCommand\\Gamma\\Gamma\\Delta\\Delta\\Theta\\Theta\\Lambda\\Lambda\\Xi\\Xi\\Pi\\Pi\\Sigma\\Sigma\\Upsilon\\Upsilon\\Phi\\Phi\\Psi\\Psi\\Omega\\Omega\nArrows\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSymbolCommandSymbolCommand\\gets\\gets\\to\\to\\leftarrow\\leftarrow\\Leftarrow\\Leftarrow\\rightarrow\\rightarrow\\Rightarrow\\Rightarrow\\leftrightarrow\\leftrightarrow\\Leftrightarrow\\Leftrightarrow\\mapsto\\mapsto\\hookleftarrow\\hookleftarrow\\leftharpoonup\\leftharpoonup\\leftharpoondown\\leftharpoondown\\rightleftharpoons\\rightleftharpoons\\longleftarrow\\longleftarrow\\Longleftarrow\\Longleftarrow\\longrightarrow\\longrightarrow\\Longrightarrow\\Longrightarrow\\longleftrightarrow\\longleftrightarrow\\Longleftrightarrow\\Longleftrightarrow\\longmapsto\\longmapsto\\hookrightarrow\\hookrightarrow\\rightharpoonup\\rightharpoonup\\rightharpoondown\\rightharpoondown\\leadsto\\leadsto\\uparrow\\uparrow\\Uparrow\\Uparrow\\downarrow\\downarrow\\Downarrow\\Downarrow\\updownarrow\\updownarrow\\Updownarrow\\Updownarrow\\nearrow\\nearrow\\searrow\\searrow\\swarrow\\swarrow\\nwarrow\\nwarrow\\overrightarrow{AB}\\overrightarrow{AB}\\overleftarrow{AB}\\overleftarrow{AB}\\overleftrightarrow{AB}\\overleftrightarrow{AB}\n(For those of you who hate typing long strings of letters, \\iff and \\implies can be used in place of \\Longleftrightarrow and \\Longrightarrow respectively.)\nDots\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSymbolCommandSymbolCommand\\cdot\\cdot\\vdots\\vdots\\dots\\dots\\ddots\\ddots\\cdots\\cdots\\iddots\\iddots\nAccents\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSymbolCommandSymbolCommandSymbolCommand\\hat{x}\\hat{x}\\check{x}\\check{x}\\dot{x}\\dot{x}\\breve{x}\\breve{x}\\acute{x}\\acute{x}\\ddot{x}\\ddot{x}\\grave{x}\\grave{x}\\tilde{x}\\tilde{x}\\mathring{x}\\mathring{x}\\bar{x}\\bar{x}\\vec{x}\\vec{x}\nWhen applying accents to i and j, you can use \\imath and \\jmath to keep the dots from interfering with the accents:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSymbolCommandSymbolCommand\\vec{\\jmath}\\vec{\\jmath}\\tilde{\\imath}\\tilde{\\imath}\n\\tilde and \\hat have wide versions that allow you to accent an expression:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSymbolCommandSymbolCommand\\widehat{7+x}\\widehat{7+x}\\widetilde{abc}\\widetilde{abc}\nOthers\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSymbolCommandSymbolCommandSymbolCommand\\infty\\infty\\triangle\\triangle\\angle\\angle\\aleph\\aleph\\hbar\\hbar\\imath\\imath\\jmath\\jmath\\ell\\ell\\wp\\wp\\Re\\Re\\Im\\Im\\mho\\mho\\prime\\prime\\emptyset\\emptyset\\nabla\\nabla\\surd\\surd\\partial\\partial\\top\\top\\bot\\bot\\vdash\\vdash\\dashv\\dashv\\forall\\forall\\exists\\exists\\neg\\neg\\flat\\flat\\natural\\natural\\sharp\\sharp\\backslash\\backslash\\Box\\Box\\Diamond\\Diamond\\clubsuit\\clubsuit\\diamondsuit\\diamondsuit\\heartsuit\\heartsuit\\spadesuit\\spadesuit\\Join\\Join\\blacksquare\\blacksquare\\diamondsuit\\diamondsuit\\copyright\\copyright\\underarc{XYZ}\\underarc{XYZ}\\heartsuit\\heartsuit\\overarc{ABC}\\overarc{ABC}\\cup\\cup\\S\\S\\P\\P\\Vdash\\Vdash\\pounds\\pounds\\in\\in\\vDash\\vDash\\bigstar\\bigstar\\implies\\implies\\square\\square\\smiley\\smiley\\mathbb{R}\\mathbb{R} (represents all real numbers)\\checkmark\\checkmark\\cancer\\cancer\nNote: \\cancer and \\overarc{ABC} do not work in the classroom.\nCommand Symbols\nSome symbols are used in commands, so they need to be treated in a special way.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSymbolCommandSymbolCommandSymbolCommandSymbolCommand\\textdollar\\textdollar or $\\&\\&\\%\\%\\#\\#\\_\\_\\{\\{\\}\\}\\backslash\\backslash\n(Warning: Using for\\textdollarwill result in $$. This is a bug as far as we know. Depending on the version of\\LaTeX$ this is not always a problem.)\nEuropean Language Symbols\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSymbolCommandSymbolCommandSymbolCommandSymbolCommand{\\oe}{\\oe}{\\ae}{\\ae}{\\o}{\\o}{\\OE}{\\OE}{\\AE}{\\AE}{\\AA}{\\AA}{\\O}{\\O}{\\l}{\\l}{\\ss}{\\ss}\\text{!`}!`{\\L}{\\L}{\\SS}{\\SS}\nBracketing Symbols\nIn mathematics, sometimes we need to enclose expressions in brackets, braces or parentheses. Some of these work just as you’d imagine in LaTeX; type ( and ) for parentheses, [ and ] for brackets, and | and | for absolute value. However, other symbols have special commands:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSymbolCommandSymbolCommandSymbolCommand\\{\\{\\}\\}\\||\\backslash\\backslash\\lfloor\\lfloor\\rfloor\\rfloor\\lceil\\lceil\\rceil\\rceil\\langle\\langle\\rangle\\rangle\nYou might notice that if you use any of these to typeset an expression that is vertically large, like\n(\\frac{a}{x} )^2\nthe parentheses don’t come out the right size:\n(\\frac{a}{x})^2\nIf we put \\left and \\right before the relevant parentheses, we get a prettier expression:\n\\left(\\frac{a}{x} \\right)^2\ngives\n\\left(\\frac{a}{x} \\right)^2\nFor systems of equations or piecewise functions, use the cases environment:\nf(x) = \\begin{cases} x^2 & x \\ge 0 \\\\ x & x < 0 \\end{cases}\nwhich gives\nf(x) = \\begin{cases} x^2 & x \\ge 0 \\\\ x & x < 0 \\end{cases}\nIn addition to the \\left and \\right commands, when doing floor or ceiling functions with fractions, using \\left\\lceil\\frac{x}{y}\\right\\rceil and \\left\\lfloor\\frac{x}{y}\\right\\rfloor\ngives both \\left\\lceil\\frac{x}{y}\\right\\rceil and \\left\\lfloor\\frac{x}{y}\\right\\rfloor, respectively.\nAnd, if you type this\n\\underbrace{a_0+a_1+a_2+\\cdots+a_n}_{x}\nGives\n\\underbrace{a_0+a_1+a_2+\\cdots+a_n}_{x}\nOr\n\\overbrace{a_0+a_1+a_2+\\cdots+a_n}^{x}\nGives\n\\overbrace{a_0+a_1+a_2+\\cdots+a_n}^{x}\n\\left and \\right can also be used to resize the following symbols:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSymbolCommandSymbolCommandSymbolCommand\\uparrow\\uparrow\\downarrow\\downarrow\\updownarrow\\updownarrow\\Uparrow\\Uparrow\\Downarrow\\Downarrow\\Updownarrow\\Updownarrow\nMulti-Size Symbols\nSome symbols render differently in inline math mode and in display mode. Display mode occurs when you use \\[...\\] or $$...$$, or environments like\n[…]\n,\n...\n. Read more in the commands section of the guide about how symbols which take arguments above and below the symbols, such as a summation symbol, behave in the two modes.\nIn each of the following, the two images show the symbol in display mode, then in inline mode.\n\n\n\\sum\n\\sum  \\textstyle\\sum\n\n\n\\int\n\\int  \\textstyle\\int\n\n\n\\oint\n\\oint  \\textstyle\\oint\n\n\n\\prod\n\\prod  \\textstyle\\prod\n\n\n\\coprod\n\\coprod  \\textstyle\\coprod\n\n\n\\bigcap\n\\bigcap  \\textstyle\\bigcap\n\n\n\\bigcup\n\\bigcup  \\textstyle\\bigcup\n\n\n\\bigsqcup\n\\bigsqcup  \\textstyle\\bigsqcup\n\n\n\\bigvee\n\\bigvee  \\textstyle\\bigvee\n\n\n\\bigwedge\n\\bigwedge  \\textstyle\\bigwedge\n\n\n\\bigodot\n\\bigodot  \\textstyle\\bigodot\n\n\n\\bigotimes\n\\bigotimes  \\textstyle\\bigotimes\n\n\n\\bigoplus\n\\bigoplus  \\textstyle\\bigoplus\n\n\n\\biguplus\n\\biguplus  \\textstyle\\biguplus\n\n"},{"type":"post","id":"静态版rubycrystal语言试用","title":"静态版Ruby？Crystal语言试用","url":"/blog/静态版rubycrystal语言试用/","content":"前几天在思考，Python 和 JS 都拥抱了类型检查（类型注释），但是 Ruby 却只能用 Sorbet 这样的影响性能的类型检查器（Ruby 没有官方的类型检查工具，引入静态类型检查的 gem 反而降低了性能），在搜索中找到了 Crystal 这门语言。\nhttps://crystal-lang.org/\n看描述我就惊艳到了：作为一个静态语言，Crystal 居然长得这么像 Ruby，于是本着不妨玩玩的想法，我进行了 Crystal 的初试。\n# A very basic HTTP server\nrequire \"http/server\"\n\nserver = HTTP::Server.new do |context|\n  context.response.content_type = \"text/plain\"\n  context.response.print \"Hello world, got #{context.request.path}!\"\nend\n\naddress = server.bind_tcp(8080)\nputs \"Listening on http://#{address}\"\n\n# This call blocks until the process is terminated\nserver.listen\n\n简介（翻译自 Github README）\n目标\nCrystal 是具有以下目标的编程语言：\n\n和 Ruby 相似（但不要求兼容）的语法\n静态类型检查，但不要求处处指定变量或者方法的类型\n可以 call C 代码\n对编译时进行评估和生成代码，避免 boilerplate code.\n编译成高效的原生代码\n\n为什么？\n我们喜欢 Ruby 写代码的高效率\n我们也喜欢 C 运行代码的高效率\n我们想要集二者所长\n我们想要编译器能理解我们，而不是我们对编译器指定类型\n我们想要完整的面向对象\n而且，我们不想为了让代码跑的更快而去写 C 代码。\n下载安装\n请遵循 RTFM 方法，Read The Fucking Manual\nhttps://crystal-lang.org/install/\n语法\nCrystal 的语法高度类似于 Ruby，建议先学会 Ruby 的语法再说 Crystal。\n这里只提一些比较亮点的东西。\nA+B problem，但是自动泛型\nCrystal 有自动类型推断的功能。也就是说，大部分情况下类型声明可以直接不写，比如这样\ndef add(a, b)\n  a + b\nend\n\n\nputs add(1, 2) # 3\nputs add(\"1\", \"2\") # \"12\"\n这段代码有些类似于 C++这样写\nauto add(auto a, auto b) {\n  return a + b;\n}\n我个人很喜欢 Ruby 和 Crystal 一脉相承的一个想法：程序员的幸福最大化。 Ruby 是这样的，程序员只要负责写的爽就行了，而 Ruby 要考虑的事情就多了（不是）\n让我们看看 Rails 信条 中怎么说\n\n早期 Ruby 的极端邪说就是把程序员的幸福度放到第一位。还把追求幸福置于驱动编程语言与生态圈前进的考量之上。\n然而 Python 可能对于“用一种方法，最好只有一种方法来完成一件事”而感到自豪，而 Ruby 则喜欢自身表现力与巧妙。Java 是饱受软件工程师的强力推崇，Ruby 则在欢迎工具里就附上了自尽的绳子。Smalltalk 专注于消息传递的纯粹性，Ruby 则累积关键字和臃肿的语法构造。\nRuby 与众不同的原因是看重的事情不一样。这些考量，都是为了满足和追求软件工程师的幸福。这些追求导致了与其他编程语言的辩论，也打开了主流文化对于究竟什么是软件工程师，以及应该如何应对软件工程师的认知。\nRuby 不仅承认，而且从设计上适应和提升软件工程师的感受。不管它们是不足的、奇思妙想的，还是令人喜悦的。Matz 跨越了惊人难度的实践门槛，让机器面有喜色，且富有人性。Ruby 满满是视觉上的错觉，在我们看起来 Ruby 很简单，清晰，也很优美，背后其实是杂技般的错综复杂。这些选择不是没有代价（问问 JRuby 那些试着要对 Ruby 逆向工程的人看看！），这也是为什么，这是很值得赞扬的一件事。\n这是对软件开发另一种愿景的致敬，也决定了我对 Ruby 的钟爱。这不止是简单易用，不仅是美学的元素，也不是单一的技术成就。而是一种愿景，是反文化。Ruby 是一个不适应呆板专业软件开发的人，而是专属于爱好之士的乐土。\n\n回到刚刚的 A+B problem。 即使 C++有 auto （更多静态类型语言会要求你写冗长的泛型），我们为什么不能更进一步呢？传入两个参数，把它们加起来。电脑理所应当可以从参数类型推导结果类型。那我为什么还要写呢？\n我在意的是我写得爽不爽，而不是它是不是符合哪个 RFC 的哪一条。所以，你已经是个成熟的编程语言了，该学会揣摩我到底要写什么类型了。我很喜欢。\n面向对象，真的\nRuby 和 Crystal 都是特别面向对象的语言。比绝大多数自称面向对象的语言还要面向对象。\n举个例子，Ruby/Crystal 支持这样的写法\n3.times do |i|\n  puts i\nend\n# 输出：\n# 0\n# 1\n# 2\n这是因为哪怕是数字 3 也被视为一个对象，是 Object 的子类，可以有自己的 methods\n所以在 Crystal 内可以写出这样极其直观的代码\nputs 3.seconds # 00:00:03\nputs 3.minute  # 00:03:00\nputs 3.hours   # 03:00:00\nputs 3.years   # Time::MonthSpan(@value=36)\n这些也可以传入到 sleep 中作为参数。sleep 3.seconds 即为 sleep3 秒，所有人一眼就能看懂，再也不用担心什么 sleep 传入的int参数到底是毫秒还是秒的问题。\n相似的，由于一切皆对象，可以轻松的这样把一个对象转换为 JSON：\nrequire \"json\"\n\nputs (\n  {\n    a: 1,\n    b: 2,\n    c: {\n      a: 2,\n      b: [1,2,3,4, {\n        str: \"hello\"\n      }]\n    }\n  }.to_json\n)\n\n# {\"a\":1,\"b\":2,\"c\":{\"a\":2,\"b\":[1,2,3,4,{\"str\":\"hello\"}]}}\n缺点\nCrystal 目前的生态还有问题，vscode 插件甚至无法做到优秀的代码补全和类型检查。好在编译时 Crystal 会报告你的类型错误，呃（）\n速度测试\n测试代码：欧拉筛素数，数量级 1e8\ndef get_primes(n)\n  isnt_prime = Array.new(n + 1, false)\n  res = [] of Int32\n  isnt_prime.each_index do |val|\n    next if val < 2\n    next if isnt_prime[val] == true\n    (val * 2..n).step val do |id|\n      isnt_prime[id] = true\n    end\n    res << val\n  end\n  res\nend\n\nputs \"Start calculating...\"\nt1 = Time.monotonic\nresu = get_primes(100000000)\nt2 = Time.monotonic\nputs resu[..100]\nputs t2 - t1\n$ crystal build .\\prime.cr --release\n$ .\\prime.exe\nStart calculating...\n[2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97, 101, 103, 107, 109, 113, 127, 131, 137, 139, 149, 151, 157, 163, 167, 173, 179, 181, 191, 193, 197, 199, 211, 223, 227, 229, 233, 239, 241, 251, 257, 263, 269, 271, 277, 281, 283, 293, 307, 311, 313, 317, 331, 337, 347, 349, 353, 359, 367, 373, 379, 383, 389, 397, 401, 409, 419, 421, 431, 433, 439, 443, 449, 457, 461, 463, 467, 479, 487, 491, 499, 503, 509, 521, 523, 541, 547]\n00:00:01.156142200\n相同框架改写的代码，Crystal 用时 1.2 秒，C++用时 1.2 秒，nodejs 用时 7.9 秒，ruby 用时 16.5 秒，python 用时 22 秒\nCrystal 在这个素数筛上还是非常接近 C++ 的速度的"},{"type":"post","id":"查看你的misskey存档","title":"查看你的Misskey存档！","url":"/blog/查看你的misskey存档/","content":"简而言之，我写了一个可以查看Misskey/Firefish/Sharkey/…等Misskey系软件导出帖子存档的工具！\n网址： https://lhcfl.github.io/misskey-archive-viewer-web\n源代码： https://github.com/Lhcfl/misskey-archive-viewer"},{"type":"post","id":"gotofediverse","title":"从中心化平台跑路：迁移到联邦宇宙（Fediverse）","url":"/blog/gotofediverse/","content":"\n\n X (Twitter) 的一则公告，要求特定地区的新用户为使用 X 付费 https://x.com/Support/status/1714429406192582896 \n\n \n绪言\n2023 年 10 月 18 日， X (Twitter) 发布了一则公告，宣布他们在进行一项“测试”：在新西兰和菲律宾注册的新用户必须支付 $1 的年费才能在 X (twitter) 上和人互动。并且“在此测试中，现有用户不受影响。”，换而言之，测试结束以后现有用户受不受影响还不知道呢。\n而这并不是第一次。自从 Elon Musk 买下 Twitter 以后，他擅自对 Twitter 进行了无数的更改，这些更改很多都只是他自己的想法，无视用户的体验，比如：\n\n2 月，调整 API 接口规范，限制开发者免费访问数量，并随即推出了三种不同层级的 API 接口服务，分为免费、基础版和企业版三档。免费版仅用于测试；具有少量访问权限的基础版月费为 100 美元（约人民币 723 元），推特称目标客户主要为爱好者（有人对此非常愤怒：在哪个星球上会有“爱好者”支付 100 美元每月的费用？这简直就是疯子1 ）；而针对大规模商业项目的企业版，推特并未公开其订阅费用，有消息指出该服务月费至少在 4.2 万美元（约人民币 30.4 万元）以上。\n\n\n\n4 月，把 Twitter 的 Logo 换成狗狗币的图标，拿 Twitter 的标志为狗狗币打广告。\n\n\n7 月 3 日，宣布将调整推特用户浏览权限，非认证（花钱购买蓝标）老用户每日浏览推文上限为 1000 条，新用户 500 条；已认证用户的浏览上限则为 10000 条。这直接导致了大批用户转向其他社交平台。大量推特画师集体入驻微博一事在中文互联网世界受到关注，相关微博话题阅读数过千万。\n\n\n7 月 24 日，Twitter 宣布告别最经典的小蓝鸟标志，将 Logo 更改为 “X”。\n\n\n有人说，“他就像在做一场大型社会实验，正在消除所有让人感到安定的元素，加入所有能够让混乱加剧的元素”2。而且这一切完全合理合法，因为 Twitter 被他买下来了。\n这促使我写下这篇文章：早该跑路了！如果之前的 Twitter 还努力营造一种“为了所有人”的印象，重视用户的黏性，Elon Musk 的肆意妄为无疑是宣告 Twitter 终究是一个由公司掌握的营利性平台，而任何这样的大型中心化平台都不可避免的被少数人控制。国内平台尤甚，The big brother 可以随意获取你的隐私，审查你的言论 (censorship)，无需理由就能禁言、封禁你的账户，随意关闭任何回答的评论区。你真的愿意让你使用社交平台的权利被拿捏在它们手中吗？\n中心化之恶\n让我们从国外视角移动到国内，再看另一些典型的中心化服务。我将展示中心化的服务们是怎么努力一步步的抢夺、占满我们的生活的。\n非你，即我\n相信你一定用过 QQ 和微信。即使它们同是腾讯公司的项目，你用 QQ 也没法和使用微信的好友聊天。QQ 和微信是两个完全不同的世界，哪怕它们都是即时通讯类社交软件，都有自己的社交服务（QQ 空间，微信朋友圈），有极其类似的功能，隶属于同一个公司，它们就是不能互相通信。 如果你喜欢用 QQ，但你的老师、领导、甲方，等都在用微信，对不起，你必须也去注册一个微信才能和他们沟通。\n你是否遇到过，微信就像是饕餮一样，贪婪的吞吃你的手机空间。同一个文件，仅仅因为你转发一次，就多在你的手机里保存一份。明明把所有图片都保存到本地了，以至于轻松占据你 10G 多的内部存储，你想翻几天前的图片/消息时，微信却告诉你：图片/文件已过期。国外的即时聊天工具大多都可以发送简单的格式，比如粗体、斜体，微信和 QQ 毫不支持。甚至微信可以随意封禁你的账号，哪怕你的微信里还有未取出的零钱；你在 QQ 发出的图片别人可能会直接看不到，而你毫无意识。\n\n\n 微信占用用户巨大的存储空间。图源 https://www.zhihu.com/question/616494153/answer/3173414541 \n\n于是你想，你可以不用吗？\n对不起，不可以。\n因为垄断的中心化平台根本不在乎你的感受。你想不用微信，你可以不用微信吗？你的朋友，你的家人，你的上级，你的同事，大家都在用微信。你不用，是你承受损失，而微信是完全没有什么损失的。没有你一个人，它还有几亿用户，为什么要在乎你的看法？有本事你走啊？\n为什么我在第一段强调“它们不能互相通信”呢？因为你拥有选择权利极其重要。微信和 QQ 是两个不同的团队，即使微信只能和 QQ 互通，你认为微信的客户端做的不好，就能逃向 QQ，就能更多的给 QQ 贡献用户，让 QQ 的团队获得更好的绩效，只有这才能让微信的开发团队感到切身的压力，让他们听你的意见。\n是你在用他们的 App，不是他们在用你。\n无限审查\n或者，你可能有一个微博账户。你是一个关心世界大事的人，最近你得知，关于日本往海水里排放核废水这件事，日本福岛当地最大港口爆发了抗议集会。你心想，这不是说明日本的行为并没有得到全国人的支持，很多日本人激烈反对和抵制，这相当于间接给我们声援吗！于是你轻点转发，附上话题，#日本福岛当地最大港口爆发抗议集会 。你希望这样能让更多人看到这件事——\n然后你的微博没了。\n这个话题不仅仅从热搜榜上撤下，还整个消失。\n\n\n环球时报：日本福岛当地最大港口爆发抗议集会\n\n微博上该话题被屏蔽\n\n你不明白，这可是人民日报发的，怎么回事？\n后来微博 CEO 出来回应，他说话题“日本福岛当地最大港口爆发抗议集会”被夹是因为命中了“口爆”这个审核关键词。\n事出突然，他可能忘了口爆是禁词，中文直接发后被限流，于是半小时后，他又把“口爆”改成拼音首字母“KB”。\n\n\n\n在中心化平台你并不拥有你的账号。平台可以随意对你封禁、禁言，不需要任何理由就可以对你的言论限流，可以让你以为发出来的内容实际上仅仅只有你自己可见。或者例如知乎，作为一个内容创作平台，知乎可以随意删除你的文章、回答，让你的心血无人响应。推送的时间流操纵热点，它们想要谁能火，就能让谁被曝光。同样的，如果有话题被认为是不好的，它们也能让话题直接消失。而你，无法反抗，因为只此一家。\n平台和你，本来应该是互利的。平台没有要求你付费，为你提供服务器，存放你的内容。你无偿的为平台贡献流量，给了品台通过广告、宣传获得收入的机会。但巨大的平台，这样的互利关系逐渐倾斜。平台平白地多了一项筹码：你的社交圈/内容被掌握在平台手上，你想走就得掂量掂量，你的所有朋友都还在这个平台，你走了怎么联系？你不再拥有你的社交，而是被你的社交绑架。\n什么是联邦，和什么是联邦宇宙\n看到这里，你可能会问：那你说了这么多，怎么解决这个问题呢？什么是联邦宇宙？它能为我们带来什么？\n要说明这个，我们首先谈一下什么是联邦（Federation）\n联邦 (Federation)\n联邦听起来是一个很高大上的词，但其实你很有可能已经使用过一种联邦服务：电子邮件。\n现在电子邮件已经有了悠久的历史，也因为种种缺陷而在今天日趋衰落，因此，你可能没怎么用过电子邮件。但你大概应该还是知道电子邮件的一些基本规则：\n\n\n任何邮箱都可以彼此通讯。只要知道对方的电子邮件地址，你用 QQ 邮箱可以给 163 邮箱发消息，也可以给 Outlook 发消息，也可以给 Gmail 发消息。\n\n\n邮箱服务不掌握在一个人手中。如果你是大学生，你可能会发现学校会为你分配一个 edu 邮箱。edu 邮箱也可以和别的任何邮箱沟通——比如，有的班级会要求你用 edu 邮箱把作业交给用 163 邮箱的助教。\n你可能也经常会收到各种网站的验证电子邮件，如果你注意看他们的发信人邮件地址，会一般都来自自己的网址，而不是某个大型的电子邮件平台，例如 Outlook，Gmail。换言之，任何人都有资格建立自己的邮件服务。\n\n\n\n\n一封来自 Cloudflare 的通知邮件，发信人是 noreply@notify.cloudflare.com \n\n电子邮件几乎没有审查。一方面，当然是因为使用电子邮件的人已经少了，另一方面，看到上面所说了吗？邮箱服务不掌握在一个人手中。假如 QQ 邮箱突然设置规定，包含“口爆”的邮件都不准发送，你可以直接转手就注册一个 outlook 邮箱，反正你还是可以和之前的联系人沟通，只要告诉他们你换邮件地址了就行。\n这就是区别： 中心化服务像是一个俱乐部，只有俱乐部的成员可以彼此交流，俱乐部的主人对你有极大的权利，可以干涉你和其他俱乐部成员的关系，可以随时让你离开俱乐部。而联邦服务像很多组相互联系的俱乐部，加入了任何一个联邦平台，你就可以和整个联邦里的所有俱乐部沟通。如果你所在的俱乐部赶你走，干涉你和别人的交流，你大可以直接就走，因为还有无数的俱乐部与你所在的俱乐部相连。在现实中，就如你在一个 Mastodon 实例上的所有关注列表和被关注列表可以迁移到另一个 Pleroma 实例。\n\n\n从左到右依次是：中心式服务，联邦式服务，分布式服务 \n\n联邦 是去中心化的一种形式。在联邦中，不是所有人共同使用一个中心服务，而是使用多个不限人数的服务器。你可以自由的选择加入联邦的服务器，任何一个服务器都没法代表整个联邦。虽然相比起最去中心化的分布式服务，联邦还保留了服务器，但相比中心式服务，你拥有对服务器的自由选择权，这是对服务器的拥有者的一种制衡。服务器拥有者虽然还是可以在自己的服务器上制定各种规则，但是 TA 需要先想一想，用户会不会因此去往其他站点？其他站点会不会因为这种规则屏蔽你？有所顾虑，便能维护用户和提供服务者的权衡。\n联邦宇宙 (Fediverse)\n严格的来说，我觉得联邦宇宙这个翻译有些歧义。因为联邦宇宙并不是所有联邦式服务的总称，而是使用一些特定协议的联邦服务的集体。使用不同协议的联邦服务，比如电子邮件，就并不含括在内。不过我们还是采用这个翻译。\n在联邦宇宙，每个加入联邦宇宙的站点都可以独立运作。和中心式网站一样，人们可以在上面注册、发布消息、上传图片、互相聊天。但与中心式网站不同的是，联邦宇宙的网站之间可以互动，让不同站点的用户互相交流。就好像只要你知道他们的电子邮件地址，你就可以从你 QQ 邮箱帐户发送电子邮件给使用 Outlook、163、Protonmail 等任何其他电子邮件供应商的朋友一样，在联邦宇宙里，你可以对任何加入联邦的网站上的任何人进行无缝交流——除非你所在的实例被对方屏蔽了。\n联邦宇宙使用多种协议进行互通，其中使用人数最多的软件 Mastodon 主要使用的是 ActivityPub 协议。如果你是一名开发者，可以试试让你的服务支持 ActivityPub —— 这样，你的服务就加入联邦宇宙了。就是这样简单。\n加入联邦宇宙\n如果你也希望你的社交应该掌握在自己的手中，不希望被中心化商业平台控制，这里有一份加入联邦宇宙的指南：\n选择一个实例（服务器）\n联邦宇宙中，每一个网站都被称为一个实例(instance)。每个实例都有自己的特征。有的实例主要是同一个地区的人，也有以爱好、职业、身份等乃至朋友关系维系的实例。\n牢记每个实例都是与整个联邦宇宙相连的，所以小实例与大实例其实没有很大的区别，选择你喜欢的就行。这里给出一些大实例和小实例的比较，主要是本人的经验之谈：\n\n\n大实例的本站时间线一般会有很多人，小实例的本站时间线就基本上只有几个人的帖子。当然，联邦时间线（基本能看到整个联邦宇宙发的）是大家都有的。\n\n\n大实例一般更不容易跑路，小实例有可能资金不够就跑路\n\n\n大实例可能屁事多，比如某些站的站长出过出售数据的争议，也有的大实例可能会被墙内特别监控，小实例这方面的风险小一些。\n\n\n你能加入的小实例管理员一般好说话，可以直接和管理员 py 交易（雾）来优化实例的一些内容。比如提升嘟文字数（mastodon），增加第三方功能之类的。大实例可能不会理你。\n\n\n关于个人推荐的一些联邦宇宙实例，请参见 附录\n如果你觉得一个实例都不适合你，你还可以选择自建实例：\n（注意，联邦宇宙有很多开源前端；如果你作为实例主觉得下面的软件的外貌不符合你的审美，你可以替换它们的前端）\n\nPleroma：Installing on Linux using OTP releases - Pleroma Documentation\n一个相当不错的联邦宇宙软件，个人感觉比 Mastodon 可配置性好太多了\nMastodon Glitch Edition：Introduction | Mastodon Glitch Edition (glitch-soc.github.io)\n我推荐安装 Mastodon 的 Glitch Edition，给管理员和用户都提供了更多的配置。原版 Mastodon 的配置太少了）\n原版 Mastodon：从源中安装 - Mastodon documentation (joinmastodon.org)\n原版 Mastodon 最大的缺点是可配置项惊人的少，我不是很推荐，尤其是Mastodon 还存在严重的一家独大问题\nMisskey：创建您自己的 Misskey 实例 | Misskey Hub (misskey-hub.net)\n最大的优点就是它可爱，它真的很好看\nFirefish：Firefish (joinfirefish.org)\nMisskey 的 Fork，保留了 Misskey 的一大优点：界面很好看\nGoToSocial：Installation - GoToSocial Documentation\n这是一个轻量级的联邦宇宙软件，卖点就是轻量级，你能直接安装在有内网穿透的家里的旧电脑上，或者装在树莓派之类的东西上。\n\n你在联邦宇宙上的身份\n在加入联邦宇宙以后，你就有了一个在联邦宇宙上的唯一标识身份，也就是你的用户名。它大概长这样：\n@username@example.com\n任何人都可以用这个联邦宇宙用户名在自己的实例上搜到你，然后关注你。你也可以这样搜索别人，关注别人。\n探索联邦宇宙\n关于各个联邦宇宙软件怎么使用，我想聪明的你一定能摸索出来。这里以 Mastodon 为例贴 bangdream.space 的一条 blog：Mastodon（长毛象）中文使用讲解/教程 – 炸邦裂梦乐团信息站 (bangdream.space)\n下载客户端\n无论是 Mastodon 还是 Pleroma，它们的界面都多少有点不够爽。Misskey 除外，它的网页版太好看了。\n所以我建议大家如果想要手机上刷联邦宇宙，建议下载第三方的客户端。一般的客户端都是不仅支持 Mastodon 还支持别的联邦宇宙软件的。这里推荐：\nAndroid\nMegalodon 和 Moshidon\nhttps://play.google.com/store/apps/details?id=org.joinmastodon.android.sk\nhttps://play.google.com/store/apps/details?id=org.joinmastodon.android.moshinda\n这两个软件似乎是同一个软件的两个 fork，界面设计不能说是非常相像，只能说是一模一样，几乎只有图标有区别。\n非常圆润、美观，功能非常舒服。可以关注别的站点的本站时间线，这是一个非常吸引我的功能。\nTusky\nhttps://play.google.com/store/apps/details?id=com.keylesspalace.tusky\n和 Mastodon 的官方移动版网页有点类似，方方的，适合审美是方方正正的东西的人。\nIOS\nMammoth\nhttps://apps.apple.com/app/mammoth-for-mastodon/id1667573899\nMammoth 的界面有点像 Twitter，界面设计非常的流畅，简洁，美观，很适合 ipad 用户\ntooot\nhttps://apps.apple.com/app/tooot/id1549772269\ntooot 更加适合 iphone 一点，没有对 ipad 进行优化。界面也很美观。\n联邦宇宙常见误区\n实例不是越大越好\n大实例有大实例的好处，小实例有小实例的好处，个人实例有个人实例的好处。但超大型实例除外：无论如何，像 mastodon.social 这样的超级实例对整个联邦宇宙有害。我不推荐任何人去注册 mastodon.social 。\n其一，很多联邦宇宙软件的设计，例如 Mastodon，不适合超大型实例。像 mastodon.social 那么大的实例，其请求数非常的多，会导致后台容易出现阻塞。使用超大型实例的用户可能会遇到一些奇怪的地方的 bug，比如本站时间线刷不到自己的帖子，不能及时看到对方的回复3超大型实例的使用体验其实是最低的。\n其二，超大型实例很有可能成为黑客 DDoS 攻击的目标。对于 mastodon.social 这个超大型实例，把它打倒，就能让 10% 的联邦宇宙用户连不上联邦宇宙，这对于黑客来说其实很诱人。你也不想偶尔就用不了一次服务吧？\n其三，超大型实例有挟持，或者脱离联邦宇宙的危险。这不是危言耸听，在这篇文章中，就已经介绍了 identi.ca 脱离 OStatus 协议变成 pump.io 后对于其他 Ostatus 协议网站造成巨大影响的先例。尤其是 Mastodon 的开发者还有独自掌握自己的软件的倾向。\n当一个实例的用户数达到 10 万，你就不应该考虑它了。\n联邦宇宙不只有 Mastodon\n你可能经常听到“来 Mastodon 上找我”、“象友”、“禁止转出长毛象”这样的词。但请注意，Mastodon（长毛象）只是联邦宇宙的一部分。 其他不同的软件，例如 Pleroma，Misskey，Plume，装了 ActivityPub 插件的 Wordpress，甚至是某人配置的个人博客，都能与整个联邦宇宙连接，并与 Mastodon 无缝互动。对联邦宇宙的其他软件用户这样有意无意的忽视是对联邦宇宙的健壮性的伤害。“禁止转出长毛象”这种词尤甚，可能会冒犯到使用其他软件的用户。\n请尽量避免用 Mastodon 代指整个联邦宇宙。事实上，Mastodon 存在严重的一家独大问题。还记得我们为什么反对中心化吗？Mastodon 一家独大，开发者敌视定制性，有意忽略其他联邦宇宙软件，对 Mastodon 软件过度的控制4，实际上隐患很大。我推荐新用户选择非 Mastodon 的软件。（而且事实上，作为开源软件，其他软件也可以使用 Mastodon 的前端。）\n\n\n图源 https://fediverse.observer/stats\n\n脚注\n\n\nRobert on Discourse Meta: https://meta.discourse.org/t/bye-bye-embedded-tweet-previews/261708/10 ↩\n\n\n告别小蓝鸟，推特正式启用「X」标志，如何看待此举？ - 刘轩的回答 - 知乎 ↩\n\n\nhttps://www.reddit.com/r/Mastodon/comments/16zpa8w/mastodonsocialtoo_big, https://www.reddit.com/r/Mastodon/comments/16zpa8w/comment/k4lrf1e ↩\n\n\nMastodon 的一些问题\n\n在 Mastodon 的官网中故意没有提其他软件，相比之下，Pleroma 和 Misskey 都提到了 Mastodon 和其他软件。 https://kazv.moe/objects/7ab9df6a-1b1a-4e65-b37f-2f2fc975098b\n在源代码中将 500 字嘟文限制写死，管理员无法修改，除非装非官方版本 https://kazv.moe/objects/a86fe86e-3365-413c-a777-c9aab23834e5\n在文档中提到“有意禁止了在数据库中搜索任意内容” https://docs.joinmastodon.org/admin/elasticsearch/ , 并不重视站点管理员的想法，很多功能都完全由开发者写死 https://blog.bgme.me/posts/2020/my-understanding-of-microblogging/#section-6\n\n↩\n\n\n"},{"type":"post","id":"mastodon-monoculture-problem","title":"Mastodon的单一文化问题","url":"/blog/mastodon-monoculture-problem/","content":"\n译者注：\n本文是 Michał “rysiek” Woźniak 的博客 Mastodon monoculture problem 的翻译。 source: https://rys.io/en/168.html\n对于不太懂文中的名词的人，译者额外做出一些解释：\n\n联邦宇宙：Fediverse，是使用一些协议彼此链接的一系列网站/服务（被称为“实例”）的总称。在联邦宇宙，你在任何一个实例上拥有账号，你就能访问几乎整个联邦宇宙的所有内容——实例有特殊规则的时候除外。\n实例：联邦宇宙上的单独一个网站/服务。\n实例软件：运行实例使用的软件，比如 Mastodon。用一种实例软件可以搭建很多个实例。\nActivityPub 协议：一种旨在让不同的实例之间可以互相连接，共通账号的协议。联邦宇宙实例很多使用的就是 ActivityPub 协议。\nMastodon：连接到联邦宇宙的一个微博类社交媒体软件，有类似 Twitter 的设计。\n\n依照 Michał “rysiek” Woźniak 的原文 (https://rys.io/en/168.html)，本文以 CC-BY-SA 4.0 协议发布。您可以自由地共享、演绎本作品，但是必须署名、以相同方式共享 - 如果您再混合、转换或者基于本作品进行创作，您必须基于与原先许可协议相同的许可协议分发您贡献的作品。\n\n\nMastodon 非营利组织的首席执行官兼 Mastodon 软件的首席开发者 Eugen Rochko（在联邦宇宙上被称为 Gargron）最近的举动让一些人担心 Mastodon 该软件项目，同时也是该非盈利组织对联邦宇宙的其余部分造成的巨大影响。\n确实。我们就是应该担心。\n到目前为止，联邦宇宙上大多数人都在使用 Mastodon 软件。 截至撰写本文时，最大的实例 mastodon.social 拥有超过 200,000 个活跃帐户。 这意味着这单独一个实例上涵括了整个联邦宇宙的大约 1/10。 更糟糕的是，Mastodon 软件经常被认为是整个社交网络，这掩盖了一个真相： Fediverse 是一个由更多样化的软件们组成的更广泛的系统。\n现在它就已经产生了糟糕的后果，而且以后可能会更糟。 让我困扰的还有，我以前也见过这样的情况：\n正如 OStatus 宇宙所示\n几年前，我在联邦宇宙的前身有一个账户。 它主要基于 StatusNet 软件（后来更名为 GNU Social）和 OStatus 协议。 最大的实例是 identi.ca ——笔者在那里拥有自己的账户。 同时还有很多其他实例、其他软件项目也实现了 OStatus 协议——例如 Friendica。\n出于本博文的需要，我们将该社交网络称为“OStatus 宇宙”。\n与今天的联邦宇宙相比，OStatus 宇宙是微不足道的。 我没有具体的数字，但我的粗略估计是，即使在最活跃的时候，也只有大约 100,000 到 200,000 个活跃帐户（如果你有实际数字，请告诉我，我将很乐意更新这篇博客）。 我也没有 identi.ca 上用户数目的确切数字，但我粗略估计它有 10,000 到 20,000 个活跃帐户。\n对，刚好也是整个社交网络的 1/10。\nOStatus 宇宙虽小但很活跃。我们在上面有讨论、线程回复（threads）和话题标签（hashtags）。 它早在 Mastodon 软件项目实现 Group 的十年前就实现了群组。它有桌面应用程序——我仍然怀念 Choqok 的可用性！ 甚至经过一番唠叨后，我还说服了波兰的一个政府部门在那里设立官方办事处。 据我所知，这是最早的政府机构在自由软件驱动的去中心化社交网络上拥有官方账户的例子。\nIdentipocalypse (identi 的末日)\n然后有一天，identi.ca 的管理员（也是 StatusNet 软件的原始创建者）Evan Prodromou 决定将其重构为一项新服务，即 pump.io。 他们希望新软件更好、更精简。 他们创建了一个新协议，因为 OStatus 协议有非常现实的限制。\n只有一个问题：新协议与 OStatus 宇宙的其它部分不兼容。它把这个社交网络撕碎了。\n拥有 identi.ca 帐户的用户与所有其他 OStatus 实例失去了连接。 在其它实例上拥有帐户的人与 identi.ca 上的人失去了联系，并且其中一些人在 OStatus 宇宙中非常受欢迎（听起来很熟悉？..）。\n事实证明，如果一个实例占据了整个社交网络的 1/10，那么它就会承载太多的社交联系。尽管的确存在其他实例，但突然间大量活跃用户消失了。一些群组瞬间就变得安安静静。 即使有人在不同的实例上有一个帐户，并且在其他实例上有联系人，很多熟悉的面孔也会消失。 于是此后不久我就停止使用它了。\n从笔者的角度来看，就这么一项行为，就使得我们在推广去中心化社交媒体方面至少倒退了五年甚至十年。 identi.ca 的重构不仅在社交关系意义上破坏了 OStatus 宇宙，而且在协议和开发者社区意义上也是。 正如 Pettter，一位 OStatus 资深人士所说：\n\n我认为，这个巨变带来的影响是，它不仅切断了社交联系，还导致了协议变得支离破碎，一次又一次地让重建联合社交网络的基本架构的努力付诸东流。 也许这是他们重新聚集在一起设计 ActivityPub 的必要步骤，但我个人不这么认为。\n\n当然，Evan 完全有权利这样做，毕竟这是他用自己的钱、按照自己的条款无偿经营的一项服务。 但这并不能改变它割裂了 OStatus 宇宙的事实。\n我认为我们需要从这段历史中吸取教训。我们应该担心 mastodon.social 的庞大规模。 我们应该为联邦宇宙上 Mastodon 软件明显的单一文化感到担忧。 我们还应该担心将整个联邦宇宙与“Mastodon”等同起来。\n做大的代价\n发展到像 mastodon.social 这样的规模，需要付出相当的成本和风险。 这些成本，尤其是那些风险，既针对该实例本身，也针对更广泛的 Fediverse。\nFediverse 上的审核很大程度上以实例为中心。 单个巨大的实例很难有效地管理，特别是如果它开放注册（就像 mastodon.social 目前所做的那样）。 作为直接在官方移动应用程序中推广的旗舰实例，它吸引了大量新注册，其中包括不少不太友好的用户。\n同时，这也使得其他实例的管理员和版主更难以做出有关 mastodon.social 的审核决定。\n如果其它实例的管理员认为 mastodon.social 出于某种原因缺乏管理，他们是否应该静音该实例，甚至将其屏蔽（显然，有些人已经这样做了），代价是让本站的用户无法联络许多在 mastodon.social 有账户的受欢迎的人？或者、他们就应该冒着让自己的社区面临潜在有害行为的风险，保留这种联络的可能性吗？\nmastodon.social 的庞大规模使得任何其他实例的管理决策成为了一件大事。 这是某种形式上的特权：“当然，如果您不喜欢我们的管理方式，您可以封掉我们，但如果您实例上的用户无法访问整个联邦宇宙的 1/10，那将是一种耻辱！” 正如 GoToSocial 网站所说：\n\n我们也不认为拥有成千上万用户的旗舰实例对联邦宇宙来说很有好处，因为它们会导致中心化，并且很容易变得“太大而不敢屏蔽”。\n\n请注意，我并不是说这种权力动态是有意识地、有目的地利用的！ 但不可否认，它是存在的。\n作为一个巨大的旗舰实例也意味着 mastodon.social 更有可能成为恶意行为的目标。 例如，在过去几个月中，它多次受到 DDoS 攻击，并且好几次都因为这个而无法访问。 联邦系统的可靠性依赖于消除大的故障点，而 mastodon.social 现在已经是一个巨大的故障点了。\n该实例的规模让它成为了一个诱人的攻击目标，这也意味着它需要做出某些艰难的选择。 例如，由于经常成为 DDoS 的目标，它现在由 Fastly 保护。 从隐私角度和互联网基础设施中心化的角度，这是一个问题。 这也是较小的实例完全避免的一个问题，因为它们很小，很少有人会无聊到 DDoS 攻击它们。\n（译者注：这方面译者非常存疑，事实上小实例也经常受到随机的 DDoS 攻击。）\n明显的单一文化\n虽然联邦宇宙并不完全是单一文化，但它太接近单一文化了，令人感到不舒服。 Mastodon 非营利组织对整个联邦机构有着巨大的影响力。 这让使用社交网络的人、Mastodon 软件和其他实例软件项目的开发人员以及实例管理员感到紧张。\nMastodon 既不是联邦宇宙上唯一的平台软件，也不是第一个。 例如，Friendica 已经存在了十五年了，早在 Mastodon 软件的第一次 git 提交之前就已经存在。一些现在的联邦宇宙中运行着的 Friendica 实例（例如 pirati.ca）在十年前曾是 OStatus 宇宙的一部分！\n但是很多人在将整个联邦宇宙称为“Mastodon”，说的跟 Fediverse 上只存在 Mastodon 软件一样。 这导致人们经常要求 Mastodon 实现一些新功能，但其实这些功能已经由其他实例软件实现了。 Calckey 已经有引用嘟文（带评转发）功能了。 Friendica 也早就有线程对话和富文本。\n将 Mastodon 与整个联邦宇宙等同起来对于 Mastodon 软件开发人员来说也是不利的。 这导致他们面临着被要求实现不完全适合 Mastodon 软件的功能的压力。 或者，有时候他们不得不两群吵吵囔囔的用户打交道，一群人想要某个功能，另一群人又觉得这个功能太大，实现不了。通过清楚地划出一条界限，并引导人们使用可能更适合他们的用例的其他实例软件，许多此类情况可能会更容易处理。\n最后，Mastodon 是目前为止（按活跃用户和实例数量衡量）最流行的 ActivityPub 协议实现。 每个实现都有其自己的特性。 随着时间的推移和新功能的实现，Mastodon 的实现可能会进一步偏离严格的规范。 毕竟，这很诱人：如果你怎么弄都是龙头老大，为什么要艰难的去实现标准协议呢？\n如果这真的发生了，其他所有实现是否都必须跟随它，从而变得随波逐流，没有对于事实标准的话语权？ 这是否会在 Mastodon 软件开发人员和其他实例软件项目的开发人员之间造成更多紧张关系？\n“Mastodon 错过了 XX 功能”的最优解并不总是“Mastodon 应该实现 XX 功能”。 通常来说，最好使用更适合特定任务或社区的不同实例软件。或者开发一个扩展协议，允许尽可能多的实例可靠地实现特别流行的功能。\n但这只有在每个人都清楚 Mastodon 只是更大的社交网络：联邦宇宙 的一部分的情况下才有效。 而且，对实例软件、单个实例以及移动应用程序而言，我们现在本来就有很多选择。\n遗憾的是，这似乎与 Eugen 最近的决定背道而驰：它们打算导向自上而下（不是完全垂直整合，但倾向于垂直整合）的官方 Mastodon 移动应用程序模型，以推广他们最大的 mastodon.social 实例。 在我看来，这很值得担忧。\n更好的方式\n我想澄清的是，我在这里并不是主张停止 Mastodon 的开发并且从不实现任何新功能。 我也同意注册流程需要比以前更好、更简化，我也同意需要实施大量 UI/UX 更改。 但所有这一切都可以并且理应以提高联邦宇宙弹性的方式进行，而不是破坏它。\n必要的更改\n我觉得 Mastodon 和联邦宇宙必须要更改的地方是：\n\n现在关闭 mastodon.social 上的注册\n对于联邦宇宙的其他部分来说，这个实例已经太大了，所带来的风险也太大了。\n使用户迁移更加容易，甚至可以跨实例迁移\n在 Mastodon 上，个人资料迁移目前仅移动关注者。 您关注的人、收藏夹、屏蔽和隐藏列表都可以手动移动。 帖子和列表无法移动——这对很多人来说都是一个很大的问题，因此他们就被和他们注册的第一个实例绑在了一起。 这并不是无法克服的——笔者已经迁移了两次个人账户，感觉也很不错。但这种阻力还是太大了。 值得庆幸的是，其他一些实例软件项目也正在努力允许帖子迁移。 但这不会是一个快速而简单的解决方案，因为 ActivityPub 的设计使得在实例之间移动帖子变得非常困难。（译注：Sharkey 和 Firefish 实现了这项功能）\n默认情况下，官方应用程序应该随机从一些可信的实例中选一个推荐给新用户注册\n至少其中一些实例不应由 Mastodon 非营利组织控制。 理想情况下，某些实例应该运行不同的实例软件，只要它使用兼容的客户端 API。\n\n我能做什么？\n作为联邦宇宙的一员，我们可以做以下事情：\n\n如果您在 mastodon.social 上有帐户，请考虑迁移走\n的确这是有点艰难的一大步，但也是你可以做的最直接有助于解决问题的事情。 几年前，我从 mastodon.social  迁移过来，再也没回去过。\n考虑使用基于不同软件项目的实例\n越多的人迁移到使用 Mastodon 软件以外的其他实例软件的实例，我们的联邦宇宙就越平衡越有弹性。 例如，我听说很多人都觉得 Calckey 不错。 GoToSocial 看起来也很有趣。\n请记住，联邦宇宙不仅仅是 Mastodon\n语言很重要。 当谈论联邦宇宙时，称其为“Mastodon”只会让我上面提到的问题更难处理。\n如果可以的话，支持 Mastodon 官方项目以外的项目\n至此，Mastodon 软件项目已经拥有众多的贡献者、稳定的开发团队以及足够雄厚的资金，可以安全地持续很长一段时间。这那太棒了！但是，对于其他与联邦宇宙相关的项目，包括独立的移动应用程序或实例软件，它们没有那么受到关注。为了拥有一个多元化、有弹性的联邦宇宙，我们需要确保这些项目也在各个方面得到支持，比如金钱上。\n\n结束语\n首先，联邦宇宙是一个比任何中心化的孤岛更有弹性、更长期可行、更安全、更民主化的社交网络。 即使存在 Mastodon 单一文化问题，它仍然不是（并且不可能 ）由任何单一公司或个人拥有或控制。 我也觉得它比只是在 cosplay 去中心化的社交网络，比如 BlueSky 是一个更好、更安全的选择。\n从某种意义上来说，OStatus 宇宙可以说是联邦宇宙的早期版本； 如前所述，当时属于其中的一些实例仍在运行，并且今天已成为联邦宇宙的一部分。 换句话说，联邦宇宙已经存在了十五年了，尽管它受到了严重的伤害，但它仍然在 identi.ca 的灾难中“幸存下来”，同时见证了 Google+ 的诞生和过早的消逝。\n我确实相信如今的联邦宇宙比 identi.ca 重新部署之前的 OStatus 宇宙更具弹性。 就用户群而言，联邦宇宙至少要多十倍，有数十个不同的实例软件项目和数以万计的活跃实例。还有一些认真的机构对其未来进行了投资。 我们不应该对我上面写的一切感到恐慌。 但我确实认为我们应该防患于未来。\n我不会将恶意归因于 Eugen 最近的行为（比如让官方 Mastodon 应用程序将新人引向 mastodon.social），也不会归因于 Evan 过去的行为（在 pump.io 上重新部署 identi.ca ）。 我认为任何人都不应该这样做。 做好这件事很难，我们都在边走边学，并努力利用有限的时间和有限的资源去做到最好。\nEvan 后来成为 ActivityPub（联邦宇宙运行的协议）的主要创建者之一。 Eugen 发起了 Mastodon 软件项目，我坚信这个项目让联邦宇宙蓬勃发展到了今天的样子。 我真的很欣赏他们的工作，并认识到如果没有人发表意见，在社交媒体空间中做任何事情都是不可能的。\n然而，这并不意味着我们不能仔细思考这些决定，也不应该对此有这些意见。\n\n更新：我（原作者）犯了一个傻傻的错误，mastodon.social 由 Fastly 提供保护，我以为是 CloudFlare。修复了，感谢指出这个错误的人！\n更新 2：衷心感谢 Jorge Maldonado Ventura 提供了这篇博文的西班牙语翻译，并在 CC BY-SA 4.0 下发布。 谢谢！"},{"type":"post","id":"anatolo-math-support","title":"Hexo 博客添加数学支持","url":"/blog/anatolo-math-support/","content":"e^{i\\pi} = -1\n\n数学支持对于个人博客来说我觉得至关重要，但是默认的 Hexo 渲染 Markdown 的引擎 hexo-render-marked 却不支持。本文讲述如何通过更换 Hexo 的 Markdown 渲染引擎的方式让你的博客支持数学。\n\n警告：在开始本指南之前，请确保您位于 hexo 主目录中。\n\n默认的 Hexo 安装将包括一个使用 marked 的 Markdown renderer（渲染器）插件，因此如果要更换，例如更换成本教程使用的 hexo-renderer-markdown-it ，你应该先卸载它。\n$ npm un hexo-renderer-marked --save\n如果您已经删除了默认 renderer 以及您可能添加的其他 renderer，现在可以安全地安装 hexo-renderer-markdown-it\n$ npm i hexo-renderer-markdown-it --save\n安装 markdown-it 数学插件：\n$ npm install katex @renbaoshuo/markdown-it-katex\n在 _config.yml 中添加下列配置：\nmarkdown:\n  preset: \"default\"\n  render:\n    html: true\n    xhtmlOut: false\n    langPrefix: \"language-\"\n    breaks: true\n    linkify: true\n    typographer: true\n    quotes: \"“”‘’\"\n  enable_rules:\n  disable_rules:\n  plugins:\n    - name: \"@renbaoshuo/markdown-it-katex\"\n      options:\n        skipDelimitersCheck: true\n  anchors:\n    level: 2\n    collisionSuffix: \"\"\n    permalink: false\n    permalinkClass: \"header-anchor\"\n    permalinkSide: \"left\"\n    permalinkSymbol: \"¶\"\n    case: 0\n    separator: \"-\"\n  images:\n    lazyload: false\n    prepend_root: false\n    post_asset: false\n  inline: false # https://markdown-it.github.io/markdown-it/#MarkdownIt.renderInline\n可选的，你可能需要去你的主题设置里，添加 KaTeX 样式表：\n<link\n  rel=\"stylesheet\"\n  href=\"https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css\"\n/>\n关于 hexo-renderer-markdown-it 的其他说明，请参考 https://github.com/hexojs/hexo-renderer-markdown-it"},{"type":"post","id":"hitokoto","title":"一言","url":"/blog/hitokoto/","content":"\n这里将会显示一句话\n\n源代码\n<script>\n  fetch(\"https://v1.hitokoto.cn\")\n    .then((response) => response.json())\n    .then((data) => {\n      const hitokoto = document.getElementById(\"hitokoto_text\");\n      hitokoto.href = \"https://hitokoto.cn/?uuid=\" + data.uuid;\n      hitokoto.innerText = data.hitokoto + \"   ——\" + data.from;\n    })\n    .catch(console.error);\n</script>"},{"type":"post","id":"ubuntu-wifi-unable-use","title":"3/26/2020","url":"/blog/ubuntu-wifi-unable-use/","content":"联想电脑 wifi 无法使用，有时只需输入一条命令即可\nsudo modprobe -r ideapad_laptop"},{"type":"post","id":"notesofvim","title":"Vim学习笔记","url":"/blog/notesofvim/","content":"Vim 的学习笔记\n\n\n基础按键\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n按键作用什么都不按 　　　　普通模式i输入模式Esc从输入模式退出：命令模式v可视模式↑上↓下←左→右\n基础命令\n普通模式\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n命令作用:open [file]打开文件:qa!强退:![command]在 shell 执行[command]这条命令:w保存:q退出:set设置:set guifont [font]设置字体为[font]:set guifont [font]:h[number]　　　　设置字体为[font]，字号为[number]dd删除整行[number]dd删除下[number]行u撤销[number]=[方向键]向[方向键]方向[number]行自动缩进r用你下一个输入的字符替换后面一个字符\n可视模式\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n命令作用y　　　　复制p粘贴\n一个方便的.vimrc\nset ts=4                    \"设置tab为4空格\n\nset expandtab               \"用空格替代tab\n\nset nocompatible            \" 关闭 vi 兼容模式\n\nsyntax on                   \" 自动语法高亮\n\nset number                  \" 显示行号\n\nset cursorline              \" 突出显示当前行\n\nset ruler                   \" 打开状态栏标尺\n\nset shiftwidth=4            \" 设定 << 和 >> 命令移动时的宽度为 4\n\nset softtabstop=4           \" 使得按退格键时可以一次删掉 4 个空格\n\ncolorscheme molokai\n\nset nobackup                \" 覆盖文件时不备份\n\nset autochdir               \" 自动切换当前目录为当前文件所在的目录\n\n\"filetype plugin indent on   \" 开启插件\n\nset backupcopy=yes          \" 设置备份时的行为为覆盖\n\nset ignorecase smartcase    \" 搜索时忽略大小写，但在有一个或以上大写字母时仍保持对大小写敏感\n\nset nowrapscan              \" 禁止在搜索到文件两端时重新搜索\n\nset incsearch               \" 输入搜索内容时就显示搜索结果\n\nset hlsearch                \" 搜索时高亮显示被找到的文本\n\nset noerrorbells            \" 关闭错误信息响铃\n\nset novisualbell            \" 关闭使用可视响铃代替呼叫\n\nset t_vb=                   \" 置空错误铃声的终端代码\n\nset magic                   \" 设置魔术\n\nset hidden                  \" 允许在有未保存的修改时切换缓冲区，此时的修改由 vim 负责保存\n\nset guioptions-=T           \" 隐藏工具栏\n\nset guioptions-=m           \" 隐藏菜单栏\n\nset smartindent             \" 开启新行时使用智能自动缩进\n\nset backspace=indent,eol,start\n\n                            \" 不设定在插入状态无法用退格键和 Delete 键删除回车符\n\nset cmdheight=1             \" 设定命令行的行数为 1\n\nset laststatus=2            \" 显示状态栏 (默认值为 1, 无法显示状态栏)\n\nset statusline=\\ %<%F[%1*%M%*%n%R%H]%=\\ %y\\ %0(%{&fileformat}\\ %{&encoding}\\ %c:%l/%L%)\\\n\n                            \" 设置在状态行显示的信息\n\n\"set foldenable              \" 开始折叠\n\"\n\"set foldmethod=syntax       \" 设置语法折叠\n\"\n\"set foldcolumn=0            \" 设置折叠区域的宽度\n\"\n\"setlocal foldlevel=1        \" 设置折叠层数为\n\"\n\"set foldclose=all           \" 设置为自动关闭折叠\n\"\n\"inoremap <space> @=((foldclosed(line('.')) < 0) ? 'zc' : 'zo')<CR>\n\n                            \" 用空格键来开关折叠\n\nset whichwrap+=<,>,[,]\ninoremap ( ()<LEFT>\ninoremap { {}<LEFT>\ninoremap [ []<LEFT>\n\n\" 插件类快捷键\nmap <c-b> :NERDTreeToggle<CR>\n\ninoremap <silent><expr><Tab> pumvisible() ? \"<C-y>\" : coc#pum#visible() ? coc#_select_confirm() : \"<Tab>\"\n\n\" Use vim-plug\n\" Plugged Start\n\" Vim-Plug Start\ncall plug#begin('~/.vim/plugged')\nPlug 'itchyny/lightline.vim'         \" lightline插件底部状态栏\nPlug 'scrooloose/nerdtree'           \" NERDTree\nPlug 'Chiel92/vim-autoformat'\nPlug 'dense-analysis/ale'\nPlug 'neoclide/coc.nvim'\n\ncall plug#end()\n\" Vim-Plug End\n\" autocmd VimEnter * NERDTree\n\n\" Plugged End\n"},{"type":"page","id":"about","title":"About","url":"/about/","content":""},{"type":"page","id":"links","title":"Friends","url":"/links/","content":""},{"type":"tag","title":"碎碎念","url":"/tags/碎碎念/"},{"type":"tag","title":"Decentralized","url":"/tags/Decentralized/"},{"type":"tag","title":"Fediverse","url":"/tags/Fediverse/"},{"type":"tag","title":"Community","url":"/tags/Community/"},{"type":"tag","title":"Linux","url":"/tags/Linux/"},{"type":"tag","title":"Ubuntu","url":"/tags/Ubuntu/"},{"type":"tag","title":"Solution","url":"/tags/Solution/"},{"type":"tag","title":"Code","url":"/tags/Code/"},{"type":"tag","title":"C++","url":"/tags/C++/"},{"type":"tag","title":"Programing Language","url":"/tags/Programing Language/"},{"type":"tag","title":"Hexo","url":"/tags/Hexo/"},{"type":"tag","title":"Blog","url":"/tags/Blog/"},{"type":"tag","title":"Gleam","url":"/tags/Gleam/"},{"type":"tag","title":"Functional","url":"/tags/Functional/"},{"type":"tag","title":"Idris","url":"/tags/Idris/"},{"type":"tag","title":"Latex","url":"/tags/Latex/"},{"type":"tag","title":"Math","url":"/tags/Math/"},{"type":"tag","title":"Lean","url":"/tags/Lean/"},{"type":"tag","title":"Mastodon","url":"/tags/Mastodon/"},{"type":"tag","title":"Frontend","url":"/tags/Frontend/"},{"type":"tag","title":"Note","url":"/tags/Note/"},{"type":"tag","title":"Vim","url":"/tags/Vim/"},{"type":"tag","title":"Joke","url":"/tags/Joke/"},{"type":"tag","title":"Haskell","url":"/tags/Haskell/"},{"type":"tag","title":"Rust","url":"/tags/Rust/"},{"type":"tag","title":"Misskey","url":"/tags/Misskey/"},{"type":"tag","title":"Backend","url":"/tags/Backend/"},{"type":"tag","title":"Vue","url":"/tags/Vue/"},{"type":"tag","title":"Windows","url":"/tags/Windows/"},{"type":"tag","title":"双语","url":"/tags/双语/"},{"type":"tag","title":"Zig","url":"/tags/Zig/"},{"type":"tag","title":"Tools","url":"/tags/Tools/"},{"type":"tag","title":"Javascript","url":"/tags/Javascript/"},{"type":"tag","title":"Algorithm","url":"/tags/Algorithm/"},{"type":"tag","title":"Crystal","url":"/tags/Crystal/"},{"type":"category","title":"Practical Foundations for Programming Languages","url":"/categories/Practical Foundations for Programming Languages/"}]